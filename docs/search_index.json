[
<<<<<<< HEAD
["vocab.html", "3 Vocabulary Development 3.1 Norms 3.2 Quantifying Variability", " 3 Vocabulary Development Far from simply reflecting noise in our measuring instruments or variability in low-level aspects of physiological maturation, the variations that we will document (in vocabulary development) are substantial, stable, and have their own developmental course. Because this variation is substantial, it is critical for defining the boundary between normal and abnormal development; because it is stable, it provides a window onto the correlates and (by inference) the causes of developmental change; and because it has its own developmental course, it can be used to pinpoint critical developmental transitions that form the basis for theories of learning and change. (Bates et al., 1995) This chapter focuses on a particular view of the data, namely that each child is represented by a single vocabulary score: the proportion of words that child knows out of the total in the form. We begin by quantifying the nature of variability across individuals, ages, and languages. 3.1 Norms We begin with the general pattern of data across the instruments. 3.1.1 Comprehension Comprehension is typically meausured only for younger children, using Words and Gestures instruments.1 3.1.2 Production Production is measured both on Words and Gestures (WG) forms and Words and Sentences (WS) forms, though it is often at floor for younger children and so is not a reliable individual difference measure. Words and Sentences Stiched across forms. See A. 3.2 Quantifying Variability One of the most important features of early vocabulary development is its variability (Fenson et al. 1994). Consider the English production data from the Words and Sentences form. It’s immediately clear that there is tremendous variability in vocabulary. Consider just a single age group, 24-month-olds. The distribution of vocabularies across children is far from normally distributed, with many children at the very bottom of the scale and almost as many at the top. Quite a few two-year-olds on their second birthday are producing only a handful of words (or at least their parents say they are) and others are producing more than 600 listed on the form, with the total number higher than that even.2 One way to describe these data is to consider the relationship of the variance to the central tendency. The “coefficient of variation” (CV) is a common measure used for this purpose: \\[CV = \\frac{\\sigma}{\\mu}\\] This statistic allows standardized comparison of variability across measurements with different scales, an important concern when we want to compare forms with very different numbers of vocabulary items. For example, for two-year-olds, the mean productive vocabulary is 319 words, and the standard deviation is 175, words, leading to a CV of 0.55. But, as seen in Figure @ref(fig:v_histogram), the distribution of productive vocabulary scores is far from normal; this trend is even more apparent at the younger and older ages. Thus, a non-parametric approach is more appropriate. Accordingly, we compute the MADM statistic, the non-parametric equivalent of the CV. In MADM, the mean \\(\\mu\\) is replaced by the median (\\(m(x)\\), and the standard deviation \\(\\sigma\\) is replaced by the mean absolute deviation (which captures how far away values are from the median): \\[MADM(x) = \\frac{\\frac{1}{n} \\sum_{i = 1..n}{|x_i - m(x)|}}{m(x)}\\] In American English production, this ratio is actually close to 1 from age one until almost age two, suggesting that the standard difference from the median is actually as big as the median itself! The decline begins before variability is substantially truncated by the ceiling of the form, suggesting that variability between kids is really highest before the second birthday. Imagine groups of three children. A group where one produced 30 words, one produced 100, and another produced 170 would have a MADM of 0.99. In contrast, one where they were more closely grouped – say 70, 100, 130 – would have a MADM of 0.44. The next figure shows MADM across languages and instruments. This similarity in variability structure is quite striking, such that between the first and second birthdays, language is remarkably variable. Yet this variability is quite consistent! With the exception of populations like signers, e.g. in the case of British Sign Language, which is truncated here.↩ It will quickly get tiresome to acknowledge ceiling effects and parent report biases in every sentence, so we will acknowledge them up front and then mention them only when relevant throughout.↩ "]
=======
["gestures.html", "11 Gesture and Communication", " 11 Gesture and Communication This chapter contains analysis of the “early gesture” items from the CDI. Analyses will focus on the cross-linguistic consistency and variability of reporting milestones like first pointing, as well as social routines like waving hi and playing peekaboo. Let’s try out some basic descriptives. What do these things look like? Let’s arrange them in order of difficulty(on the bases of highest proportion of non-producers). I can’t tell if sometimes/often really carries very much signal. It looks like it’s all over the place for the earliest gestures and almost overlapping for the latest ones. Let’s try compressing to a binary These look pretty reasonable to me, and a lot more stable. Also smacklip doesn’t seem to have much of any kind of trajectory, which makes me think that parents don’t know what do with it. For comparison, let’s try the other gesture categories. Interesting, ok most of these look like they have some signal (with the exception maybe of sobig). Also some of them don’t look terribly different from the First Gestures. Let’s try looking at correlations with vocabulary size Wow, age is really predictive of gesture, even more so than comprehension/production. Let’s looking at the effect when we fit age simultaneously. #&gt; Generalized linear mixed model fit by maximum likelihood (Laplace #&gt; Approximation) [glmerMod] #&gt; Family: binomial ( logit ) #&gt; Formula: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; scale(age) + scale(production) + (1 | data_id) #&gt; Data: cor_data #&gt; #&gt; AIC BIC logLik deviance df.resid #&gt; 16997.2 17020.4 -8494.6 16989.2 2430 #&gt; #&gt; Scaled residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.39115 -0.30211 -0.01556 0.27692 2.68485 #&gt; #&gt; Random effects: #&gt; Groups Name Variance Std.Dev. #&gt; data_id (Intercept) 0.2875 0.5362 #&gt; Number of obs: 2434, groups: data_id, 2434 #&gt; #&gt; Fixed effects: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 0.14989 0.01227 12.22 &lt;2e-16 *** #&gt; scale(age) 0.59606 0.01402 42.53 &lt;2e-16 *** #&gt; scale(production) 0.26313 0.01448 18.17 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Correlation of Fixed Effects: #&gt; (Intr) scl(g) #&gt; scale(age) -0.014 #&gt; scl(prdctn) 0.029 -0.450 #&gt; Generalized linear mixed model fit by maximum likelihood (Laplace #&gt; Approximation) [glmerMod] #&gt; Family: binomial ( logit ) #&gt; Formula: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; scale(age) + scale(comprehension) + (1 | data_id) #&gt; Data: cor_data #&gt; #&gt; AIC BIC logLik deviance df.resid #&gt; 16336.8 16360.0 -8164.4 16328.8 2430 #&gt; #&gt; Scaled residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.44108 -0.34002 -0.01794 0.31467 3.04034 #&gt; #&gt; Random effects: #&gt; Groups Name Variance Std.Dev. #&gt; data_id (Intercept) 0.1983 0.4453 #&gt; Number of obs: 2434, groups: data_id, 2434 #&gt; #&gt; Fixed effects: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 0.14965 0.01065 14.05 &lt;2e-16 *** #&gt; scale(age) 0.43318 0.01341 32.30 &lt;2e-16 *** #&gt; scale(comprehension) 0.46264 0.01346 34.37 &lt;2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Correlation of Fixed Effects: #&gt; (Intr) scl(g) #&gt; scale(age) -0.015 #&gt; scl(cmprhn) 0.024 -0.580 #&gt; Generalized linear mixed model fit by maximum likelihood (Laplace #&gt; Approximation) [glmerMod] #&gt; Family: binomial ( logit ) #&gt; Formula: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; scale(age) + scale(comprehension) + scale(production) + (1 | #&gt; data_id) #&gt; Data: cor_data #&gt; #&gt; AIC BIC logLik deviance df.resid #&gt; 16318 16347 -8154 16308 2429 #&gt; #&gt; Scaled residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.45408 -0.34620 -0.01623 0.31725 3.05044 #&gt; #&gt; Random effects: #&gt; Groups Name Variance Std.Dev. #&gt; data_id (Intercept) 0.196 0.4427 #&gt; Number of obs: 2434, groups: data_id, 2434 #&gt; #&gt; Fixed effects: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 0.15077 0.01061 14.205 &lt; 2e-16 *** #&gt; scale(age) 0.42424 0.01349 31.439 &lt; 2e-16 *** #&gt; scale(comprehension) 0.42833 0.01534 27.914 &lt; 2e-16 *** #&gt; scale(production) 0.06568 0.01439 4.563 5.05e-06 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Correlation of Fixed Effects: #&gt; (Intr) scl(g) scl(c) #&gt; scale(age) -0.018 #&gt; scl(cmprhn) 0.010 -0.432 #&gt; scl(prdctn) 0.025 -0.143 -0.485 #&gt; Data: cor_data #&gt; Models: #&gt; age_cor: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; age_cor: scale(age) + (1 | data_id) #&gt; age_production_cor: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; age_production_cor: scale(age) + scale(production) + (1 | data_id) #&gt; Df AIC BIC logLik deviance Chisq Chi Df #&gt; age_cor 3 17311 17328 -8652.6 17305 #&gt; age_production_cor 4 16997 17020 -8494.6 16989 315.91 1 #&gt; Pr(&gt;Chisq) #&gt; age_cor #&gt; age_production_cor &lt; 2.2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; Data: cor_data #&gt; Models: #&gt; age_cor: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; age_cor: scale(age) + (1 | data_id) #&gt; age_comprehension_cor: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; age_comprehension_cor: scale(age) + scale(comprehension) + (1 | data_id) #&gt; Df AIC BIC logLik deviance Chisq Chi Df #&gt; age_cor 3 17311 17328 -8652.6 17305 #&gt; age_comprehension_cor 4 16337 16360 -8164.4 16329 976.28 1 #&gt; Pr(&gt;Chisq) #&gt; age_cor #&gt; age_comprehension_cor &lt; 2.2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; Data: cor_data #&gt; Models: #&gt; age_comprehension_cor: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; age_comprehension_cor: scale(age) + scale(comprehension) + (1 | data_id) #&gt; age_both_cor: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; age_both_cor: scale(age) + scale(comprehension) + scale(production) + (1 | #&gt; age_both_cor: data_id) #&gt; Df AIC BIC logLik deviance Chisq Chi Df #&gt; age_comprehension_cor 4 16337 16360 -8164.4 16329 #&gt; age_both_cor 5 16318 16347 -8154.0 16308 20.789 1 #&gt; Pr(&gt;Chisq) #&gt; age_comprehension_cor #&gt; age_both_cor 5.127e-06 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; Data: cor_data #&gt; Models: #&gt; age_comprehension_cor: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; age_comprehension_cor: scale(age) + scale(comprehension) + (1 | data_id) #&gt; age_interaction_cor: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; age_interaction_cor: scale(age) * scale(comprehension) + scale(age) * scale(production) + #&gt; age_interaction_cor: (1 | data_id) #&gt; Df AIC BIC logLik deviance Chisq Chi Df #&gt; age_comprehension_cor 4 16337 16360 -8164.4 16329 #&gt; age_interaction_cor 7 16250 16291 -8118.3 16236 92.32 3 #&gt; Pr(&gt;Chisq) #&gt; age_comprehension_cor #&gt; age_interaction_cor &lt; 2.2e-16 *** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; Generalized linear mixed model fit by maximum likelihood (Laplace #&gt; Approximation) [glmerMod] #&gt; Family: binomial ( logit ) #&gt; Formula: cbind(produced_gestures, num_gestures - produced_gestures) ~ #&gt; scale(age) * scale(comprehension) + scale(age) * scale(production) + #&gt; (1 | data_id) #&gt; Data: cor_data #&gt; Control: glmerControl(optimizer = &quot;bobyqa&quot;) #&gt; #&gt; AIC BIC logLik deviance df.resid #&gt; 16250.5 16291.1 -8118.3 16236.5 2427 #&gt; #&gt; Scaled residuals: #&gt; Min 1Q Median 3Q Max #&gt; -2.54909 -0.35685 -0.02043 0.31887 3.07812 #&gt; #&gt; Random effects: #&gt; Groups Name Variance Std.Dev. #&gt; data_id (Intercept) 0.188 0.4336 #&gt; Number of obs: 2434, groups: data_id, 2434 #&gt; #&gt; Fixed effects: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) 0.22164 0.01349 16.425 &lt; 2e-16 *** #&gt; scale(age) 0.36969 0.01494 24.752 &lt; 2e-16 *** #&gt; scale(comprehension) 0.42651 0.01576 27.062 &lt; 2e-16 *** #&gt; scale(production) 0.15817 0.02355 6.716 1.87e-11 *** #&gt; scale(age):scale(comprehension) -0.06899 0.01547 -4.461 8.17e-06 *** #&gt; scale(age):scale(production) -0.07262 0.02258 -3.217 0.0013 ** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; Correlation of Fixed Effects: #&gt; (Intr) scl(g) scl(c) scl(p) scl(g):scl(c) #&gt; scale(age) -0.298 #&gt; scl(cmprhn) -0.035 -0.320 #&gt; scl(prdctn) 0.384 -0.378 -0.469 #&gt; scl(g):scl(c) -0.213 0.087 -0.238 0.311 #&gt; scl(g):scl(p) -0.354 0.306 0.267 -0.777 -0.592 Ok so all of the things that are positively correlated contain some signal in predicting each-other over and above age. It also looks like there is some non-linearity in the correlation, because the age * comprehension/production correlations are negative. Presumably this is some kind of ceiling effect where the gestures in general are producted before the words? Let’s check that next. "]
>>>>>>> a5e8e68a499952bc1d4be409c148ac449106db13
]
