[
["conclusion-consistency.html", "Chapter 15 Variability and Consistency Within and Across Languages 15.1 Methods 15.2 Results and discussion", " Chapter 15 Variability and Consistency Within and Across Languages In the preceding chapters, we have presented evidence from a wide range of analyses of the Wordbank dataset. These analyses have revealed both striking variability across our units of sampling – across children, primarily, but also across words and even languages – but they have also revealed substantial consistencies (even in the nature of the variability itself!). In this short chapter we present a set of analyses of the consistency and variability of specific phenomena. The next chapter, Chapter 16, synthesizes these observations with . In each of the substantive chapters of this book (roughly speaking from Chapter 5 to 14), we have presented analyses of specific phenomena of theoretical interest. Wherever possible, we have generalized these analyses across languages so that their relative consistency can be examined and discussed. The goal of the current analysis is to bring together these analyses into a single meta-analysis (in the general sense, not the specific statistical sense). This strategy executes the general idea discussed in Chapter 1: We have identified “signatures” of language development, measurements that we believe are theoretically interesting or central. We have then quantified variability in these signatures across languages. These estimates of cross-linguistic variability are measurements of the degree to which aspects of language development are more or less similar across different languages and cultural contexts. We discuss the types of inferences licensed – and not licensed – by these analyses below. 15.1 Methods We begin by identifying a small number of measures computed in each chapter to serve as the “signatures” to be promoted into this analysis. For each measure, we compute its cross-linguistic variability using a standardized measure of variance, the coefficient of variation (CV, the standard deviation divided by the mean). This measure can range from 0 (indicating a phenomenon that is completely invariant across languages) to infinity (with higher numbers indicating greater variation). These CV values provide a single common measure to allow comparability of otherwise very different quantities, allowing inferences across analyses and datasets – albeit with some cautions that we describe below. Each measure for which we compute the CV will have both a different base unit and a different number of languages contributing. For example, when considering the correlation between grammar and the lexicon (Chapter 13), we will be looking at the CV of a set of correlations with one specific set of languages contributing. In contrast, when we look at the size of the noun bias (Chapter 11), we will be looking at a group of bias estimates that each may have different units and may be based on a somewhat different set of languages. Thus, caution is warranted in interpreting these variability estimates, even though we believe that they indeed are informative. To assist in interpretation, we include only those measures that can be computed in 6 languages or more; provide the N contributing languages for all analyses; and compute an estimate of the standard error of the CV (\\(SEM \\approx CV / \\sqrt{2N}\\)). The set of signatures we include in this analysis are necessarily a subjectively-determined subset of the possible measures we have examined in the book. And, of course, those in turn are a subset of the measures we could have computed. Wherever possible we have attempted to make reasonable decisions, but some of these are, by necessity, somewhat arbitrary. An example of such a decision comes from the summary of Chapter 5. In that chapter we noted that population variability appears quite consistent across languages. We summarized population variability in production via a statistic, MMAD – but what is the appropriate range of ages to include in a single estimate? In this chapter, we observed that there appears to be a ceiling effect in the later ages. Thus, we decided to include variability in production from 12 – 24 months. But this decision is data-dependent and so, of course, there is a risk of circularity. We point the issue out not to undermine this particular analysis; we believe the ceiling effect is quite clear and other aspects of the age choice do not lead to much change in the CV estimate. Rather we intend to highlight that the summary we give is not a theory-neutral estimate but rather a “best guess” – an attempt to navigate the myriad choices involved in our analysis in a reasonable way. One example of such a choice is that we have made the decision to omit estimates of early production from WG-type forms. Our judgment was motivated by the fact that such estimates are routinely quite noisy and difficult to interpret, likely due to the small size of early productive vocabularies. In chapter after chapter, we found unreliable or uninterpretable results that are plausibly due to data sparsity; thus, we choose to omit these patterns. 15.2 Results and discussion Figure 15.1: Coefficient of variation across languages for signatures of language development corresponding to four different categories (panels). Each point gives an estimate, with point size corresponding to number of languages. Color indicates whether comprehension or production is measured. Error bars give the standard error of the coefficient of variation. Figure 15.1 shows the coefficient of variation across languages for all measures in each of these categories. For the sake of our analysis, we have divided measures from the preceding chapters into four categories, corresponding to the panels of Figure 15.1. These are: Measures of the composition of vocabulary, from Chapters 11 and 12. These measures describe the over- and under-representation of various word categories in vocabulary. The units over which CV is computed are bias scores; these are bounded from -.5 to .5 (deviation from unbiased acquisition of a particular category). Predictors of word difficulty, from Chapter 10. The consistency of different regression predictors of age of acquisition are here represented by their cross-linguistic consistency. This analysis is distinct from the analysis presented in that chapter (which focused mostly on the magnitude rather than variability of the coefficients themselves). Despite that, we include it here for comparison with other signatures. The units over which CV is computed are standardized regression coefficients. Relational measures, from Chapters 7 and 13. These measures are originally correlations between vocabulary size and other aspects of early language. Vocabulary signatures, from Chapters 5 and 6. These measures document patterns in the overall size of vocabulary across individuals and demographic groups. The original units are themselves variability-based (MMAD scores). A number of local patterns are immediately apparent; we discuss these briefly below before turning to larger-scale generalizations in the next section. First, comprehension is almost always more variable than production, even when a comparable number of languages are included. The only obvious exception to this regularity is for coefficient weights on arousal in the Predictors category – and we can discount this example: arousal was on average one of the weakest predictors of acquisition order overall. Why would comprehension be more variable across languages than production, especially given evidence that comprehension vocabulary tends to be less idiosyncratic than production (Mayor and Plunkett 2014)? One strong possibility is the psychometric properties of comprehension vs. production reports. As described in Chapter 4, while comprehension scores are likely still a reliable and valid index of children’s abilities in the aggregate, individual comprehension questions tend to carry less information. Thus, there may simply be more noise in these measurements, leading to less cross-linguistic stability. This regularity illustrates a point we have made earlier and will return to below: the inferences from consistency and variability are asymmetric. In the case of consistency, we can make relatively strong inferences about some kind of shared process or mechanism. In contrast, in the case of variability, there are many sources of variance (including measurement error) that can account for a specific pattern of performance. Second, relational measures are highly invariant across languages. These relations include correlations between the size of children’s lexicon (in production or comprehension) and their gesture, morphology, and grammatical complexity. These findings can be measured in a relatively small set of languages (due to limited data availability for the gesture and complexity items on the form). Nevertheless, the high level of consistency is striking. Third, demographic predictors – birth order, maternal education, and sex – are somewhat variable, likely reflecting at least some cultural variation. The most variable of these is the relation of maternal education with vocabulary. Maternal education is plausibly a proxy for socioeconomic status (SES); in turn, the relation of SES to vocabulary is likely mediated by many local- and national-level policies including access to childcare, parent leave, pre- and post-partum education and services. Thus, we view variation on this dimension as highly plausible a priori. In contrast, as we asserted in Chapter 5, the consistency of children’s variability is quite striking: the variability of children across instruments is almost completely constant, especially for production. Around the world, toddlers appear to be have similar levels of variability in their level of production. Finally, while predictors of word difficulty are consistent relative to a chance baseline (see Chapter 10), they are also on the higher end of variability. Especially in comparison to some of the relational signatures (e.g., the correlation between grammatical complexity and vocabulary), their variability is high. Plausibly some of this variability is due to additional variation added to these estimates by the use of external resources (e.g., corpus counts). In particular, as we discussed in that earlier chapter, there is an unknown amount of noise added by estimating frequencies from smaller-scale cross-linguistic corpora. "]
]
