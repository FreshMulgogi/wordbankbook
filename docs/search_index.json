[
["index.html", "Variability and Consistency in Early Language Learning: The Wordbank Project Preface Overview Outline How to Read This Book Acknowledgements", " Variability and Consistency in Early Language Learning: The Wordbank Project Michael Frank, Mika Braginsky, Virginia Marchman, and Daniel Yurovsky Preface Overview The emergence of children’s early language is one of the most miraculous parts of human development. The ability to communicate using language arrives with incredible rapidity – most parents judge that their child is producing words with the intent to communicate before his or her first birthday (Schneider, Yurovsky, and Frank 2015) and the onset of comprehension is even earlier (e.g., Bergelson and Swingley 2012; Tincoff and Jusczyk 1999). New words enter children’s expressive vocabularies slowly at first, but this process accelerates over the second year such that children reach an average of 300 words by 24 months and more than 60,000 by the time they graduate from high school (Fenson et al. 2007). At the same time, there are significant individual differences in the rate and timing of language acquisition. For example, although some 18-month-olds already produce 50–75 words, others produce no words at all, and will not do so until they are two years or older (e.g., Brown 1973; Bloom 2002; Clark 2003). How do children learn their first language? To what extent do different children and children learning different languages follow the same path into language? Are these paths similar or idiosyncratic? These questions about the consistency and variability of early language lead directly into the central question of language acquisition: What are the mechanisms that lead to the emergence of human language? Answering this question is complicated immensely by the fact that there is no one single event that constitutes language acquisition. Early language learning involves the accumulation of thousands of words, grammatical rules, and constructions, and takes place over the course of years of growth and millions of separate interactions. This problem of timescales makes measurement a tremendous challenge. In addition, during the period in which language emerges, language ability varies wildly from child to child and most children are at best reluctant experimental participants. Accurate measurement of language development across individuals is thus a major challenge. Parent report is one powerful method for adressing these. The MacArthur-Bates Communicative Development Inventory (CDI) is a simple survey instrument for measuring early language outcomes that was designed to address these issues.1 The CDI is a checklist for parents to fill out to report on their child’s progress in language. In different versions of the form, parents mark whether their child “says” or “understands and says” particular words out of a list of several hundred. Separate sections for gestures, word forms, and grammar are also present in some versions. Despite their simplicity, over the past 25 years of use, CDI forms have been shown to be reliable and valid measures of children’s early language. In addition, CDI forms have been adapted to more than 100 different languages around the world. Research based on the CDI has contributed tremendously to our understanding of the growth of language in early childhood. In this book, we examine the question of variability and consistency in early language through the lens of the CDI. Our book is an outgrowth of the Wordbank project (M. C. Frank et al. 2016), which has as its goal to archive CDI data in a structured format so that they can be explored and analyzed in the service of describing early language. The database currently contains data from more than 82055 CDI form administrations across 29 languages. Wordbank is also continuously growing as new researchers contribute data. We believe this database is the largest and most diverse set of data on early language acquisition currently in existence. Over the course of our work with Wordbank, we have developed a consistent framework for representing and analyzing CDI data. This framework allows us to unify a variety of influential previous analyses of CDI data. Just to take an example, one question of theoretical interest has been whether young children have an over-representation of nouns (names for things) in their vocabulary, and whether this trend is seen across languages. In Chapter 11, we develop an analytic method for measuring the size of this “noun bias” and apply the analysis to the Wordbank data. This measurement can then be compared across languages, and its variability can be estimated and compared to other measurements. Thus, one first contribution of this book is to synthesize and unify previous work. Research in early language learning often builds off a fragmentary empirical picture, in which many important theoretical conclusions are based on analyses of transcripts from a small number of children, or analyses of experimental or parent-report data from English learners only. We hope that bringing together a large set of analyses of vocabulary data and implementing them consistently, openly, and reproducibly on the same dataset will help to create an empirical starting point for future work. A second contribution of the book is to develop theory treating the question of consistency and variability in early language. We introduce the notion of “process universals” – that some aspects of the process of word learning may be universal across cultures and may lead to similarities in the dynamics of learning. These universals may arise due to the basic mechanisms of learning, memory, and social cognition that are at play in early vocabulary learning. This general idea has a long history in the field (e.g., Bates, MacWhinney, and others 1989), but the Wordbank project provides an opportunity to lend new empirical data and analytic power to these ideas. This notion is contrasted with notions of “content” or “structural” universals in which particular principles regarding the structure of languages are innately given. This set of contributions reflects an important guiding principle of our work here. Studies which at first glance seem like “mere replication” – in which a particular analysis is replicated on a larger dataset – are in fact important opportunities for theoretical development. Replicating with a larger dataset alone leads to a more precise estimate of the phenomenon, which can be used to confirm reliability, but also for quantitative comparisons and computational models. Further, increased precision allows for the examination of variability and consistency across meaningful units like children, words, instruments, or languages. Such estimates in turn are – as we argue throughout – relevant to foundational theoretical questions. Thus, there is never “mere” replication. More precise measurements sit hand and hand with better theory. Outline The first chapters of this book provide an overview of the practical and theoretical issues that we cover. Chapter 1 gives a broad theoretical overview of our claims and sets up some of the empirical themes that we return to throughout, especially the notion of using the consistency and variability of phenomena to make generalizations about the process of acquisition. Chapter 2 then discusses the practicalities of the CDI and the Wordbank project. Chapter 3 gives a methodological and descriptive overview of the dataset we analyze throughout. And Chapter 4 discusses the psychometric properties of parent report data, addressing questions about the strengths and limitations of this method. Chapters 5 – 14 then form the empirical heart of the book. Each applies a particular analysis of interest to our dataset. Although our goal is a full exploration of the phenomena of child language acquisition, the analyses we report are constrained by the structure of the data in Wordbank. At its heart, the individual instrument datasets stored in Wordbank are matrices of item by child data (see the figure below). Figure .: A graphical outline of the book. Considering the data in this way leads to a number of obvious data analytic strategies, many of which correspond directly to previous approaches to CDI data. For example, averaging across items leads to by-child averages, where each child receives a comprehension or production score. Chapter 5 considers this view of the data, examining developmental change and variability in such data. Then in Chapter 6, we report the ways that vocabulary growth varies across gender, birth order, and maternal education (a rough but cross-cultually valid proxy for socioeconomic status). Averaging across the other margin of the data leads to by-item averages. These can be examined in a number of different ways. Gesture items and their growth trajectory – and relationship to overall vocabulary size – are examined in Chapter 7. Chapter 8 then considers the growth trajectories for individual words, focusing especially on early vocabulary. Chapter 10 follows this approach and attempts to predict the trajectories of individual words based on both environmental and conceptual features of these words. This last approach calls for the incorporation of other resources, and so we use a variety of English and cross-linguistic resources to supplement Wordbank data in this chapter. Next, we investigate the grouping of items into categories (both syntactic and semantic). Chapter 11 considers the categorical composition of early vocabulary, giving special consideration to the “noun bias” that is found in many – but not all – of the languages in Wordbank. Chapter 12 adopts the same approach for semantic, rather than syntactic, categories. This approach leads us to consider other aspects of morphosyntax that are reflected in the CDI forms. Chapter 13 explores the relationship between vocabulary growth and the growth of grammar. Finally, Chapter 14 returns to the question of individual variation using tools built up in previous chapters to quantify differences in the style and trajectory of learning across children. The book ends with two synthesis chapters. Chapter 15 synthesizes observations across languages for the preceding chapters to quantify variability and consistency directly across phenomena. And the concluding chapter, Chapter 16, considers broadly the question of what the process of language acquisition looks like from the birdseye view afforded by our data. Finally, a number of appendices provide supplemental analyses, validating particular analytic practices that we adopt. How to Read This Book You can read this book as a narrative monograph. If you intend to do so, we recommend you read Chapters 1, 2, 3, and 4 before moving on to substantive chapters of interest. You can also read this book as a reference. If you take this approach, just dive into any chapter that is of interest, knowing that you may need to use some of the terminology defined in Chapter 3 to interpret the constructs and analyses that are used. Further, you may have concerns about the reliability and validity of CDI-type instruments; some of these are addressed in Chapter 4. A number of the analyses reported here were first described in earlier conference proceedings or publications (e.g., M. C. Frank et al. 2016; Braginsky et al. 2015, 2016). Rather than reprinting these verbatim, this manuscript updates them using the unified analytic approach and larger dataset described in Chapter 3. The version of these analyses represented in this manuscript should be considered more definitive than any previously published or presented version. The dataset in Wordbank is constantly growing and changing as we add new features, new data, and new languages. In addition, as users of the data occasionally identify issues and errors, we make will make corrections to the database. In writing this manuscript, we have attempted to find a middle ground between a completely dynamic document that responds to any change in the database, on the one hand, and a traditional, static book, on the other. A static manuscript would be a shame given the potential for dynamic extension and updating with new data. On the other hand, if the data were completely dynamic, any claim we made in prose would risk being out of date almost as soon as we wrote it. For this reason, we work using snapshots of the underlying database. Every so often, we will return to the manuscript and recompile the online edition, then check references to the data that might have changed. The current build of the book is from Tue Dec 11 17:03:20 2018, based on data cached on CACHE DATE. Acknowledgements Our sincere thanks go to all of the generous researchers – too many to name here, but listed on the Wordbank contributors page and in Appendix A – who contributed their data to the database. Even during our time working on this project, norms of data sharing have shifted; some substantial portion of this shift is due to the generosity of those researchers who shared their data early on in the process. Thanks especially to Rune Nørdgard Jørgensen for sharing the full CLEX-CDI dataset (Jørgensen et al. 2010) and for his kind assistance in the transition from the CLEX-CDI website to the Wordbank website. Major thanks are also due to the MacArthur-Bates CDI Advisory Board, especially Philip Dale and Larry Fenson, for their continued intellectual, financial, logistical, and personal support of the Wordbank project. Thanks to Danielle Kellier for substantial work importing data and mantaining the Wordbank website, as well as updating the universal lemma mappings. Initial programming work was done by Ranjay Krishna, and some database imports were performed by Elise Sugarman. Thanks to NSF Award #1528526, “Wordbank: An Open Repository for Developmental Vocabulary Data” for financial support of the Wordbank project as well as to the Stanford Psychology Department for a small seed funding award that supported the initial development of the site. For purposes of clarity and ease throughout we refer to CDIs (the family of instruments) rather than the MB-CDI (the particular English forms). We will use this term throughout even though technically some of our data come from “checklists” containing only vocabulary items rather than true Communicative Development Inventory forms.↩ "],
["intro-theory.html", "1 Theoretical Foundations 1.1 The Picture To Date 1.2 Making Progress 1.3 Variability and Consistency 1.4 Process Universals 1.5 Replication and Theory-Building: Conclusions", " 1 Theoretical Foundations One of the defining human characteristics is the ability to use language in its lexical and combinatorial richness. The study of language acquisition has been a traditional locus of our search to understand the nature of this ability. What allows human children to acquire a language has been the subject of one of the historical “great debates,” in which different proposals about the architecture of the human mind and the nature of human uniqueness have been discussed. Does language arise from domain-specific adaptations for syntactic structure (Chomsky 1981, 2014)? Or does it arise from a combination of environmental input and sophisticated, general-purpose learning mechanisms (Elman et al. 1996)? Two poles have traditionally emerged in this discussion: from domain-general empiricist proposals to domain-specific, nativist proposals. In this chapter, we begin by presenting the perspective from these poles but contend that they are rarely helpful in the practice of understanding the scope and course of early language learning. Instead, we argue for the development of theories that describe the scope and course of language learning as a whole, as well as its quantitative variation across children, languages, and cultures. These concerns lead us to frame our own study in terms of a set of distinct theoretical issues: capturing consistency and variability; drawing connections across timescales of learning; and the notion of process, rather than content, universals. We end by discussing the relation of our theoretical stance to others and the role of replication and larger datasets in building quantitative theories. 1.1 The Picture To Date Empiricist proposals emphasize the ability of children to learn structure across domains, the richness of the distributional input that children are exposed to, and their ability to create appropriate abstractions from structured linguistic input. The components of these proposals are children’s general statistical learning abilities (Saffran, Aslin, and Newport 1996; Fiser and Aslin 2002). When applied to linguistic input, even general statistical tools can recover some aspects of linguistic structure across a variety of domains (Redington, Crater, and Finch 1998; Frank, Bod, and Christiansen 2012; Elman et al. 1996). While promising, these proposals have as their primary challenge that children show evidence of abstractions that encode key aspects of linguistic competence, even at an early age and in the absence of substantial input. For example, young children show systematic word orders even in the absence of structured input (Goldin-Meadow and Mylander 1983). Further, typically developing children interpret the arguments of novel verbs (Gertner, Fisher, and Eisengart 2006) and show evidence of category structure for syntactic categories such as determiners (Yang 2013) and structures such as the dative (Conwell and Demuth 2007), even from an early age. Nativist proposals, in contrast, tend to focus on the complexity of the grammatical structures that young children appear to possess, relative to their rarity in children’s environment. Such arguments emphasize the poverty of the linguistic stimulus (e.g., Legate and Yang 2002) in contrast to the richness of the structural generalizations children make (e.g., Crain and Thornton 2000). The type of proposals that are on offer within this space often include “principles and parameters”-type theories, in which languages share a set of syntactic principles that govern syntactic combination but vary on a relatively small set of parameters that control how these structures vary (Baker 2005; Yang 2002). These proposals are challenged by the vast cross-linguistic differences in syntactic abstractions (Evans and Levinson 2009), by the character and scope of children’s syntactic generalizations (which are often tied to specific lexical structures; Tomasello 2000), and by evidence of early input-sensitive learning and generalization both within specific domains (e.g., Meylan et al. 2017) and in artificial language tasks (Gómez and Gerken 1999). Such proposals also tend to downplay the inherent variability that characterizes language learning across individuals (Bates, Bretherton, and Snyder 1988; Bates et al. 1994), focusing instead on the universals or commonalities that exist across children. While nativist proposals acknowledge that individual variation exists, variation is thought to serve a primarily descriptive function, existing in a “theoretical vacuum” (Bloom 2002, 52), with greater emphasis on how language acquisition works in the general case. The “great debate” between these viewpoints is philosophically appealing, but has also led to a polarization of the field of language acquisition. Typically researchers work in their own siloed traditions (empiricist or nativist), and focus on individual phenomena that do not make contact with one another – a classic version of Kuhn (1970)’s “paradigms.” Research in the nativist tradition often focuses on particular syntactic phenomena that are largely neglected in the empiricist tradition (e.g., the “optional infinitive,” Wexler 1998; but cf. Freudenthal, Pine, and Gobet 2010). In contrast, research in the empiricist tradition has often used artificial language learning tasks that are argued not to reflect on the underlying structural properties that are claimed to be innate (e.g., Lany and Saffran 2010; cf. Yang 2004). Empiricist theories are also more likely to recognize the causes and consequences of individual variation in rates of learning, including potential sources of that variation that arise from variation in the circumstances in which children learn and the opportunities they have for engaging with language in a meaningful way (e.g., Huttenlocher et al. (1991); Hoff (2006); Weisleder and Fernald (2013)). By focusing on different paradigms and phenomena and theorizing using distinct vocabularies, these traditions make limited contact. Often, language development conferences feature paired keynote talks from these two different traditions – a clear sign of polarization. In addition, these theories are frameworks, rather than than actual hypotheses. Few proposals within these frameworks can be said to generate testable and clearly competing predictions, even within a specific domain. And any individual observation typically cannot be said to be inconsistent with any but the absolute strongest nativist or empiricist position. To be tested, proposals must make specific predictions. Computational models have been an important method for allowing proposals to be instantiated to the degree that they can make testable predictions. In practice, however models typically end up less differentiated than framework rhetoric suggests. In order to get off the ground in performing a particular empirical task, theories must often help themselves to generous amounts of both innate structure – in the form of structured inputs from social, cognitive, or perceptual domains – and statistical learning abilities (Roy and Pentland 2002; Alishahi and Stevenson 2008; Frank, Goodman, and Tenenbaum 2009; Frank et al. 2010; Yang 2004).2 Further, when nativist and empiricist viewpoints make differing predictions, they are often in phenomena that – from a bird’s eye, or even parents’ eye, view – are relatively trivial in the general course of language development. Abstraction debates have played out in the acquisition of the definite determiner “the” (Valian 1986; Pine and Lieven 1997; Yang 2013; Meylan et al. 2017), auxilliary inversion (Pullum and Scholz 2002; Legate and Yang 2002), and the use of anaphoric “one” (Akhtar et al. 2004; Regier and Gahl 2004; Lidz, Waxman, and Freedman 2003), for example. These phenomena are occasionally observable in the children of linguistically-trained parents, but even the closest observer would be forgiven for being more compelled by watching the increasingly creative and complex ways that children interpret, use, and play with language, rather than the occasional syntactic slip. Further, all of these phenomena concern linguistic behavior at a particular level of abstraction, syntax, reflecting a broader historical argument that syntactic structure is the heart of the uniquely human language faculty (Chomsky 1957), and that other aspects of language tend to be shared with other species (Hauser, Chomsky, and Fitch 2002) and are therefore somehow less interesting, less amazing and less critical for science to understand. From an evolutionary perspective, syntax is far from the only unique or notable feature of human communication (Pinker and Jackendoff 2005; Tomasello 2010). The nature and range of communicative gestures, the variety of sounds, and the diversity of lexical items all are relatively unprecedented – especially in the primate lineage. And these observable aspects of language – as well as the emergence of syntactic structure more broadly – are some of what makes the broad course of language acquisition striking from the perspective of a clinician or a parent. We notice the first communicative signals, the emergence and rapid growth of of vocabulary, the beginning of the productive combination of words, increases in the length and complexity of utterances, and the patterns of error and overgeneralization that remain in early childhood. Moreover, there is considerable evidence for continuity across these domains (e.g., Bornstein and Putnick 2012; Tsao, Liu, and Kuhl 2004; Bates, Bretherton, and Snyder 1988; Cristia et al. 2014). Children’s earliest gestures and sounds relate to their oral language comprehension and production. And these in turn relate to later skill in using language as a tool for learning, through both the auditory (or visual, in the case of sign language) as well as the written modality. These broader patterns of language learning are the natural focus of investigations like ours that use parent report to learn about children’s language. Parents are attentive and accurate observers of communicative gesture, vocabulary, and word combination. But without linguistic training they may not even notice subtleties like non-productive determine use, auxilliary inversion, or anaphoric “one.” Further, these investigations can in many case make productive contact with the rich literatures on early communication, speech perception (e.g., Kuhl 2004), word learning (e.g., Bloom 2002; Snedeker 2009), and grammatical productivity through verb structure (Fisher et al. 2010). While debates over the nature of syntactic knowledge and abstraction have raged, other subfields of language acquisition have prospered. Research in these subfields makes at most limited contact with broad questions of nativism and empiricism, in part because they deal with phenomena that are language specific – sounds, lexical items, grammatical constructions – and hence that children must learn from their input. The question is then about the mechanisms and constraints that guide this process of learning, rather than about any posited universal or innate content (even at the level of abstractions). 1.2 Making Progress To move beyond great debates, what should a unifying theoretical framework for language learning look like? In spite of the critiques above, we still believe in the importance of the search for core, universal aspects of language learning that elucidate the process by which children acquire this uniquely human ability. Yet the sort of theory that describes such universals will likely look radically different from its historical antecedents. Below and in the remainder of this chapter, we sketch some aspects of what such a theory will look like and how this vision connects to our present investigation. Any universal is likely to be a statistical or quantitative universal – we refer to these as “consistencies.” The variation across the world’s languages is such that only the most tautological facts will be truly invariant (Evans and Levinson 2009). Further, we are unlikely to be able to access the kinds of samples that would allow us to make claims of universality (Piantadosi and Gibson 2014). Thus, we should talk about the relative consistency and variability of particular phenomena rather than any sorts of absolutes. In addition, language learning takes place at the timescale of years. CDI forms provide a global snapshot of a child’s language at a particular point in time, rather than demonstrating the operation of a particular mechanism or principle. Substantial reconstruction is necessary to understand how processes operating over seconds – for example, online statistical learning or pragmatic inference – would result in particular structures accreting over time in the vocabulary. Thus, consistencies we observe are at best the basis for abductive inferences about underlying mechanisms. These consistencies are consistencies in the learning of vocabulary and constructions, rather than syntactic rules. These items must be learned from data. Thus any putative universals identified in our investigation must not be “content universals” that specific particular grammatical rules or linkages. They must be “process universals” in the sense that they specify mechanisms or processes that unfold over time and operate over children’s interactional input in ways that produce the observed consistencies. Harkening back to Bates, Bretherton, and Snyder (1988) and Elman et al. (1996), our proposal is a shift from a focus on universal content to universal mechanism. 1.3 Variability and Consistency Observing what “hangs together” in development can provide clues about the architecture of the underlying system (Bates, Bretherton, and Snyder 1988). We think of these correlations as loose targets for theorists: a successful theory can gain support by providing an account for these observations. Crudely put, if a theory posits that some aspect of language acquisition is universal, it should be relatively more consistent in our data. What are the units over which we compute variability and consistency? We refer to these as “signatures” – loosely, measurements that can vary across populations. In practice, a signature can be the output of any analysis, with the simplest being vocabulary size or variability itself (as in Chapter 5). Signatures are linked to particular theoretical goals by arguments about the validity of an analysis – for example, the argument of Bates et al. (1994) that the over-representation of nouns in early vocabulary is a meaningful dimension of variation between individuals. A signature for our purposes is thus an analysis that yields a set of numbers. In nearly every chapter of the book, we define one or several signatures whose variability we can measure. Different sources of variance provide different sorts of evidence. One sense of the notion of “universal” that dates to early generative syntax is the notion of typological invariance (Greenberg 1963). Following this general idea, in the majority of the book we focus on variability in some signature across languages. The implied inference is that consistency across languages points to the idea that a signature results from some mechanism (more on inferences about mechanism below) that is independent of the language being learned and the context in which it is learned. But when we assess the variability of some signature across datasets, many things vary that are not the target of our inference. Although language and culture typically vary (except in the case of multiple instruments that are assessed on the same data source), many other things vary as well. Different datasets are constructed by different researchers with different goals. They use different instruments with different items – and different length and composition. These instruments are administered to different samples, with different sampling strategies. And the nature of the administration is different as well. Thus, when a particular response appears to be consistent, we can say a fortiori that none of these sources of variation appear to have affected the consistency of the response. (Or at least that if they have, they have canceled each other out in a highly non-random way). But when variability does occur, we cannot make the opposite inference. Variability has many explanations, but consistency tends to point us towards a single inference. We focus on cross-dataset variabity as the primary source of variability in this book. We refer to this variability throughout as cross-linguistic variability, though in fact there are a number of caveats that must be stated. First, many things vary between datasets far beyond language (as noted above). And second, some datasets represent the same language in different dialects (e.g., Australian and British English). Some even reflect the same language and dialect, measured using two different instruments (e.g., the two Beijing Mandarin datasets). In some cases we will even leverage these parallels to help us rule out alternative explanations. The reasons we focus on cross-dataset variability are three. First, datasets vary so much that – assuming this variation is somewhat random – claims of consistency are stronger when they emerge from this sort of data. Imagine counterfactully that all of the instruments we used had exactly the same structure and item set, and all were administered identically. Certainly this lack of variation would make our life easier in a number of ways when making quantitative comparisons between datasets! But it also then means that these consistencies would be confounded in our data – particular item sets (plausibly) or administration instructions (somewhat less plausibly) could be the source of an observed consistency in the data. In contrast, while the messiness and inconsistency of the data in the Wordbank dataset make many aspects of our analysis much harder, it actually increases the strength of the inferences we can draw when – despite this – we see some phenomenon emerge with striking consistency.3 Second, the genesis of the investigations documented in this book was in part the observation that several phenomena that we examined were strikingly consistent across languages. For example, the gender effects shown in Chapter 6 were much more consistent than any of us thought (being at the time ignorant about the previous literature in this particular area; Eriksson et al. 2012). Empirically, we found a lot to look at that was both surprising and interpretable when we examined well-known signatures as they varied across languages. Thus, our motivation is in part the emergent success of this approach. The final reason we consider cross-language variability as our primary lever is a negative one. The obvious competitor as a source of variability is variation across individuals. We examine this variability briefly in Chapters 4 and 5 and more extensively in Chapter 14. While we document substantial and stable variability across individuals (echoing Bates et al. 1994), this variability empirically proves to be less of a lever into theoretical issues of interest than we would hope. One aspect of this move is data-related – we have far more cross-sectional than longitudinal data in the Wordbank dataset – and hence we cannot track stability and change over time as easily or powerfully as we would like. Further, we have very few additional measures on most children in the dataset (beyond the occasional demographic feature). In addition, as we show in Chapter 14, though there is some reliable stylistic variation between children, much apparent variability in children’s style of language learning can be traced to variation in rate. Thus, and in contrast to the exciting emergent conclusions from cross-linguistic variation, individual variation appears to be a less powerful theoretical lever. Nevertheless, individual variation across individuals does exist and it is robust. Indeed, in Chapter 5, we show remarkable consistency across languages in the extent to which there is variability across individuals. We remain optimistic that continuing to explore the extent and consistency of this variability will continue to provide a window into the universal processes that guide learning for the mythical “model” child, as well as define the upper- and lower-limits on typical development. In Chapter 15, we bring together estimates of variability of individual signatures from each of the earlier constituent chapters. We combine these into a single, data-driven continuum from absolute consistency to high variability, and use this continuum to drive speculations about the sorts of mechanisms that would produce a particular set of consistencies. 1.4 Process Universals 1.4.1 Preconditions Imagine we were to uncover an aspect of language development that was completely consistent across languages. (Surprisingly, as we’ll see in Chapter 15 there are some!). What could we then infer from this observation? Not much, it turns out. The observed regularity could be due to different sources in different datasets or it could be uninteresting from a theoretical perspective. First, even if the consistency is interesting, any inference from it will always be abductive – an inference backwards from observation to cause These abductive inferences will always be underconstrained and tentative, thus they will always be at best empirically-grounded speculations that should be brought together with other data to make a test. In some sense, this is the fundamental caveat governing our entire enterprise here. The research design is correlational and so causal inferences are not available. Inferences can go wrong even within this more limited correlational paradigm. For example, we could observe that, across languages, we saw hypothetically that some word was always produced earliest. But it could be the case that the word happened to be learned earliest in some languages because it was short and easy to pronounce, while in other languages it was learned early due to a high frequency of usage in the input. This example illustrates the difficulties of reverse inference from consistency. Similarly, we could observe that a certain distributional form always described children’s vocabulary estimates, across languages. This regularity could be due to the operation of the central limit theorem rather than any interesting or substantive mechanism that we might be interested in as psychologists. These problems mean that we need to have two (somewhat informal) conditions on the consistencies that we posit. First, we need to consider the possibility of multiple routes to the same observed consistency. To the extent that observed regularities are specific and surprising, it will be less likely that there are multiple routes across different languages to observing the same thing. Second, for any potential causal story that we posit, we need to be able to posit a plausible or interesting causal story that does not generate the observed regularity. The tightness of this comparsion with a counterfactual governs the strength of the inteference. 1.4.2 The nature of the processes Suppose a consistency we identify meets the conditions we describe above: it is sufficiently surprising that we don’t see a parsimonious story for how the data for different languages could have been generated by different processes, and there are close counterfactuals in which this consistency did not emerge. Further, in our example suppose we have a larger and more diverse set of languages and cultures represented in our dataset such that we can justify using the title “universal” rather than the more descriptive and limited “consistency.” We can then imagine trying to constrain the nature of the sort of universal that could give rise to this type of consistency. What can we say about putatitive universals? By virtue of the learning problem that they arise from, they cannot be universals of content. A child’s vocabulary is made up of individual words, each arising from a set of specific interactional circumstances (e.g., the trip to the zoo where a giraffe was seen for the first time). And each of these words is – of course – specific to a particular language. Thus, there is no viable sense in which any possible universals for vocabulary learning can be content universals: no particular content of this type could be innately given. For this reason, we describe these as “process” universals: they relate to the process by which each individual extracts a lexicon from their own idiosyncratic linguistic experiences. Further, since these processes are fundamentally learning processes, they operate at the timescale of moment-to-moment interactions (Frank, Goodman, and Tenenbaum 2009; McMurray, Horst, and Samuelson 2012). In contrast, using the CDI, we observe the accretion of vocabulary and linguistic competence over the course of millions of these interactions (see e.g., Dupoux 2018 for estimates). This mismatch makes inferences about the nature of the processes even trickier – in some sense, we are attempting to uncover what forces eroded a hillside when all we see are the uncovered strata. Yet, from the perspective of the language learning literature, there are still obvious candidates for the sort of universals we are talking about. The general idea of “statistical learning” is one (Saffran, Aslin, and Newport 1996; Saffran and Kirkham 2018). From a very early age, children are sensitive to regularities in their sensory environments and track statistical associations between elements in these environments. Concrete examples of these mechanisms in action include the tracking of syllable-to-syllable conditional probabilities (Saffran, Aslin, and Newport 1996) and the tracking of word-referent corresspondences (Smith and Yu 2008), but in principle these mechanisms are likely operating over every level of representation present in early language (Shukla, White, and Aslin 2011). Of course, these processes of statistical learning operate in a social context. Statistical learning processes certainly operate over social input that includes information from social partners (Yu and Ballard 2007). In addition, it is likely that statistical learners take into account the nature of the social context in the inferences that they make (Frank, Goodman, and Tenenbaum 2009; Shafto, Goodman, and Frank 2012; Frank, Tenenbaum, and Fernald 2013). Processes of generalization are also strong candidates for process universals. The nature of these generalization mechanisms is of course highly controversial (for all the reasons discussed above), but every account of learning requires some type of generalization from specific lexical items to syntactic constructions or morphological rules (Tomasello 2003; Yang 2016). In addition, a number of processing factors might lead to processes that are universal. At the same time as children’s language abilities are growing, a variety of core aspects of cognition are undergoing developmental change as well. Children’s general speed of processing is changing (Kail 1991; Frank, Lewis, and MacDonald 2016) – including changes in memory (Ross-sheehy, Oakes, and Luck 2003; Rovee-Collier 1997), attention (Colombo 2001), and executive function (Davidson et al. 2006). Processing factors also influence the speed and efficiency with which children can comprehend words in real time, linking both to developmental change and individual differences that are stable and meaningful and that extend beyond language (Fernald and Marchman 2012; Marchman and Fernald 2008; Marchman and Dale 2017). Although much of the developmental literature on these cognitive constructs focuses either on infancy or the preschool years – because one- and two-year-olds are hard to measure with standard cognitive psychology tasks – the assumption is that these processes are developing continuously throughout the period we focus on here. These developmental changes mean that the processes that we describe are themselves not static but – inasmuch as they draw on these capacities – they are themselves a moving target. Finally, it is important to note that process universals need not be internal to the child. Instead, they may be universals of interaction between children and their caregivers. Such processes could lead to the emergence of specific signatures just as well as processes internal to the learner. To take a concrete example, the timing of turn-taking in conversation is an example of one such proposed interactional universal (Stivers et al. 2009). In particular, it is entirely possible that some of the specific consistencies in the content of children’s early vocabulary (Chapter 8) that we observe in fact emerge from the nature of children’s early environments, including universal features of what children and their caregivers talk about and why. 1.4.3 Alternatives In Chapter 15, we will examine the empirical support for the claim of consistent signatures in language learning across languages. Yet our further claim is that these consistencies are supported by universal processes. To examine whether there is content to the claim of process universals, it is helpful to consider the alternative hypothesis. One important alternative is that the process of language acquisition is specific and particular, rather than universal. Two prominent particulars pull against universal tendencies. The first is the vast semantic and syntactic variation across the world’s languages. For example, as illustrated by Slobin (1996) and others, languages vary dramatically in the ways that they assign semantic content to verbs. If the semantic partition of verbs led to large-scale differences in the timeline or mechanism of acquisition, we might see systematic differences in the predictors of age of acquisition for verbs in these languages, yet we do not. Further, languages are more and less morphologically complex; while the most morphologically-complex, polysynthetic languages are not represented in Wordbank, we do have data from both Mandarin (less complex) and Russian (more complex). If morphosyntax were relatively more or less important in the acquisition of particular languages, we might expect radical differences in the noun bias, the grammar-lexicon correlation, or the predictors of age of acquisition across languages, yet we do not observe these. Of course, there is always room for finer-grained predictions – with more detailed predictive models and better typological coverage, perhaps we will discover such signatures. Our point here is merely that – to the extent that we observe consistencies, neither morphosyntactic nor semantic variability across languages dominates the process of vocabulary acquisition. The second set of language-specific particulars that might lead to variance across languages is the vast cultural variability across the communities represented in the Wordbank data. Our data contain both “individualist” and “collectivist” cultures (Markus and Kitayama 1991; Nisbett et al. 2001) as well as both “loose fit” and “tight fit” cultures (Gelfand et al. 2011). To the extent that parenting differs across these cultures – and there is good evidence that it does (e.g., Bornstein 2013) – we should see variance in the trajectory of language learning. For example, it would be quite reasonable to predict that the female advantage in vocabulary acquisition might vary as a function of cross-national gender biases (Nosek et al. 2009). Yet it is strikingly consistent overall (presaging the conclusions in Chapter 6), again arguing that – at the broadest level, at least – variable cultural factors do not dominate other processes in the acquisition of vocabulary. 1.5 Replication and Theory-Building: Conclusions In this chapter, we have sketched a bit of what we see to be the unique theoretical contributions of work with a much larger dataset than is usual in developmental language acquisition research. In a nutshell, doing this work at scale allows for the identification of sources of variability in the “signatures” of language learning. What these signatures are is a matter for further development – each chapter will describe and motivate the particular signatures that it includes. Further, the consistency of these signatures can provide a motivation for positing process universals that underly the emergence of these signatures (pending the caveats stated above). We return to the general picture of language learning that emerges from our study in Chapter 16. One final note about nature of the theory that emerges from the work we do here. One set of concepts that is subsumed in our interest in consistency is that theory be supported by observations that are reproducible, replicable, and robust (Munafò et al. 2017). A theory of consistencies is, again, a fortiori all of these. If a particular characteristic can be shown again and again across individuals, samples, and languages it is replicable. Indeed, one view of our enterprise is that its impact is fundamentally in the consolidation of knowledge through unifying – replicating – previous work. Crudely put, we have compiled all of the CDI data that we could, and all of the CDI analyses, and executed the cross of analyses and datasets. This project is thus a cross-linguistic replication study. And so, when we state that some phenomenon is consistent across languages, it is by definition replicated – but it is additionally robust to a number of different procedural decisions (such as the design or administrtion of the CDI form) that end up varying widely in our data. Finally, this work is also fully computationally reproducible – the analytic conclusions we draw here based on a set of open data and code that can be rerun to create the figures and tables in the manuscript. This characteristic alone does not guarantee their correctness, but their provenance is known. The research on the nature of inflectional morphology – the “past tense debate” – is one place where computational models played a foundational role in instantiating theoretical claims about innateness and representational structure (e.g., Rumelhart, McClelland, and PDP research group 1986; Pinker and Prince 1988; Plunkett and Marchman 1993, 1991, 1996; Marcus 1995; Marchman 1997).↩ Of course, we also consider the confounds that do remain at the end of the book. In particular, confounding related to the parent report structure of the CDI is a major risk.↩ "],
["intro-practical.html", "2 Practical Foundations4 2.1 Measuring early vocabulary 2.2 The logic of parent report 2.3 Cross-linguistic comparison 2.4 Wordbank", " 2 Practical Foundations4 Almost uniquely in cognitive development, early language learning offers an opportunity to study both consistency and variability in a single phenomenon. Often researchers interested in consistency have measured theoretically-important, carefully-chosen phenomena using small convenience samples that suffice to show a proof-of-concept but do not provide information about variability. In contrast, work on variability between individuals has often focused on larger samples with more reliable tasks, that – perhaps as a consequence of their reliability – are less tightly linked to a particular theoretical construct of interest. And these constructs may depart from the ecological task that is of principal interest (Cronbach and Meehl 1955). Early language is a rare case where these problems are minimized. Measures of early language comprehension and production tend to be face valid and tightly linked to the construct of interest in their structure. And yet, in contrast to the measures that usually fulfill these criteria, early language measures are very closely related to the ecological task – linguistic communication – that is the theoretical target for explanation. Thus, early language is the rare case where consistency and variability can both be explored in a single set of measurements (Bates et al. 1994). Further, the nature and course of early word learning is an important window into children’s growing understanding of the world – beyond language. Early words cross-cut a variety of linguistic categories, but generally consist of names for caregivers (e.g., mama), common objects (e.g., bottle, shoe), social expressions (e.g., bye-bye), and actions or routines (e.g., peekaboo, throw) (Nelson 1973; Tardif et al. 2008). Yet this repertoire expands, and its composition can give insights into the learning mechanisms, biases, and priorities of young children. 2.1 Measuring early vocabulary Traditional studies of language development typically apply a combination of observational assessment and structured tests, frequently relying on short samples of interactions and small samples of children. Discerning both the universal features and natural variation of early lexical development has been greatly facilitated by the development of parent report instruments like the MacArthur-Bates CDI (Fenson et al. 1994, 2007) and the Language Development Survey (LDS; Rescorla 1989). The CDIs in particular were developed across a period of more than 40 years. Originally designed for use in a research study (Bates 1976), the instruments have evolved from a structured face-to-face interview to a paper-and-pencil format and are now increasingly administered online [e.g., the web-cdi project; Kristoffersen et al. (2013) for Norwegian; for Slovak]. While other assessment tools exist for slightly older children, to our knowledge, no other measure allows cost-effective global language assessment for children in the critical age ranges between the emergence of language and the period when children become more able to engage in structured, face-to-face activities (around 30 months). Naturalistic observations are the other leading candidate for measurement of early language, but such observations are extremely costly and time-consuming to transcribe and annotate. These difficulties lead to a tradeoff where most studies either include dense data about a small number of children or smaller amounts of data with a larger sample size. Dense datasets currently provide the best method for in-depth study of the interaction between learning mechanisms and language input in individuals (e.g., Lieven, Salomo, and Tomasello 2009; Roy et al. 2015). The generalizability of these studies is necessarily limited by their small sample sizes, and sample sizes are in turn limited by the costs and practicality of gathering and transcribing such data (see e.g., Bergelson and Aslin 2017 for the state of the art). At the other end of the spectrum, assessment of many individual language samples can yield information about individual variability (e.g., Dickinson and Tabors 2001; Cartmill et al. 2013; Weisleder and Fernald 2013), but at some cost in terms of depth. Further, standardization and avoidance of confounds in naturalistic observation studies is challenging. Although parent report seems at first glance to be much more subject to the biases of individual parents, in fact many of the same confounds arise in other paradigms. For example, should an observation session be during play with the parent or an experimenter? Given that parents vary in their talkativeness during a play session, play with a parent is bound to measure parents’ ability to elicit language as well as children’s variation. But for toddlers tempermental variation is extreme so an experimenter play session may simply be impractical for some children (and language use may be limited by shyness rather than a lack of ability). These difficulties can be navigated through careful procedural and statistical control, but the point of this example is that no observational method offers a perfect solution. Finally, naturalistic observations do not measure children’s language comprehension, a variable of interest for many early language researchers. Estimates of production vocabulary from naturalistic observation are highly correlated with the CDI within studies (e.g., Bornstein and Haynes 1998), but are likely to be affected substantially by length of the session, context, and interlocutor when comparing across studies (see e.g., Hidaka 2015 for discussion). And although there exist methods to extract insights about global vocabulary from naturalistic observation, these statistical extrapolations are relatively new and have not been validated extensively (Hidaka 2015). Experimental testing, in contrast, is an execellent method for measuring individual aspects of children’s linguistic competence, for example their knowledge of a handful of words or their speed of processing (e.g., Bergelson and Swingley 2012; Fernald, Perfors, and Marchman 2006). These methods are much less subject to the confounding of observational methods. But an infant or toddler can only provide a limited number of trials during a single measurement session, even in implicit tasks using eye-movements. Thus, the ability to measure global language competence is limited. Further, the specific words to measure for children of different ages vary – those words that are appropriate for measuring a 14-month-old’s competence are trivially easy for a 24-month-old. And attrition can be quite high for a long measurement session, requiring repeated testing for many participants. Other comprehension vocabulary measures are also available across some range of languages (e.g., the Peabody Picture Vocabulary Test 4; Dunn and Dunn 2007, the Computerized Comprehension Task (CCT), @friend2008), but most of these assessments are tailored for children older than 2 1/2 years. In sum, for breadth, depth, and ease of data gathering, parent report is unmatched. In Chapter 4, we provide a more extensive discussion of issues surrounding the reliability and validity of parent report. 2.2 The logic of parent report Parent-report instruments like the CDI and LDS take advantage of the fact that parents (or other primary caregivers) are expert observers of their child. Parent reports are based on experiences with the child which are not only more extensive than any researcher or clinician can obtain, but are also more representative of the child’s ability. Parents have experience with their child at play, at meals, at bath and bedtime, at tantrums – in short, with the full range of the child’s life and therefore with the full range of language structures used in these contexts. Parents also have opportunities to hear the child interact with other people: other caregivers, grandparents, siblings, and friends. Because responses on these instruments represent an aggregation over much time and many situations, they are less influenced by factors that can mask a child’s true ability in the laboratory or clinic, such as shyness or compliance, or that can impact the validity of naturalistic sampling, such as word frequency. As Bates, Bretherton, and Snyder (1991) point out, “parental report is likely to reflect what a child knows, whereas [a sample of] free speech reflects those forms that she is more likely to use.” (p. 57). Because of its format, parent report enables the collection of data from far larger samples of children than would be possible with standardized tests or naturalistic observation. Information from more adequate samples, especially in the form of norms, can benefit both clinical practice and research. Fenson et al. (1994), for example, used the norming data from English versions of the CDIs - a sample of 2,550 children aged 8 to 30 months - to address questions about variability in communicative development. Large samples are especially needed to provide an accurate statistical description of extreme scores, i.e., what score corresponds to the 10th percentile? What does the most advanced child (e.g., &gt; 90th percentile) look like at a given age? Research on questions such as environmental influences on language development can also benefit from large samples. Correlational research is hampered by the problem of multicollinearity: The predictor variables such as parental education, number of books in the home, family size, use of questions vs. imperatives, are likely to be intercorrelated, making it difficult to separate the effects of each of them individually. Large samples in which there is a substantial amount of non-overlapping variance are essential for addressing these questions. The main core of the CDIs is the vocabulary checklist. This list is essentially a “bag of words” which represents the set of words that best capture variation in lexical development across the full spectrum of child ages and abilities. Parents choose the words they believe that their child can currently “understand” (comprehension, measured for younger children) or “understand and say” (production, measured for both younger and older children). A child’s score on a vocabulary checklist represents their comprehension or production “vocabulary size,” indexing that child’s relative status against other children assessed with the same list. In their English and Spanish instantiations, the vocabulary checklists come in two versions: Words &amp; Gestures (W&amp;G) (8–18 months) which contains about 400 words, and the Words &amp; Sentences (W&amp;S) (16–30 months), which contains about 700 words. This structure has often been replicated across cross-linguistic adaptations, though there is some variation in form construction (see below), and some forms include substantially different numbers of words or include/exclude other measures. The vocabulary checklists contain words from many different semantic (e.g., animal names, household items) and syntactic (e.g., action words, connectives) categories, resulting in broader samples of lexical knowledge than are available from other methods. Importantly, however, these words are not chosen to create a complete list of all words understood or produced by a child. Instead, CDI word lists are constructed to include a set of words that most children will know as well as a sampling of intermediate and more difficult words that will be useful in assessing variability between children. (We discuss the issue of “total vocabulary” further in Appendix E.) Thus, an additional advantage of the parent-report method is that parents can report on many different sub-components and correlates of early vocabulary development. In particular, the CDI instruments ask about use of communicative gestures, grammar, and symbolic play, as well as vocabulary comprehension and production. Information about what early vocabulary development correlates with, and what it does not, can yield important theoretical information about the common mechanisms underlying learning. As Bates, Bretherton, and Snyder (1991) note, studies which have the power and scope to examine what “hangs together” across early language development can provide critical clues to how the system is put together in the first place (p. 7). Of course, parent report has substantial limitations that can lead to both measurement error and bias. These are addressed to some extent by design features of the CDI, and further addressed by evidence for the reliability and validity of the instrument. Because these concerns are so central to our enterprise here, we discuss these issues at length in Chapter 4 both from theoretical and analytic points of view. 2.3 Cross-linguistic comparison 2.3.1 Adaptation, not translation! Originally designed for English, parallel CDI instruments have now been adapted for more than 100 languages (http://mb-cdi.stanford.edu/adaptations.html), with data from 29 of those languages currently available in Wordbank (Dale and Penfold n.d.). The ethic behind the development of these instruments is “adaptation, not translation” – in other words, create forms with the same spirit as the English form, but do not simply translate the items (Dale n.d.). Instead, developers have been strongly encouraged to craft instruments that reflect the linguistic and cultural contexts that influence the early acquisition of vocabulary and other aspects of language in that particular language. The resulting forms vary widely, including differences in length and intended age range. Some forms include hundreds of items more than the original 680 words on the English Words &amp; Sentences form; others are so-called “short forms” and include only a hundred or a few hundred carefully selected words. Some are designed to capture development from the emergence of language through ages 3–4 years, while others are focused on very early development (like the English Words &amp; Gestures form, designed for ages 8–18 months). While many words on the English-language checklist may easily translate to other languages, others will simply not be relevant within the same developmental time frame for children learning that new language, e.g., cheese in Japanese or snow in Arabic. Conversely, additional words may be needed in the new language which were not included on the English-language vocabulary checklist, e.g., tortilla in Mexican Spanish. In all languages, though, the vocabulary checklists include words that appear earlier and later in normal development, as well as a similar proportion of words from different lexical classes, for example, nouns, verbs, adjectives, and so on. Taken individually then, each adapted instrument captures key trends in vocabulary development aggregated across all items on the respective checklists. Further, due to variation in language structure and the interests of the developers of CDI adaptations, the CDI instruments vary in structure across languages. Most adaptations of the W&amp;G generally include gestures as well as vocabulary comprehension and production, however, it is not always the case. Further, while adaptations of the W&amp;S always include vocabulary production, not all instruments also contain some measures of grammar, for example, early use of closed-class morphology or combinatorial syntax. Note that linguistic differences render the structure and format of many parts of the grammar sections to be very different, and hence, not amenable to comparisons across languages. A few instruments included in our dataset are pure checklists, with no other sections included. In sum, CDIs are a useful tool for many languages, but the forms differ between languages. 2.3.2 Our approach The wide cross-linguistic adoption of the CDI provides an opportunity for cross-linguistic comparison but it also creates many challenges that are not present in datasets that are designed from the start for such comparions. Differences in instruments and items as well as differences in samples and administration conditions all make it potentially quite problematic to compare scores and score distributions across forms. We discuss differences in instruments and items here and defer discussion of differences in samples and administration to Chapter 3. Obviously differences in length between CDI forms mean that comparisons of raw scores across instruments are inappropriate. Dividing raw scores by the total number of items on a form results in proportions, which are somewhat more comparable but still potentially misleading. A more comprehensive form with more items on it will yield lower proportions for children with the same vocabulary size. Despite this weakness, we typically use proportions for visualizing differences across forms as it is cumbersome to compare raw scores with different totals. More discussion of absolute and relative vocabulary size differences between instruments can be found in Chapter 5. Like other psychometric instruments, CDI instruments can also be normed, and many of the most popular forms are. In the standard norming process, the form is administered to a large typically-developing sample so that percentile ranks can be computed. For new administrations, the percentile of a particular raw score can be computed and used in place of the proportions or raw scores. These percentile ranks can be useful for clinical purposes, but they also complicate comparison across instruments because of potential differences in the norming population to begin with. In addition, the Wordbank dataset includes normed and un-normed forms, and for the normed forms, we sometimes have access to both the norming dataset and other data but sometimes only have access to the norming data. For these reasons, we do not employ normative percentile ranks in our analyses. As the preceding discussion shows, there are serious difficulties that crop up immediately in comparisons across instruments. We will grapple with these difficulties throughout the book, but we generally adopt two approaches that help us navigate this complexity. The first approach, which is used in the majority of chapters, we describe below. The second approach is described in the next subsection. In general, our approach to cross-linguistic and cross-instrument data is to provide standardized analyses within each instrument and language, without assuming equivalence across words, instruments, or populations. Thus, we will typically investigate a particular phenomenon (say the “noun bias” or the “female advantage”) independently and in parallel for each of the instruments available to us.5 We can then – still with caution – analyze and compare the magnitude of this phenomenon across languages, having abstracted away from the specifics of each particular instrument. We sometimes colloquially refer to this approach as “every form an island,” meaning that each instrument is analyzed separately and only the analytic results at the highest level are compared. Cross-linguistic conceptual comparisons are fraught, both philosophically (e.g., Quine 1960) and practically. We refer to the practical issue as the tortilla problem: in American English, we have the word bread, which translates to pan in Mexican Spanish. But the Spanish word tortilla takes some of the cultural role of bread in English; bread has two reasonable translations. These translation issues go the other way as well: reloj translates to two distinct words (clock and watch) in English. For this reason, we typically adopt the “every form an island” approach described above. But questions nevertheless arise in the course of analyzing CDI data that can only be answered by comparison across languages (see e.g., Chapter 10). Thus, in order to facilitate (cautious) cross-linguistic comparison, we developed a set of rough-and-ready translation equivalents. We call these “unilemmas” (short for “universal lemmas”). A “lemma” is a canonical form of a word, typically used for gathering frequency counts across different morphological variants (e.g., walk is the lemma for walks, walked, and walking). Unilemmas are used for mapping distinct lexical forms across languages. Unilemmas enable a number of desirable analyses, but more practically, they also provide consistent glosses that make it easier for researchers to work in languages with which they are not familiar. For convenience, our unilemmas are written in English, but they could of course have been written in any other language as well. Further details on the unilemmas are given in Chapter 3. Even with the care we used here to construct a robust set translation equivalents, individual items are likely to only be roughly equivalent cross-linguistically, and may have significantly different referential scopes for children learning the different languages. That is, if a parent indicates that a child can produce the word dog in English and another parent indicates the translation equivalent in, for example, Spanish (perro), it may nevertheless be the case that these words are heard more or less frequently and in different contexts in the two languages. An important empirical question is the degree to which translation equivalents across languages have consistent developmental profiles. 2.4 Wordbank To take advantage of the opportunity posed by the broad use of CDI instruments in the child language community, in 2014 we began constructing Wordbank, an open repository for CDI data that allows for interactive analysis and visualization. Our inspiration for Wordbank came from two successful projects for sharing data on children’s language acquisition. The first is the Child Language Data Exchange System (CHILDES; MacWhinney 2000). A database of transcripts of children’s speech and speech to children, CHILDES has grown into a robust and important tool for the community, with many contributors and affiliated projects. The second is the Cross-Linguistic Lexical Norms site (CLEX; Jørgensen et al. 2010), which is closer in content to Wordbank, and effectively our precursor. CLEX archived normative data from a range of CDI adaptations across languages, allowing browsing of acquisition trajectories for individual items or age groups. Wordbank initially built on CLEX, offering the same functionality but allowing flexible and interactive visualization and analysis, as well as direct database access and data download. In addition, Wordbank’s goal was always to extend beyond normative data by dynamically incorporating data from many different researchers and projects of varying sizes and scopes. While the resulting datasets in Wordbank are much more heterogeneous than if they were just based on norming samples alone, they are also larger and more representative than the individual norming datasets (in some cases), and available in languages where no norms exist (for others). From the perspective of the study of child language, there are a number of notable omissions from the datasets represented in Wordbank and the analyses reported in this book. We discuss three of these below: our focus on typical development, monolinguals, and (for the most part) WEIRD populations. First, our analyses here focus exclusively on typical development. The study of atypical language development is an important part of characterizing the mechansims of acquisition; further, characterizing language development in these circumstances can have important applied benefits. Studies of language in developmental disorders (Tager-Flusberg et al. 2009; Eigsti et al. 2011), in cases of sensory deficits (Landau, Gleitman, and Landau 2009), and in cases of abnormal input (Curtiss 1977), among others. Many of these studies have made use of dense observations of individual children, however, an approach that is fundamentally different than our large-scale, statistical approach here. While CDI-type instruments are increasinly being used with atypical populations (e.g., Charman et al. 2003; Luyster, Lopez, and Lord 2007), in practice these datasets still tend to be smaller, concentrated in on English-speaking children, and difficult to access publicly. Thus, Wordbank does not currently archive stufficient data from atypical populations to justify inclusion of these analyses in the current book. Second, the Wordbank dataset focuses on monolingual acqusition. CDI instruments were initially developed to provide normative measurements of variation within a single language. Since then, however, they have increasingly been used for comparison between monolingual and bilingual groups based on the administration of CDIs in both languages (e.g., Pearson, Fernandez, and Oller 1993; Hoff et al. 2012). These studies initially focused on specific bilingual populations (e.g., Spanish/English bilinguals). Recent studies have moved beyond this strategy and have begun to examine general trends aross multiple bilingual pairings (e.g., Bilson et al. 2015; Floccia et al. 2018). Questions of bilingual acquisition are fascinating and important from both a theoretical and practical perspective. But there are practical obstacles to applying our approach to bilingual data that mean that this book does not consider the bilingual acquisition situation. First, because most of the largest CDI datasets were generated from monolingual norming studies, the vast majority of our data are not bilingual. Second, the combinatorics of bilingualism mean that data on nearly all language pairs will be non-existant. For these reasons, our book focuses on monolingual acquisition, though we recognize this as a limitation that must be addressed by future work. Finally, the sample of languages we include is limited by our access to data. We have made efforts to include any large CDI datasets whose existence we are aware of – including extensive outreach to CDI authors, professional networking through the CDI board. Despite these efforts, our dataset is limited by both the sample of languages in which such studies have been conducted and international attitudes towards datasharing. Thus, although we do cover many languages around the world (see 3 for a map), these languages are skewed towards Europe and the United States, as well as towards WEIRD – western, educated, rich, industrialized, and democratic – populations (Henrich, Heine, and Norenzayan 2010). While there are inherent limitations in comparing different instruments across languages – limitations that we return to again and again throughout the book – our dataset is the first that allows the exploration of both child- and item-level data within- and across such a large and diverse set of languages. As such, the availability of these adaptations remain at the core of the analyses that we offer within Wordbank. We began the Wordbank project – our first large-scale, data-aggregation project – with a relatively naive attitude. We thought “if you build it, they will come”: that contributors would flock to the opportunity to share their data with the world. We were unprepared for the challenges of contacting academics around the world, asking them to volunteer their time and hard-won data to an unknown cause, and then understanding the myriad formats and conventions represented in the data we eventually received. For the first couple of years, our data were largely co-extensive with those gathered by CLEX. Fortunately, in the years since the Wordbank project began, attitudes towards data sharing have been shifting rapidly (in part as a result of work on replication and reproducibility, e.g. Collaboration and others 2015). In addition, the credibility of the Wordbank project has gradually grown, in part due to the support of the MacArthur-Bates CDI advisory board. And as we received successively more data, our expertise in dealing with heterogeneous datasets has grown. Thus, the dataset has grown quickly in recent years. We hope that in future, authors see contribution to Wordbank as an aspirational endpoint for future studies using CDI instruments. Some material in this chapter comes from M. C. Frank et al. (2016) and Marchman and Dale (2017).↩ An exception to this approach is that we do sometimes interpolate words’ trajectories across matched instruments for the same language, e.g. the proportion of children who say the word “cat” on both Words and Gestures and Words and Sentences forms for American English; see Appendix C.↩ "],
["methods.html", "3 Methods and Data6 3.1 Database 3.2 Datasets", " 3 Methods and Data6 We begin by introducing the structure of our dataset and the database that contains it. In the second section, we give some descriptive information on the datasets included in the database. 3.1 Database Why use a database to store vocabulary data? Consider the standard format of raw CDI data. Here is a small slice of the original CDI norming data (Fenson et al. 1994, 2007). Each row is a child, each column gives a variable – either a demographic variable or the result of a particular word being administered to a particular child. Although this format is useful for homogeneous administrations of a single instrument, it cannot accommodate multiple instruments, multiple languages, or datasets with different sources or kinds of demographic information. Consolidating data across different instruments is very difficult in this format, and tracking data on children with multiple longitudinal administrations of a single instrument must also be done in an ad-hoc manner. The move to a database format allows far more flexible and programmatic handling of heterogeneous data structures from different sources. Further, as information about particular entities becomes available – for example, cross-linguistic mappings of lexical items – this information can be added in a way that preserves previous analyses. In a tabular format, such functionality is not guaranteed, and changes to the structure of the dataset will necessarily break previous analyses. A database, especially when supplemented with an appropriate application programming interface (API, see below), can solve this problem elegantly. 3.1.1 Database Architecture A relational database such as Wordbank is at its heart an ontology: a set of entities that are described in a series of tables linked by unique identifiers. The primary entities in the Wordbank database are: Instrument: A specific parent-report survey or questionnaire with a particular set of items. For example, the American English Words and Sentences form is an individual instrument. Item: A particular question on an instrument. A specific word like dog is our canonical CDI item, but other items include questions about gestures, morphological and syntactic complexity, and other aspects of early language or behavior. Administration: A particular instance of an instrument being given to a child, with an associated child age and source (the contributing lab). Child: A unique individual, with associated demographics. Language: A particular language or language community for which a CDI instrument has been adapted. Note that this definition of language distinguishes e.g. American and British English. These entities are related by two primary groups of tables in Wordbank. The common tables store data that is shared between CDI instruments, including information about administrations (individual instances of a form being filled out for a child), and items (words and other questions on a form). Then the instrument tables store the item-by-item response data for particular CDI instruments. We currently include all items on CDI instruments, including questions about communication, gesture, morphology, and grammar (though in quite a few of the datasets that we archive these non-vocabulary questions have not been digitized so data on these are sparse at present; see e.g., Chapters 7 and 13). Wordbank is designed so that it can accommodate data from a wide variety of instruments, both within and across languages. Indeed, at the time of rendering, the site includes data from more than 82055 administrations of the CDI across 29 different languages and 56 different instruments. 3.1.2 Implementation Wordbank is constructed using free, open-source tools. The database is a standard MySQL database, managed using Python and Django.All code for Wordbank is hosted in GitHub repositories, with the primary site repository containing data and database code, the r package repository containing code for the API, and the book repository containing the code and text for this manuscript. All data uploaded to Wordbank are open and freely available for download, both through the site itself and through the GitHub repository. The site includes only de-identified data that cannot be linked to individual parents and children under US Department of Health and Human Services’ “Safe Harbor” standard. Because of these features, the Stanford Institutional Review Board has determined that the Wordbank project does not constitute human subjects research. 3.1.3 The wordbankr API An application programming interface (API) is a set of abstractions that allow applications to interact with a resource (e.g., a set of data like Wordbank) through consistent abstractions. Although in principle it is possible to construct raw SQL queries to Wordbank, in practice all access is through an R API that constructs individual SQL calls. This API is distributed to R users through the wordbankr package, which is available through the Comprehensive R Network (CRAN). We developed this package, wordbankr, to provide a simple and flexible API for the Wordbank dataset (M. C. Frank et al. 2016), and our current book depends on it heavily. The package provides a consistent set of function calls for retrieving data from the underlying database, for example get_instruments or get_administrations to retrieve all or subsections of these tables, respectively. We do not describe the package in depth here, since it is described in our previous paper and in its online documentation 3.1.4 “Unilemmas”: cross-linguistic conceptual mappings As described in Chapter 2, it is sometimes useful to (cautiously) compare the developmental trajectory for a single concept across multiple languages. To facilitate these comparisons, we created “unilemmas,” cross-linguistic mappings from lexical items to single (English) forms that stand for a particular conceptual abstraction. Some lexical items are represented on only one or a handful of instruments, but there are many that are common across a large number of instruments, leading to an opportunity for cross-linguistic comparison. Unilemmas were created for particular instruments by following a two-step procedure. First, using a pool of English unilemmas, we proposed candidate mappings for each lexical item on a form. This first step was often accomplished by a non-native speaker using translation resources and the context of the form (e.g., that an item occurs in the “animal sounds” section). Second, we recruited a linguistically-sophisticated native speaker of the language (often a psychologist or linguist), provided them with the candidate unilemma list, and asked them to review this list item by item and suggest corrections and amendments.7 Not every instrument has unilemma mappings, but they are currently available for FIXME forms in FIXME languages. 3.1.5 A note on age Developmental psychologists are very fond of using temporal units like months and years as rough guides. Children tend to begin to crawl between 5 and 8 months, and say their first word around one year. This practice is fine for rules of thumb, but we also use these units for measurement as though they were precise (e.g., “infants with ages between 7;0 and 8;0”) when in fact such infants will vary in the number of days since their birth depending on facts like whether their seven months of life encompassed February or not. A similar problem is true of years as a scientific unit – because of leap years, years technically include 365.2524 days — though the magnitude of the imprecision is smaller. Despite these issues, months are the currency of language development research, and we often receive contributed datasets with months as the only measure of age. In Wordbank, we define a standardized month as 365.2524 / 12 = 30.4377 days. When possible, we compute the number of days from birth to testing and then compute the number of standardized months that the child has lived. If this is not possible, we use months as reported in the dataset. We define an eight-month-old (age == 8) as a child who has lived between 8 and 9 standard months: their age is in the range [8 - 9) standard months. (The alternative definition, from 7;16 – 8;15, is sometimes used in infancy research but is in our opinion less intuitive.) 3.2 Datasets This section gives a broad overview of the data we have available. Unlike projects in which data are collected by the organizers, in our work here, we rely on the kindness of others in contributing data that are often years or decades old. Some datasets come via an email containing well-curated tabular data; others were contributed in more idiosyncratic formats or even on paper. One dataset was even retrieved by one of us from a doorstep several hours drive away, in the form of a paper bag full of old paper forms. Thus, the amount and type of meta-data available for some datasets is limited. For example, we have limited demographic information for some datasets and only vocabulary – not complexity or gesture – items for others. In many cases we do not have full details of instructions and administration for a particular dataset. This section gives an overview of data availability and some demographic comparisons of the samples. Specifics of each dataset – to the extent that they are available – are given in Appendix A. 3.2.1 Data Provenance As mentioned above, datasets come from a variety of sources. In all cases, the preferred citation for each dataset and its contributor is given on the Wordbank contributors page. Several of these datasets were transferred second-hand from a pre-existing database (CLEX-CDI; Jørgensen et al. 2010), while many of the others were contributed directly via electronic or paper forms. In the case of paper forms, we re-keyed the forms using double-entry methods (either ourselves or via a commercial contractor).8 Each of these datasets is then imported to the database by creating a custom import key that matches individual columns of the dataset to particular database fields (e.g., item types like words or gestures, or standardized demographic fields). These mappings are preserved along with the raw data so that they can be re-checked later. 3.2.2 Overview of the data Wordbank currently contains data from 29 language communities. Many of these are from instruments in the original Words &amp; Gestures (infant) / Words &amp; Sentences (toddler) format, with around 400 items in WG and 700 in the WS. Typically, WG forms are intended for children from 8–18 months and WS forms are intended for children 16–30 months, but these ranges are flexible. Some WS forms are used up to 36 months or extended as low as 12 months (in cases where a single form is considered desirable by the researchers constructing the adaptation). This table gives an overview of the available instruments in the dataset. Wordbank also includes some other forms that do not fit into this schema, including short forms and vocabulary questionnaires. Some of these are “short forms” with no internal category structure and fewer items overall, and these are excluded from many item and category analyses. But others have many structural features of WS and WG forms. For example, the Oxford CDI is a WG-style form with comprehension as well as production estimates, but applied to a larger age-range. The Mandarin Infant Checklist (IC) and Toddler Checklist (TC) are checklist forms without grammatical and gesture items but with structured sets of vocabulary items. We include these forms in analyses where WS and WG data are included. The number of administrations available is highly variable across instruments and languages, however. The log-scaled plot above shows the distribution of administrations across forms and languages. These instruments have global reach, although the maximal number cover North America and Western Europe. African, South American, and South/South-East Asian languages are notably under-represented. 3.2.3 Administration details Data in the dataset were gathered between the beginning of the first CDI norming study in 1990 and the present, with the majority of datasets gathered within the 10–15 years prior to the writing of this book. The details of administration vary widely from dataset to dataset. Though we have different levels of knowledge regarding the exact details of administration, we know that the three most common circumstances of administration (in no particular order) are: On paper in a lab or other space, with instructions given in person by a researcher (e.g., Fenson et al. 1994); On paper, with the form sent by mail with written or telephone instructions from a researcher (e.g., the British English Twins Early Development data, which were sent home as part of a packet; Dale et al. 2003); or Electronically, with instructions given either electronically or by phone (e.g., Kristoffersen et al. 2013). We have limited direct evidence about the effects of particular administration details on the overall results. Such evidence would require random assignment of parents to administration method rather than, e.g., a comparison of administration methods across different populations in which there are obvious sample-related confounds. Nevertheless, the CDI community has amassed a substantial set of anecdotal experiences. For example, improper administration or limited instructions can result in over- or under-reporting, especially with respect to comprehension (see e.g., Feldman et al. 2000). In one trial we conducted using electronic administration, we found that basic written instructions were misinterpreted by some proportion of parents (as evinced by an atypical number of floor and ceiling responses). This proportion appeared to decrease when we made an attempt to simplify and illustrate the instructions that we gave. Such experiences suggest – congruent with the general warnings above – that caution is warranted in interpreting absolute comparisons between different populations where there are also differences in administration style. 3.2.4 Demographic details In addition to differences in administration and form, samples from different studies also differ in myriad other ways. The most important of these, especially cultural differences between language communities, are extremely hard to quantify. But we can make a first stab at investigating some similarities and differences between the convenience samples from different studies by comparing demographics where they are available. Sex proportions tend to be quite close to .5, with a few exceptions for small datasets. Several WG datasets (e.g., British Sign Language, Russian, Italian, Quebec French) have more males than would be expected by chance. This pattern is important because (as we will investigate in Chapter 6), there are systematic differences in vocabulary size between boys and girls, and so sample differences in gender will lead to absolute differences in mean vocabulary size. Although we have maternal education data for far fewer datasets, there are also substantial differences between datasets on this variable (we will also return to this issue again in Chapter 6). Analyses of this variable are complicated by different reporting formats, so for example the German and Mexican Spanish datasets have no separate categorization for graduate education. That said, even for datasets with the most fine-grained maternal education breakdown, we see substantial differences. Finally, when we examine birth order, we also see differences in the proportion of children who are first- vs. later-born. The majority of the German sample is first-born, while the Czech sample has many more second children, for example. In summary, our samples differ substantially in their demographic makeup. Presumably these differences are due both to the composition of the societies being sampled as well as the sampling procedure the researchers used. 3.2.5 Longitudinal vs. cross-sectional data The strongest developmental inferences can be made by the examination of longitudinal data, in which children’s individual development is measured multiple times using the same instrument. Unfortunately, relatively little of our CDI data comes from this type of repeated administration. The figure above shows the number of administrations for particular languages that come from longitudinal datasets with a particular depth. There is a substantial amount of two-administration longitudinal data for several languages, but only a few have more than two observations for an individual child. In general, this aspect of our data is a consequence of the fact that, for normative datasets, pure cross-sectional data collection is used to ensure statistical independence between datapoints. Thus, we must typically settle for using the large amount of available cross-sectional data to average out individual variability. We do use the more extensive Norwegian and English longitudinal data in Chapter 14, however. 3.2.6 Conclusions The strength of the Wordbank framework is that it allow access to CDI data in a consistent format, such that analyses can be applied uniformly. Yet we must not allow this ease to blind us to the difficulties of comparing across measurements that are gathered using different forms, under different administration conditions, and from convenience samples in different countries and cultures using different sampling schemes. Each of these differences has the potential to complicate cross-linguistic comparisons. We will return to each throughout the book. Some material in this chapter is adapted from M. C. Frank et al. (2016).↩ The specific direction they were given was: “We’re looking for the best English translation of these words. These are words that are among the first words that children learn, so your translation should be closest to the meaning of the word as it would be used by a young child (say, under 3 years old). For cases when there are two equally good English words, put both. If you don’t think there is a good translation into a reasonable English word that a kid might know, you can leave the alternative translation blank.”↩ In a check for errors in the re-keying of one Korean dataset, we found that there were 4 incorrect fields in 10 full records for an error rate of ~0.06%.↩ "],
["psychometrics.html", "4 Measurement Properties of the CDI 4.1 Strengths and limitations of parent report 4.2 Longitudinal stability of CDI measurements 4.3 Psychometric modeling 4.4 Conclusions", " 4 Measurement Properties of the CDI Many researchers are initially shocked to hear that one of the most important methods for studying child language is parent report. Yet, as we argued in Chapter 2, alternative methods like naturalistic observation or lab experiments can be biased, and are quite costly to revisit at scale. Thus, the goal of this chapter is to revisit the strengths and weaknesses of parent report in depth, since the remainder of our manuscript depends on the use of CDI data. Broadly speaking, we would like to provide evidence for the reliability and validity of the CDI. Many studies provide evidence for reliability in the form of concurrent and longitudinal correlations between CDI scores and validity in the form of correlations between the CDI and other language measures; some of the most prominent of these studies are cited below and others are reviewed in Fenson et al. (2007). Here we address some issues that have received a little less attention: in the first part, we discuss the limitations of the CDI (and the design features that address these limitations); in the second part, we use longitudinal data to examine the test-retest reliability of the CDI; and in the third part, we present evidence for the measurement properties of the CDI (including comprehension questions) from a psychometric perspective. 4.1 Strengths and limitations of parent report Although the standardization of parent reports using the CDI contributes to the availability of large amounts of data in a comparable format, there are significant limitations to the parent report methodology that are important to understand (Tomasello and Mervis 1994; Feldman et al. 2000). To do so, it is useful to reflect on what it means when a parent reports that their child “understands” or “understands and says” a word. In an ideal world, the parent’s responses would be an unbiased reflection of their observations of their child’s language development. For example, when asked if their child produces the word ball, a parent is likely recalling situations in which their child has used the word ball correctly, and then reporting on the success or failure of this process of recollection. Of course, this judgment clearly depends on the parent’s ability to accurately judge that the child intended to say the word ball, that the child’s target word form was ball, and that the child has some meaning for the word form ball that at least approximates the expected meaning. There are also a number of other sources of information that the parent might bring to bear on these judgments. Figure 4.1: The intuitive structure of parent report. The figure shows a sketch of the process of parent report. For each word on the CDI, the parent is asked to report whether their child has produced or comprehended the word. This report could depend on direct recall of a particular case when their child actually produced or showed comprehension. But in addition to these factors, parents probably draw on their general assessment of the difficulty of the word and on their overall assessment of the child’s linguistic abilities. As even this simple sketch shows, parent report judgments are based on a fairly complex set of factors. And hence there are legitimate concerns about the ability of parents to provide detailed and specific knowledge about their children’s language. We discuss specific concerns below. First, parents may be biased observers generally. Most parents do not have specialized training in language development, and may not be sensitive to subtle aspects of language structure and use. Further, a natural pride in the child and a failure to critically test their impressions may cause parents to overestimate the child’s ability; conversely, frustration in the case of delayed language may lead to underestimates. Parent report is most likely to be accurate under three general conditions: (1) when assessment is limited to current behaviors, (2) when assessment is focused on emergent behaviors, and (3) when a primarily recognition format is used. Each of these conditions acts to reduce demands on the respondent’s memory. For example, parents are better able to choose from a list of items that are likely candidates, rather than requiring that the parents generate the list themselves. In addition, parents are likely to be better able to report on their child’s language at the present time than at times past and when their child is actively learning the particular words on the list (e.g., names for animals). Second, parent reports likely suffer from a number of biases that interact with sub-portions of the forms and the ages of the target children. For example, it is likely that parents may have more difficulty reporting on children’s comprehension or production of function words (e.g., so, then, if) than content words (e.g., baby, house)–relying more on their estimates of the words general difficulty. We return to this question below in our psychometric analyses. Moreover, in typically-developing samples, parents can track their child’s receptive vocabulary to about 16-18 months, after which it is too large to monitor. Expressive vocabulary can be monitored until about 2.5 - 3 years, after which the number of words a child can say becomes too large. Different instrument developers make different choices about the ceiling of CDI-type forms but relatively few have considered CDI-type parent report for measuring older children’s vocabularies (but cf. Libertus et al. 2015). The CDI instruments capitalize on the greater ease of recognition, as contrasted with free recall, to help offset these memory limitations. That is, it is better to ask parents to report on their child’s vocabulary by selecting words from a list of possible words rather than having them write down all the words they can recall hearing their child use (or, even worse, asking the global question “Does your child know at least 50 words?” that is so commonly used in pediatric assessments). In addition, asking parents to reflect on their child’s language abilities may be particularly difficult for early vocabulary and especially for early comprehension. As Tomasello and Mervis (1994) point out, for the youngest children, especially 8 - 10 month olds, vocabulary comprehension scores can be surprisingly high, possibly reflecting a lack of clarity in what the term “understands” means for parents of children at this young age. On the other hand, more recent evidence has suggested that children in this age range do plausibly have some comprehension skill even if it is somewhat fragmentary (Tincoff and Jusczyk 1999, 2012; Bergelson and Swingley 2012, 2013, 2015). Thus, the degree to which very early comprehension reports are artifactual – or were actually ahead of the research literature – is unknown. (Resolving this question will require detailed studies of the correspondence between parent reports and experimental data for individual children). Below we assess some of the measurement properties of comprehension items, but we are unable to resolve the issue fully. One study that bears on the earliest production data is Schneider, Yurovsky, and Frank (2015), who compiled a number of sources of data on children’s first words. Surprisingly, they found relatively few differences for the age and topic distribution of this very salient milestone across datasets collected via a number of different methods, including concurrent (CDI) and retrospective report. The age at which a first word was reported was also relatively similar between CDI data and the concurrent diary reports of a sample of psycholinguists (though some CDI data appeared to be shifted a little bit earlier such that more parents were reporting first words in the 7-9 month period). Third, there is some evidence that variability in reporting biases may be moderated by factors such as SES (Feldman et al. 2000, 2005; Fenson et al. 2000). Some studies suggest that parents from some SES groups may be more likely to underestimate child’s abilities (Roberts, Burchinal, and Durham 1999), while others report that parents from lower-SES groups may over-estimate children’s abilities, especially comprehension at younger ages [Goldfield and Reznick (1990); Feldman et al. (2000)). Later studies, however, have shown that for children over 2 years patterns of validity were consistent in lower and higher-SES groups (Feldman et al. 2005; Reese and Read 2000). Thus, SES-differences could reflect valid delays in children’s language development that parallel those obtained with different methods, such as naturalistic observation or standardized tests (e.g., Hammer, Farkas, and Maczuga 2010). Fourth, as discussed in Chapter 2, the items on the original CDI instruments were chosen to be a representative sample of vocabulary for the appropriate age and language (Fenson et al. 1994). The checklists contain some words that most, including the youngest, children are able to understand or produce, some words that are understood or produced by the “average” child, and some which only children who are relatively more advanced will understand or produce. This structure ensures that the list has the psychometric property of capturing individual differences in vocabulary both across younger and older children and across children of different developmental levels. Validity of the CDIs has been demonstrated in reference to both standardized tests and naturalistic language sampling (see Chapter 4 of Fenson et al. (2007)). But the checklists were not originally constructed with the intention that responses on individual items would be reliable. While item-level responses provide useful information about patterns of words that children are likely to understand or produce, responses on the vocabulary checklist do not necessarily license the conclusion that a child would respond appropriately when asked “can you say ____?” by an experimenter in a confrontation naming task. Nonetheless, if parents’ observations at the item level reflect any signal – even in the context of significant influence from other factors – then this signal should be observable by aggregating together data from many children. Thus, the item-level analyses we present in Chapter 10 (for example) are not predicated on an assumption of high item-level reliability for individual children. Fifth, while the lengths of the vocabulary checklists on the CDIs may give the impression that they yield an estimate of the child’s full vocabulary, in fact the vocabulary size estimates only reflect a child’s relative standing compared to other children assessed with the same list of words (see Mayor and Plunkett 2011 for discussion). Such estimates should not be misconstrued as a comprehensive estimate of the child’s vocabulary knowledge, as CDI scores likely understate the size of a child’s “true” vocabulary substantially, especially for older children. Sixth, when a parent reports on a word on the vocabulary checklist, there is no information about the actual form of the word used, and hence, these vocabulary estimates can say little about phonological development (e.g. segmental v. suprasegmental approaches to the analysis of speech). Parents are instructed that they should check that a child can produce a word even if it is pronounced in the child’s “special way,” and only approximates the adult form. Thus, throughout this book we refrain from analyzing the phonological forms of words reported on CDI instruments (with the exception of Chapter 10, in which we use word length as a predictor of production). Finally, we also gain little information about the frequency with which children use a particular word in their spontaneous speech, nor can we know the range of contexts in which individual lexical items are used (e.g., is that word used productively vs. in a memorized chunk of speech). Thus, the vocabulary size that is captured by the CDIs reflects the number of different word types (not tokens) that the child is able to understand or produce, with little information about nuances in meaning that might be reflected in actual usage. In sum, despite these limitations, when used appropriately, the CDI instruments yield reliable and valid estimates of total vocabulary size. Because the instruments were designed to minimize bias by targeting current behaviors and asking parents about highly salient features of their child’s abilities, they have proven to be an important tool in the field. Dozens of studies demonstrate concurrent and predictive relations with naturalistic and observational measures, in both typically-developing and at-risk populations (e.g., Dale and Fenson 1996; Thal et al. 1999; Marchman and Martínez-Sussmann 2002). In addition, a variety of recent work has shown that individual item-level responses can yield exciting new insights, for example about the growth patterns of semantic networks when aggregated across children (Hills et al. 2009, 2010). Such analyses have the potential to be even more powerful when applied to larger samples and across languages. 4.2 Longitudinal stability of CDI measurements The first question that we address here is with regards to the longitudinal stability of CDI reports. A classic test of the reliability of a psychometric instrument is its test-retest correlation. Assessing this correlation for CDIs for a single reporter is a bit impractical however, since – unlike e.g., a math test with objective answers and different question forms – this procedure would involve asking a caregiver to fill out the exact same survey twice in a row, and presumably they would remember many of their answers. An alternative possibility would be to measure the same child via multiple caregivers. This procedure was followed by De Houwer, Bornstein, and Leach (2005), who found that caregivers varied substantially from one another in their responding; but plausibly this is due not only to parent bias but also to the different contexts in which caregivers interact with children (e.g., one caregiver takes the child to the zoo more often, another plays kitchen at home). Avoiding the issues of these procedures, we instead examine correlations in CDI measurements across developmental time. There are only a small number of deeply longitudinal corpora in Wordbank, so we will limit our investigation to two languages: Norwegian and English. Furthermore, the largest group of longitudinal data cover the WS form so we restrict to these data for simplicity. Within each of these datasets, the modal number of observations is two, but there are some children with more than 10 CDIs available. Differences between a particular individual’s measurements could vary for two primary reasons: first, measurement error (parent forgetfulness, mistakes, etc.) and second, true developmental change (learning new words). Since all children’s vocabulary increases over time, we can look at the relative magnitudes of CDI scores via correlations; this is our first analysis. Our second analysis attempts to normalize these absolute differences by extracting percentile ranks and finds that this procedure in fact increases longitudinal correlations. Because there are two sources of differences between measurements, when correlations are low, we do not have direct evidence for whether 1) children’s relative linguistic abilities are shifting with respect to one another or 2) we are observing measurement error. But when correlations are high, we can assume the converse: measurement error is low and developmental stability is relatively high. It turns out that this is the case: The first locus for individual differences in language acquisition is the rate of growth. As we will discuss in more detail in Chapter 5, there is substantial variability between children in vocabulary size. This variability appears to be quite stable longitudinally. The figure above shows the trajectories of children (individual colors) who were measured more than ten times, and includes Norwegian data only due to data sparsity issues in English. These trajectories appear quite stable; the ranking of individuals does not appear to change much over the course of several years. We quantify this trend below. This general conclusion – longitudinal stability of language ability as well as limited measurement error – is ratified by other studies using different datasets, for example Bornstein and Putnick (2012), who found substantial stability (\\(r = .84\\)) between latent constructs inferred from early language at 20 months and later language measured at 48 months. One way to operationalize the question of stability is how children’s percentile ranks tend to change over time. We examine this question creating an empirical CDF for each age group.9 As shown above, these ranks are visually quite stable. The transformation to percentile ranks allows us to assess the correlation between a child’s percentile rank at time 1 and their rank at time 2, depending on the gap between these two. Because of sparsity, we bin children into two-month age bins and eliminate age bins with fewer than 50 children, then calculate between-bin correlations in percentiles. The figure above shows this analysis, which reveals that percentile ranks are quite stable; across a 2-4 month age gap they are correlated at better than .8. This stability declines to around .5 at 16 months, but this decline should be taken with a grain of salt. First, this range is a doubling of the child’s age, so stability might be expected to be lower. But second, many children who are measured longitudinally across a 16-month gap will be expected to move from the floor of the form to the ceiling, compromising measurement accuracy. To test this last hypothesis, we evaluated the longitudinal stability of correlations using the same analysis as above, but varying whether we used raw scores or percentiles. The percentile method substantially increased correlations.10 In sum, the variability between children that we observe in the CDI is quite stable longitudinally. It declines over time, but some of this decline may simply be due to the unavoidable limitations of CDI forms with respect to floor and ceiling effects. 4.3 Psychometric modeling In this next section, we examine the psychometric properties of the CDI through the lens of Item Response Theory (IRT). In brief, IRT provides a set of models for estimating the measurement properties of tests consisting of multiple items. These models assume that individuals vary on some latent trait, and that each item in a test measures this latent trait (see Baker 2001 for detailed introduction). IRT models are a useful tool for constructing and evaluating CDI instruments, as they can help to identify items that perform poorly in estimating underlying ability. For example, WEBER et al. (2018) used IRT to identify poorly-performing items in a new CDI instrument for Wolof (a language spoken in Senegal). IRT can also be used in the construction in computer-adaptive testing (Makransky et al. 2016). IRT models vary in their parameterization. In the simplest (Rasch) IRT model, each item has a difficulty parameter that controls how likely a test-taker with a particular ability will be to get a correct answer. In the more sophisticated two-parameter model, each item also has a discrimination parameter that controls how much response probabilities vary with varying abilities. Good items will tend to have high discrimination parameters across a range of difficulties so as to identify test-takers at a range of abilities. We examine IRT models as a window into the psychometric properties of the CDI. In the first subsection, we explore latent factor scores using the English WS data. In the second subsection, we examine individual items and find generally positive measurement properties, although with some items at ceiling (included via carry-over from the Words and Gestures form). In the third subsection, we look at differences between comprehension and production in the WG form. In the fourth subsection, we look at the properties of the instrument by word category in both WS and WG. Overall, the conclusions of our analysis are that: Latent factor scores may have some advantages relative to raw scores in capturing individuals’ abilities, but for the purposes of the analyses we perform in the main body of the manuscript, they may carry some risks as well; hence we do not adopt them more generally. In general, CDI WS items tend to perform well, but from a pure psychometric perspective there are a number of items that could be removed from the English WS form. Comprehension items in general tend to have less discrimination than production, suggesting that they are not as clear indicators of children’s underlying abilities. Function words tend to have lower discrimination than other items but the lexical class differences are not huge and do not interact with whether they are measured using production vs. comprehension. These analyses generally ratify the conclusion that the measurement properties of the CDI are good, even for function words and for comprehension measures. These questions may carry slightly less signal about the specifics of a child’s vocabulary and load more heavily on a parents’ general estimation of the child’s linguistic ability, but they do carry some signal that relates to other responses. Further, when the English CDI departs from good measurement practice it generally does so for completeness (e.g., including “mom” and “dad” words because these are important to parents, even though they do not show good measurement properties). 4.3.1 Measurement properties of individual WS items A first question that we can ask using a fitted IRT model is how well individual items relate to children’s overall latent abilities. Practically speaking, in these analyses, we use the mirt package (Chalmers and others 2012, 2016) to estimate the parameters of a four-parameter IRT model. As described above, the two-parameter model includes difficulty and discrimination parameters for each item. The four-parameter model supplements the standard two-parameter model with two parameters corresponding to floor and ceiling performance for a particular item. Items with high rates of guessing or universal acceptance across test takers would tend to have abnormal values on these bounds. The plot above shows item discrimination and difficulty, with outlying items labeled. Difficulty refers to the latent ability necessary for a child to produce an item, on average. Discrimination refers to how well an item discriminates between children of lower and higher ability (as judged by their performance on other items). Visual inspection shows a long tail of items with limited discrimination and low difficulty (e.g., mommy, ball, bye, etc.). These are clearly those items that are produced by nearly all of the children in the sample – they do not discriminate because they are passed by all children in the sample. If the only goal of the instrument were discrimination of different ability levels, they could likely be removed. But, as discussed above, these items tend to be included for completeness (and so the WS instrument is a strict superset of the WG instrument, which is used with younger children). On the lower right hand side of the plot, the remainder of items are clumped, with discrimination above zero and somewhat higher difficulty. The right-hand tip of this triangle shows the most diagnostic words (e.g., run, kitchen, and table), all of which effectively distinguish between the upper and lower groups of children in the sample. Finally, at the bottom of this triangle is a large cluster of words that are quite difficult. Some of these do not show good discrimination (e.g., country), since it is likely too difficult for nearly all children in the sample. We can also examine the upper and lower bounds estimated for particular words. These bounds show words that are known by only a small number of children (low ceiling) or are known by almost all children (high floor), respectively. Examining those with a very low ceiling, we see items that are likely to be quite idiosyncratic, for a variety of reasons. For example, babysitter, camping, and basement likely vary by children’s home experiences (further mediated by access to resources, parenting practices, and circumstances). In contrast, genital items (e.g. vagina*) vary by gender (see Chapter 9). Examining those items with a very high base rate shows a similar set to those with very low discrimination patterns, suggesting that the four-parameter model may have fit these words as having a high chance level with essentially no discrimination ability. One way to think about these analyses is that they show that the CDI has not only a large core of words with good measurement properties but also some other words that do not contribute as substantially and add length without adding much signal. In revisions of the CDI, some of these words might be good candidates for deletion. 4.3.2 Production and comprehension We next use IRT to estimate whether there are differences between production and comprehension, using WG data. The plot above shows IRT parameter values for discrimination and difficulty for production and comprehension (a few extreme parameter values are truncated in the plot for ease of seeing general trends). There are clear distribution differences on both measures. Difficulty is much higher (negative values) for production relative to comprehension, reflecting the expected asymmetry of production coming “after” (being more difficult than) comprehension. The second generalization is that comprehension questions largely have positive discrimination parameters. Thus, these questions on the whole carry signal about children’s latent linguistic ability. There do appear to be more discrimination values that have negative discrimination parameters, however, indicating more items that are not measuring ability appropriately (perhaps because they are difficult for all children or because they are too hard to assess). Finally, mean discrimination is substantially lower for comprehension relative to production (1.1 vs. 1.8). This pattern is consistent with the hypothesis that production behavior is a clearer signal of children’s underlying knowledge than assumed comprehension. This pattern of findings – lower discrimination values for comprehension – could be due to at least two possibilities. One is that parents are better reporters of production than comprehension, and hence these items are more discriminative of true behavior. The source of error in this case would be parents’ mistaken belief that their child understands a word. The second is that comprehension is a fundamentally more variable construct and that, hence, individual word knowledge consistent with understanding could be due to partial knowledge. Here the source of error is variance in how well children know the meanings of words. We cannot distinguish between these two models, but they have different underlying implications for the CDI. 4.3.3 Lexical category effects on item performance One hypothesis that we have often speculated about is the question of whether there are special psychometric issues with particular word classes. For example, do parents struggle especially to identify whether children produce or understand function words? The plots above show WS item difficulty and discrimination (as above) and the histogram of discrimination, but broken down by lexical class (color). Many of the easy, non-discriminating items are found in the “other” section. In contrast, the hardest items tend to be function words. These items tend to have lower discrimination on average (1.3) compared with nouns (1.8), adjectives (1.9), and especially verbs (2.1). Nevertheless, the situation is not dire: most have a discrimination parameter above one. Thus, although function words are not the most discriminative items on the CDI WS, these items still appear to encode valid signal about children’s abilities. In our last analysis, we turn to the WG data. The plot above shows the mean (error bars show SD) for discrimination parameter values. In production, the higher discrimination shown on the whole (above) is likely due to the strong performance of nouns, which index distinctive and memorable productions. In contrast, mean discrimination for other words is low. This pattern may be due to the overall sparsity of early production data for non-noun items. In comprehension, in contrast, there is a moderate level of discrimination for all classes except “other” (which includes items like mommy and daddy and a variety of animal sounds and social routines). One hypothesis about this finding is that, especially early on, parents are very generous in their interpretation of whether their child understands these specific words. In sum, we do not find evidence that function words are particularly low-performing items from a psychometric perspective – even in comprehension assessments! Rather, there are some low-performing items spread across all categories of the CDI form, and many of these likely perform poorly for the reasons described above – especially difficulty in interpretation of very early behavior and variability in home experience. 4.3.4 IRT models: Conclusions One question regarding IRT-model derived parameters for individual children is whether they should be used in place of percentiles or raw scores for some of the measurement problems we encounter throughout the rest of the book. Although these latent ability scores might be overall better reflections of children’s vocabulary than other measures, we do not find strong evidence to support that conclusion. For example, in the analysis above, we compared longitudinal correlations derived from raw scores, percentiles, and IRT ability parameters. While IRT parameters yielded higher correlations than raw scores, empirical percentiles performed better still (at least for Norwegian and English, two languages for which we have large amounts of data). Furthermore, there are other negatives associated with swapping an imperfect but straightforward measure (raw and percentile scores) for a model-derived measure (latent ability). Interpretation clearly suffers if we use the model-derived measure, since readers will not be able to map scores back to actual behavior in terms of the checklist. In addition, model estimation issues across instruments introduce further difficulties in interpretation. Most obviously model estimates with smaller datasets may vary in unpredictable ways; similarly, the presence of poorly-performing items in certain datasets may lead to systematic issues in the latent estimates for those datasets. 4.4 Conclusions In this chapter, we examined the measurement properties of the CDI from three perspectives. From a theoretical perspective, we reviewed why the design features of the CDI make it a reasonable tool for measuring child language, even if there are opportunities for error and bias throughout. (Of course, one of these design features are dependent on the style of administration for a particular study, so of course a poorly-administered form will yield a dataset with lower reliability and greater bias). Then, we took advantage of the deep longitudinal data available for two languages and showed quite strong longitudinal correlations between CDI administrations. This pattern indicates that early language is a stable construct across development (Bornstein and Putnick 2012). It also signals that measurement error between CDI administrations appears to be limited, at least when the span of time between administrations is not too great. Finally, we used item-response theory to examine the measurement properties of individual items. While the CDI includes some items with limited measurement value (if all that the user cares about is a single ability score), most items show good psychometric properties. This analysis also revealed that comprehension questions and questions about function words do not appear to be particularly worse than other items, contrary to previous speculations. In sum, the CDI appears to be a reliable instrument for measuring children’s early language, with measurement properties that support a range of further analyses. We could use a model-based method (e.g., the gcrq method used in the Wordbank app and Chapter 5 and 6) but in practice we have enough data in each of these languages that this method should perform well.↩ We also used latent abilities derived from a 4-parameter IRT model as below. While the IRT-derived ability parameters showed a consistent improvement in longitudinal correlations over the use of raw scores, percentiles realized a further gain over the IRT parameters.↩ "],
["vocabulary.html", "5 Vocabulary Size 5.1 Central Tendencies 5.2 Variability between individuals", " 5 Vocabulary Size Far from simply reflecting noise in our measuring instruments or variability in low-level aspects of physiological maturation, the variations that we will document (in vocabulary development) are substantial, stable, and have their own developmental course. Because this variation is substantial, it is critical for defining the boundary between normal and abnormal development; because it is stable, it provides a window onto the correlates and (by inference) the causes of developmental change; and because it has its own developmental course, it can be used to pinpoint critical developmental transitions that form the basis for theories of learning and change. (Bates et al., 1995) This chapter focuses on one canonical view of CDI data, in which each child is represented by a single vocabulary score: the proportion of words that child knows, out of the total in the form. We begin by quantifying the median pattern of vocabulary growth observed in our data; we then turn to characterizing variability across individuals in these data. This chapter trades in variability, but variability is only meaningful in the case that it is stable; that is, that it reflects signal about individuals (or cultures) rather than measurement error. With respect to the CDI, the strong evidence for the reliability and validity of the forms – reviewed in Chapter 4 and in Fenson et al. (2007) – provides support for the contention that observed variability is meaningful. Such evidence has primarily been collected for the English CDI, however. In this chapter we examine variability across the full set of languages, and it is worth noting up front that we project the reliability and validity of the English instrument to its adaptations. One study nicely illustrates why such an approach might not be misguided. Bornstein and Putnick (2012) collected multiple language measures at 20 and 48 months in a sample of nearly 200 children and used a structural equation model to estimate the stability of a single latent construct, language ability. Essentially all measures related strongly to this latent variable and the coefficient on its stability over time was \\(r = .84\\), suggesting that early language is quite stable, at least when measured appropriately. Notably, the ELI, a precursor to the CDI, was included in the measures at 20 months and was found to correlate with the 20-month latent construct at \\(r = .87\\). This finding – along with the other evidence, mentioned above – justifies the implicit conceptual model of the following analyses. That model is that there is a single quantity, early language ability, that is stably measured by parent report and that can be approximated as the raw proportion of words a child “understands” or “understands and says” on CDI forms. 5.1 Central Tendencies One first question we can ask about CDI data is about its central tendency – the median pattern of vocabulary growth. Our general expectation is shown below. Figure 5.1: Schematic true vocabulary growth and vocbaulary growth as measured by the CDI. This image reveals a number of patterns that are explored in this and subsequent chapters. The CDI necessarily captures a small fraction of any individual’s true vocabulary, but even within this range there are specific questions that are usefully addressed. The question of the exact slope of children’s growth, especially in the period immediately after the emergence of language, is treated in Chapter 14 – this question is sometimes posed as whether children undergo a vocabulary “spurt” (Ganger and Brent 2004). On the other side of the CDI curve, the question of the divergence between CDI-measured vocabulary and true vocabulary (and whether true vocabulary can be recovered via a statistical correction) is treated in Appendix E. In the current chapter, we focus on the middle section of the CDI curve, in which children’s vocabulary is neither at the floor or the ceiling of the instrument. 5.1.1 Commonalities across languages Figure 5.2: Median production using the Words and Sentences form. Included are only lanugages where there are more than 200 administrations total. Plotted above are the median patterns of growth for early production. Rather than showing proportions, as we will do more standardly throughout the book, here individual item totals are plotted.11 In general, the median child before the first birthday is reported to produce a small number of words. (These data raise a number of questions about the specific reliability of very early parent reports, which we take up below.) Overall, however, these curves accord relatively well with our intuitive sense of early vocabulary development: they reveal that most children tend to speak at most only a few words before their first birthday, but that production accelerates across the second year. This acceleration is even clearer when looking at production reports from older children using Words and Sentences. In every language, we see the median child is reported to produce 50 words between 16 and 20 months. As we will see below, this analysis masks the tremendous variability apparent during this period. In addition, as we discuss below, languages vary considerably in the absolute number of words reported. (We discuss Mandarin in particular, which is a major outlier from other languages in this analysis). Nevertheless, there are still substantial consistencies between languages. During the period 24-30 months, we see children beginning to produce a large enough sample of words that curves are leveling out. Presumably this leveling does not reflect a slowing in the rate of acquisition, which many authors assume continues unabated for many years (Bloom, Tinker, and Scholnick 2001). Instead, it reflects the limitations of the CDI instrument, in that there are many possible “more advanced” words that they could be learning, of which only a small subset are represented on any form. (See Appendix @ref{appendix-vocabulary) for estimates of how many words children actually might know.) We next turn to comprehension. Comprehension is only queried on the Words and Gestures form. Reported comprehension increases much faster than production; so much so that most parents are reporting that their children understand most words on the form by 18 months. See Chapter 14 for discussion of the differences in the balance between comprehension and production between children. As with the production data, we see substantial differences across languages in reported vocabulary (see below). One striking aspect of comprehension data is how early comprehension is reported. For example, from 8 months, we see parents reporting medians of 4.5 (Swedish) and 123.5 (Mandarin (Taiwanese)) words. Intuitively, to many researchers (and parents) these high numbers feel unlikely. A spate of recent infancy experiments suggest that in fact, children in the second half of the first year do have some fragmentary representations of many common words available (e.g., Tincoff and Jusczyk 1999, 2012; Bergelson and Swingley 2012; Bergelson and Aslin 2017). The representations revealed in these tasks are quite weak – often amounting to a 2-5% difference in looking to a target on hearing a word uttered – but, depending on the criterion used by parents, may be what is detected in these early reports. Thus, these estimates may not be as far off as we initially suppose.12 5.1.2 Cross-language differences What causes the differences between languages observed above? In this discussion, we examine production on the Words and Sentences form, as the data are the densest and most reliable for this instrument. We first discuss the case of Mandarin. Mandarin Words &amp; Sentences data are reported by Tardif et al. (2009) in a study of both Mandarin- and Cantonese-learning children. The data reported there also show the pronounced Mandarin advantage plotted above. The authors investigate possible explanations, given that the administration and sampling procedures were similar in these two languages. The children in the Mandarin sample are nearly all monolingual, only (first born) children; but these factors did not account for variation between samples. Tardif et al. (2009) therefore, speculate that structural factors regarding Mandarin (e.g., phonological structure relative to Cantonese) might be accounting for the Mandarin advantage. These speculations seem unlikely in light of the data presented here. First, the same trajectory is not shown in the data from the analogous questionnaire of Hao et al. (2008). Second, this unusual trajectory is not apparent in the production data from the Mandarin WG data shown above. Finally, given the surprising difference between Mandarin and all other languages in the sample, pure phonological factors seem unlikely to account fully for the differences. These differences thus remain somewhat mysterious – and serve as an important caution against simple cross-linguistic comparison in raw scores. In the remainder of this section, we consider the other languages in the WS sample. The figure above shows estimates of the median 24-month vocabulary in both raw scores and proportions. (To increase stability, the plotted value is the intercept of a linear model predicting vocabulary as a function of centered age between 18 and 30 months). Clearly there are substantial differences in raw scores. We consider a range of explanations for this pattern. Differences could be due to differences in form length. As shown in the plot above, medians for production and raw scores are highly correlated (\\(r\\)(21) = 0.907, \\(p\\) = 2.5710^{-9}), suggesting that this ordering is not only a function of form length. Further, although raw scores are correlated with form length (\\(r\\)(21) = 0.51, \\(p\\) = 0.0129), this correlation changes direction and is no longer reliable for proportions (\\(r\\)(21) = 0.109, \\(p\\) = 0.622). In sum, it appears that there are form-length differences (motivating the use of proportions in general), but that there is still stratification between languages even correcting for this issue. See below for a plot of the relevant proportion trajectories, highlighting remaining differences between English and Danish (two languages for which we have substantial datasets with full demographic information). Differences could be due to form construction. For example, the Czech form could contain harder words, leading to fewer words being checked. We cannot directly address questions about the difficulty distribution items without moving to psychometric models, which carry their own risks (see Chapter 4). Further, even latent ability scores (estimated via item response theory) will not be comparable across instruments unless items are assumed to be shared across instruments (which they are not, since dog in English need not be equally easy as perro in Spanish). Thus, assessing form difficulty across languages is a complex proposition. Differences could be due to demographic differences across samples. We can examine sample composition in Chapter 3 and see that – to the extent we have access to demographic data – sample composition does vary in features that affect vocabulary (e.g., maternal education, birth order; see Chapter 6). We are not yet in a position to conduct a full analysis of these differences, controlling for demographics, as data are sparse and demographic differences also vary across cultures. But we can examine the difference between Danish, and English (American) for example, and note that these differences look quite similar (though noisier) in the female, first-born children of college-educated mothers. Thus, we do not believe that demographic differences fully explain the cross-linguistic differences observed. Differences could be due to cohort effects, in which older sets of data show differences from newer datasets. Most of our data date to the period 2005-2015, but some of the English and Spanish data are older. It’s not clear that there is an obvious trend, though, as the Danish data for example are relatively recent and were collected online using standardized instructions. Differences may relate not to demographics of the sample but to the administration, and these we cannot control for statistically. For example, instructions at administration – whether written on the form or given by experimenters – might have been more liberal in the case of Slovak or English (American) samples. Such instructions could have emphasized completeness in reporting vocabulary. Or the circumstances of administration could have been different – for example, Danish data were collected online while most English data were collected using paper and pencil forms. English (American) data are contributed by many different labs, so there are likely many different administration styles represented. Differences could be due to cultural or experimental differences in reporting bias. Slovak parents might have a lower criterion for reporting knowledge of a word. Recalling our discussion of these issues in Chapter 2, their model of children’s overall competence might be shifted up. (Such an explanation could be true in principle for the case of the Mandarin data discussed above, as well, though this would be a case of extreme differences!). This explanation is as an extension of the discussion above of administration and instructions – perhaps cultural expectations for what it means to be producing a word or cultural expectations for how verbal children are expected to be. Finally, differences could be due to true differences in language acquisition. Many researchers working on Danish believe that, due to its phonological properties, it is truly a difficult language to learn (Bleses et al. 2008; Bleses, Basbøll, and Vach 2011). In particular, Danish is characterized by some highly distinctive phonological reduction processes which greatly reduce the frequency of obstruents, and more generally lead to “an indistinct syllable structure which in turn results in blurred vowel-consonant, syllable and word boundaries. In particular, word endings are often indistinctly pronounced…” (Bleses et al., 2008, p. 623). The authors were also able to provide evidence against the alternative view that Danish parents are simply more reluctant to respond ‘yes’ – there were no differences on either gestures or word production. They conclude that the phonological structure of Danish produces an initial obstacle to breaking into the stream of speech and is reflected in overall patterns of vocabulary development. In summary, differences between languages in the sheer number of words reported are unlikely to be accounted for purely by differences in form size or demographic differences between samples. In our view, they likely result from a combination of cultural attitudes towards children’s language, differences in administration instructions, and real differences in learning across languages. Partialling out these differences would likely require better-controlled data that included constant administration and sampling methods. For this reason, we attempt to avoid interpreting overall differences in vocabulary size wherever possible and limit ourselves to quantities that can be effectively normalized. 5.2 Variability between individuals We next turn from the question of central tendencies to the question of variability. One of the most important features of early vocabulary development is its variability (Fenson et al. 1994). To examine variability, we switch to a view of the data that reveals the full range of variation across the samples in the database. Examining Words and Sentences data, we can see that across every language in the database there is a tremendous range of vocabulary sizes reported. How systematic is this variability?13 5.2.1 Quantifying Variability As an example, we zoom in on the English (American) production data from the Words and Sentences form. Consider just a single age group, 24-month-olds. The distribution of vocabularies across children is far from normally distributed, with many children at the very bottom of the scale and almost as many at the top. Quite a few two-year-olds on their second birthday are producing only a handful of words (or at least their parents say they are) and others are producing nearly all of the 680 listed on the form (as well as others, in all likelihood). One way to describe these data is to consider the relationship of the variance to the central tendency. The “coefficient of variation” (CV) is a common measure used for this purpose: \\[CV = \\frac{\\sigma}{\\mu}\\] This statistic allows standardized comparison of variability across measurements with different scales, an important concern when we want to compare forms with very different numbers of vocabulary items. For example, for two-year-olds, the mean productive vocabulary is 319 words, and the standard deviation is 175, words, leading to a CV of 0.55. But, as seen in Figure @ref(fig:v_histogram), the distribution of productive vocabulary scores is far from normal; this trend is even more apparent at the younger and older ages. Thus, a non-parametric approach is more appropriate. Accordingly, we compute the MADM statistic, the non-parametric equivalent of the CV. In MADM, the mean \\(\\mu\\) is replaced by the median (\\(m(x)\\), and the standard deviation \\(\\sigma\\) is replaced by the mean absolute deviation (which captures how far away values are from the median): \\[MADM(x) = \\frac{\\frac{1}{n} \\sum_{i = 1..n}{|x_i - m(x)|}}{m(x)}\\] In American English production, this ratio is actually close to 1 from age one until almost age two, suggesting that the standard difference from the median is actually as big as the median itself! The decline begins before variability is substantially truncated by the ceiling of the form, suggesting that variability between kids is really highest before the second birthday. Imagine groups of three children. A group where one produced 30 words, one produced 100, and another produced 170 would have a MADM of 0.99. In contrast, one where they were more closely grouped – say 70, 100, 130 – would have a MADM of 0.44. The next figure shows MADM across languages and instruments. This similarity in variability structure is quite striking, such that between the first and second birthdays, language is remarkably variable. Yet this variability is quite consistent! We summarize the MADM in the second year of life by taking its mean. This mean is close to 1 for almost every language and form for which we have data. One question that could be raised regarding the analysis above is the extent to which variability is caused by variability across children vs. variability in reporting. The extreme values seen in the English data, for example, could easily be the result of a mixture of lazy parents who stopped answering the form with overly diligent parents who misunderstood and checked every box for a word they thought the child had been exposed to. Several arguments speak against this account, however. First, to the extent these biases are the source of variability, they are extremely consistent across languages – which, recall, is the exact opposite argument from the one we considered above (where parent diligence was supposed to be variable enough across samples to lead to differences between languages). In sum, although there are certainly some reporting biases represented in the data, these results do not appear likely to be an artifact of reporting bias. We can complete the same analysis using comprehension data. Here we see a gradual decrease in variability throughout development. The intercept for the 12-18 month period appears to be lower than that observed in production, despite (or because of?) the higher scores. This observation matches one made by Mayor and Plunkett (2014), namely that production vocabulary appears more idiosyncratic in distribution of words than comprehension vocabulary. One speculative explanation for this difference would be the tremendous differences in speech-motor development (as well as general differences in loquacity) between toddlers. This variability would then carry over into production. Another possibility, however, is that true variability is masked by the overall lower reliability of comprehension items (see Chapter 4). Our data do not allow us to distinguish between these two explanations. 5.2.2 Item-response theory The analysis above suggests that variability between individuals decreases. But this conclusion is compromised by ceiling effects: once children begin to reach the ceiling of the CDI form, variability is necessarily truncated. No analysis can completely eliminate these effects, but the use of item response theory-based analyses can partially address the issue by estimating variation in latent ability (which leads to a particular score) rather than variation in raw scores themselves. Chapter 4 provides a summary of our approach to using item response theory (IRT). In brief, item response theory provides a framework in which the full test (the CDI) is broken down into a series of items, with each having its own logistic model predicting the response for a particular child on the basis of their latent ability. In Chapter 4, we examine the parameters of individual items with respect to their properties; but fitting an IRT model also implies estimating a set of latent ability parameters for individual participants. These latent ability parameters are logistic regression coefficients and hence are not bounded in the same way that individual responses (and hence raw scores) are. Thus, we can examine their variability as a way of dealing with ceiling effects. The above figure shows the normalized standard deviation of latent ability scores, plotted by age. The absolute size of the standard deviations is not easy to interpret – the range of latent ability scores on a form is a function of how consistently difficult or easy the items are. Thus, the standard deviation of these scores will be larger or smaller based on this feature as well as the consistency of children’s abilities within an age group and is not interpretable. On the other hand, age-related trends in the standard deviation are interpretable and can be used as an index of whether variability in ability stays constant, increases, or decreases. Interestingly, slopes for the variability of latent ability are fairly flat or increasing (with Mandarin – which has extreme ceiling effects – the exception). This finding suggests that the decreases in variability observed above are very likely due to ceiling effects. Variability is constant, or even increasing, with age. 5.2.3 Discussion We observed a striking consistency in the individual variability of children’s vocabulary during their second year and perhaps beyond. Across languages and forms, it appears to be the norm that toddlers vary.What does it mean to have such a high level of variability? For one comparison, we compare age of walking onset (as measured by a Norwegian national survey with parent 47,515 respondents) and age of achieving production and comprehension milestones (also in Norwegian). Walking data are from Størvold, Aarethun, and Bratberg (2013). response 25th percentile 75th percentile range range (proportion of age) walking 12 14 2 0.15 produces 10 words 13 16 3 0.21 produces 50 words 17 20 3 0.17 produces 100 words 18 23 5 0.25 understands 50 words 10 15 5 0.42 produces 200 words 20 26 6 0.26 The 25th and 75th percentiles for a variety of behaviors are summarized in the table above. The spread of achieving walking (defined as taking a step independently) is quite tight with a mean of 12.9 months and a spread of only a month between 25th and 75th percentile. Very early language comprehension and production are relatively similar with 2 and 3 month spreads. In contrast, production and comprehension at a higher level has quite a large spread in comparison to walking (even as a percentage of age). In sum, these results echo the conclusions of Bornstein and Cote (2005) based their comparative data across Spanish, English, and Italian, who noted that “individual variability is probably a universal feature of early language acquisition” (p. 311). As Eriksson et al. (2012) write, “Using raw data assumes that each form is exhaustive, while using percentages assumes that each form is equally exhaustive. Neither is correct and the truth lies somewhere in between.”↩ An alternative possibility is that both accounts are true, but unconnected: 8-month-olds could in fact know some common words, but parents could be overestimating their vocabulary based on observed behaviors – in essence, parents could be right, but for the wrong reasons.↩ Feldman et al. (2000) discusses the possibility that some portion of the observed variability in her data as well as the CDI norming data (Fenson et al. 1994) is due to reporting issues. In their response, Fenson et al. (2000) cite an unpublished dataset comparing lab-based elicited production and parent report for 36 object names and show that the standard deviation is greater than the mean on both measures, suggesting that the variability found in CDI scores is not artifactual.↩ "],
["demographics.html", "6 Demographic Effects on Vocabulary Size 6.1 Sex 6.2 Birth order 6.3 Socioeconomic status", " 6 Demographic Effects on Vocabulary Size Chapter 5 examined cross-linguistic consistency and variability in children’s reported vocabulary. In this chapter, we follow up these analyses by beginning the process – which will span throughout the book – of attempting to understand the nature and sources of these differences. In particular, we take advantage of the sample diversity described in Chapter 3 to explore differences in the median trajectory of vocabulary growth within demographic groups, focusing on three variables that are relatively available in our data: sex, maternal education, and birth order. Our goal is to develop a framework for comparing the magnitude of these effects. One important tension in this chapter reflects many earlier discussions of variability in CDI scores (from Fenson et al. 1994, @feldman2000, and @eriksson2012, among others). While some demographic differences in vocabulary are quite consistent – substantially so, as it turns out – the overall proportion of variance in vocabulary that they capture is still relatively limited. We will examine a number of different perspectives on how to quantify this relationship, moving back and forth between emphasizing consistency in differences in the central tendency and emphasizing the limited size of these effects relative to the variability documented in Chapter 5. Our analyses in this chapter are unfortunately limited to a subset of languages, as demographic data for many contributed datasets were not available. We begin with sex, the variable for which the most analysis has already been done and for which we have the most data, then move on to birth order and finally maternal education. 6.1 Sex Our first analysis examines how vocabulary development differs by children’s sex.14 The literature on cognitive differences due to sex is vast, controversial in many places, and difficult to summarize (see Miller and Halpern 2014 for a useful recent review). Focusing on development, Maccoby and Jacklin (1974) began the enterprise of systematizing and summarizing gender differences. Their conclusions were largely deflationary but did suggest some differences in aggression and verbal ability (which were suggested to emerge in the period of early adolescence). This latter claim is most relevant for our analysis, but has been subject to controversy as well. Using meta-analytic tools, Hyde and Linn (1988) found that differences in verbal ability were minimal, but more recent studies have suggested consistent verbal ability differences. For example, Stoet and Geary (2013) found differences in reading ability across nations in a massive elementary education dataset (the PISA assessment), with variance in the magnitude of difference, but with girls very consistently showing an advantage. Similarly, Robinson and Lubienski (2011) reported consistent differences in reading ability (favoring girls) at the onset of kindergarten in a nationally-representative US sample. A weak prediction from this literature is thus a modest but consistent female advantage in vocabulary. Of course, a complication of our analysis is the presence of caregiver reporting bias added to any true sex differences. In contrast to these findings suggesting modest and consistent female advantages, there is substantial cross-linguistic variation in gender stereotypes (Nosek et al. 2009). Thus, a qualitative but plausible speculation is that, if stereotype-based reporting bias plays a major role in gender effects, the cross-national variance should be high. Despite these predictions, it almost goes without saying that these findings are subject to the full range of possible explanations articulated in the literature. These range from caregiver and academic socialization (e.g., self-fulfilling expectations that girls are more verbal) to “self socialization” in which affiliative differences produce differences in behavior, all the way to biological explanations.15 While descriptive data of the type cited above (and reported in our analyses below) can be more or less consistent with some of these theories, conclusive evidence will not be forthcoming. Our analyses below replicate and extend the results of Eriksson et al. (2012), who used an overlapping sample of CDI data from 12 languages to explore sex effects on vocabulary size.16 6.1.1 Comprehension We begin by examining Words and Gestures data on comprehension. Our first plot shows comprehension on Words and Gestures. Visual inspection of the data suggest limited differences, but a female advantage in some languages (most pronounced in Korean, Latvian, and Hebrew). Note that many authors do not find gender differences in early comprehension (e.g., Eriksson et al. 2012). Feldman et al. (2000) also did not using a large, relatively representative American dataset, though they had data only from younger children (10-13 months). We can examine the statistical models to get a clearer picture. For each language, we fit a robust generalized linear model predicting vocabulary size (number of words understood out of the total) predicted by age, and the interaction of age and gender. We specified this simple model so that the coefficient estimate on the age by gender interaction provides a convenient summary of the difference in vocabulary growth across groups. Despite the small magnitudes of the coefficients, 0 of 22 languages had a female advantage. In contrast, 0 showed a male advantage and the remainder did not show a significant gender by age interaction. Moving away from the model-based method above, we can look for a measure of effect size (similar to that used in the previous chapter). Effect size quantifies the size of the difference between groups in terms of the variability, producing a scale-free measure of difference that is appropriate for comparison across languages. Normally we’d use a measure like Cohen’s \\(d\\) here, where \\[d = \\frac{\\mu_2 - \\mu_1}{SD_{pooled}}\\] But as in the previous chapter, we have the problem of non-normal distributions. To circumvent this issue, we use a non-parametric measure derived from the same components: the difference between medians, divided by the MAD. (We call this the MMAD). Applying this measure to the data on comprehension, we see a quite small average female advantage that appears relatively constant across age. For those languages with dense enough data, we can take a weighted average of this pattern across ages, which reveals substantial variability. The overall median for these 18 languages is quite small as well, 0.08. In summary, there is some evidence for a modest female advantage in comprehension. 6.1.2 Production (Words and Gestures) We next turn to production data. As in many of our subsequent analyses, data on production from Words and Gestures forms tend to be at floor, so they are of limited utility and the failure to find differences may reflect floor effects rather than any true differences. Visual inspection confirms differences at the edge of the age range covered by Words and Gestures forms, however, so for completeness we give the comparable statistical analyses as above. Here 0 of 22 languages show a statistically significant female advantage. Examining the MMAD effect size measures, it is clear that there is limited signal in early production but the overall trend appears to be for a slight developmental increase from around 12 - 20 months. In addition, overall effect sizes are larger than in comprehension, with a median effect of 0.24, though in this analysis, averaging across age may be less warranted. 6.1.3 Production (Words and Sentences) We next turn to production data on the Words and Sentences instrument, which we expect to be much more informative regarding production. Visual inspection confirms differences in almost every case, and an analysis of the fitted models shows that 0 of 26 languages show a statistically significant female advantage! We next turn to the MMAD effect size measure. Here we see a relatively consistent difference across ages with perhaps a slight downward trend in effect size. This downward trend might be a function of ceiling effects on the form, however, as seen in the model-fit curves above for, e.g., Danish. When variability is limited by the form ceiling, effect size estimates will necessarily be depressed. The median female advantage is 0.4, substantially larger than that seen in early comprehension and somewhat larger than that seen in early production (perhaps due to floor effects early on). 6.1.4 Reporting Bias? Do these differences reflect differences in measurement that are unique to the CDI? One way of addressing this question is to examine other studies of gender differences that have been found in other studies. Unfortunately, many of the studies reporting differences themselves rely on the CDI, likely for the reasons reviewed in Chapter 2, e.g. (Bauer, Goldfield, and Reznick 2002; Fenson et al. 1994; Feldman et al. 2000). For example, Feldman et al. (2000) collected CDIs with a large dataset of low-income American English speakers at 12 and 24 months. In those data, early comprehension showed no significant gender differences, but production at 24 months showed a difference comparable to what we observed here (\\(N = 2156\\), \\(d = .35\\), recomputed from provided summary statistics). These data, while providing replication in an independent dataset, do not speak to whether reporting biases contributed to or created the observed sex effects. For external validation, we turn to two other studies that provide more objective (non parent-report) measurements of early language. First, a seminal study by Huttenlocher et al. (1991) measured gender effects in vocabulary production as estimated from a naturalistic language sample, finding substantial differences in vocabulary growth favoring girls. Although the measures from this study are not comparable to the current data, the effects are quite large (and are relatively unaffected by controlling for maternal language exposure). #&gt; [1] 193 Second, Bornstein and Putnick (2012) use a particularly powerful study design to examine stability in early language estimates across different measures. They gathererd longitudinal data at 20 and 48 months using a wide range of standardized and parent-report measures, and then use structural equation modeling to model shared variance due to parent report as well as standardized latent language ability at each age. We digitized data from their Figure 2 to examine the size of the gender differences in the latent vocabulary construct that they recovered.17 As these scores are standardized, we can examine the difference in means and recover the standardized effect size for gender in the data, which is 0.62 standard deviations. Since this measurement is greater than that found using the CDIs (the comparable American English measurement was 0.35), we doubt that our observed effect is due solely to reporting bias. 6.1.5 Discussion In summary, we found a considerable and strikingly consistent cross-linguistic female advantage in early language production (replicating and extennding Eriksson et al. 2012). A much smaller but still relatively consistent female advantage was reported in comprehension. We suspect that neither of these effects are due to parental reporting bias. First, our review of the literature suggests that studies using direct assessments yield similar effects to the extent that we were able to compare. Second, comprehension is very likely to be the measure more affected by reporting biases as it is likely to be more subjective (Feldman et al. 2000; Fenson et al. 2000). In contrast, we find a much smaller gender effect in comprehension. As noted above, we remain agnostic about the causes of these differences, but in Chapter 15 we discuss inferences from consistency across languages in much more detail. 6.2 Birth order Another factor that may contribute to individual differences in children’s vocabulary development is birth order. The literature suggests some evidence for a first-born advantage in early vocabulary development, but these differences are small and tend to be most evident early in development. For example, Bornstein et al. (2004) found that mothers report larger receptive and expressive vocabularies in their first-borns. Using naturalistic language samples, Berglund, Eriksson, and Westerlund (2005) found that first-born children reached the 50-word milestone earlier than later-born children, but that birth order differences diminished later in development. Finally, Hoff-Ginsberg (1998) found that first-born children were more advanced in vocabulary development than later-born children, but that later-born children were more advanced in their conversational skills. This may be attributed to “differences in early language experience” that “may set the stage for later developmental differences” (p. 603). Here, we can examine birth order effects in early vocabulary comprehension and production in a few languages in our sample. Only 12 languages have birth order data, with data available only for 11 languages for Words and Sentences, and only 8 languages for Words and Gestures. 6.2.1 Comprehension 6.2.2 Production (WG) 6.2.3 Production (WS) 6.3 Socioeconomic status From health to education, children from lower socioeconomic status (SES) backgrounds tend to be at higher risk for a variety of negative developmental outcomes, compared to their higher-SES peers (Bradley and Corwyn 2002). A large literature documents specific relations between SES and children’s early language abilities, especially oral vocabulary, which is in turn related to outcomes when children begin formal education (e.g., Hart and Risley 1995; Hoff 2003; Fernald, Marchman, and Weisleder 2013). The parent report method allows the assessment of the influence of SES on vocabulary outcomes earlier in development than is possible with direct assessments. Using the CDI Words and Sentences form, Arriaga et al. (1998) compared the language skills in 103 very low-income toddlers with a sample of middle-income toddlers from the Fenson et al. (2007) norming sample, matched on age and sex. They found that the vocabulary production scores for the low-income group were consistently about 30% lower than those for the middle-income group. The size of these effects suggest that differences in SES are evident from the earliest phases of language development. Environmental explanations of these SES effects are often given in terms of indirect factors that affect life opportunities or experiences, such as nutrition and access to health care, as well as more direct factors that impact daily life, such as smoking during pregnancy, access to quality child care, or amount of time caregivers spend in interactions with their young children. Alternatively, even early language shows a significant genetic component, raising the possibility that SES-vocabulary links may instead be genetically mediated (Hayiou-Thomas, Dale, and Plomin 2012). In the current dataset, we have the opportunity to explore the extent of these effects across several language communities. Cross-language comparisons may shed light on the factors that lead to relations between SES and children’s vocabulary outcomes. On the one hand, relatively constant relations across language communities that vary widely in indirect and direct factors that shape learning would provide prima facie support for genetic explanations. In contrast, a greater degree of cross-language variability would point to the origins of SES effects in aspects of children’s early environments that vary with SES to differing degrees across countries [e.g., L. C. Fernald et al. (2012). We use maternal education as a proxy for SES, following previous work suggesting that maternal education is strongly related to SES variation (Bornstein et al. 2003; Hoff 2003). 6.3.1 Production (WG) 6.3.2 Production (WS) 6.3.3 Explanations Our findings show that the relations between maternal education and children’s vocabulary outcomes is highly variable across countries. The observational nature of our data precludes strong inferences about the precise factors that lead to these differences, though speculation is certainly possible. The large magnitude of the differences across countries suggests a powerful role for environmental factors in shaping variation in child outcomes even before the age of 3 years. Findings from the present study support the proposal that inequalities in factors that are linked to child well being should be addressed early in life. Since features of the quantity and quality of caregiver linguistic input has been strongly implicated in early language development, future research should focus on policy interventions that facilitate children’s access to high quality talk by caregivers, including care availability and parental leave. 6.3.4 Reporting biases While lower scores on the vocabulary checklists can reflect authentic differences across children from different SES groups, it is also possible that some of these SES effects are the result of differential reporting biases (for discussion, see Fenson et al. 2007). For example, in Feldman et al. (2000)’s study of more than 2000 children, vocabulary comprehension scores on the Words and Gestures form were higher for caregivers with lower education than for caregivers with higher education, whereas, the opposite relation was found for vocabulary production and later grammar skills from the Words and Sentences form. Thus, parents with low educational and income levels seem to overestimate their child’s comprehension abilities in comparison with parents with more education and income, especially early in development. Parents, in general, are likely to have difficulty making judgments about early comprehension. Overreporting may occur for those subscales of the CDI that require inference on the part of the parent, for example, when they have to separate evidence of comprehension of a word in isolation from that word taken together with the non-linguistic cues that are likely to support a child’s appropriate behavior in a highly constrained context. In addition, some parents may recall times when the words were used in the child’s presence and may confuse exposure with understanding. These difficulties may explain why parental reports of verbal comprehension in this age range are higher than results of direct testing (Tomasello and Mervis 1994) and why correlations between parental reports and comprehension scores from other methods are extremely low (Goldfield and Reznick 1990). Throughout, we will assume that parents report on children’s biological sex, rather than their gender identity.↩ As an illustrative example, some literature has implicated fetal testosterone, though by a Lutchmaya, Baron-Cohen, and Raggatt (2001) used CDI meausures and recovered an effect somewhat similar to ours with a small sample (\\(d = .64\\) at 18 months with \\(N=87\\)), and \\(d = .60\\) at 24 months for a subsample). They found some relationship with fetal testosterone across sexes, but it did not hold up within sex (perhaps due to small samples). The mechanism by which testosterone translates into vocabulary growth is unclear however.↩ An earlier version of this analysis was reported in M. C. Frank et al. (2016).↩ These data are not perfect, I have double-digitized one point.↩ "],
["gesture.html", "7 Gesture and Communication 7.1 Measurement properties of CDI gestures 7.2 The relationship between language and gesture 7.3 Gesture and Demographic Variables", " 7 Gesture and Communication Children’s most recognizable early linguistic accomplishments are surely their first words–a topic we turn to in the Chapter 8. However, even before infants approach this important milestone, they are already communicating with their through another modality: gesture. For example, a child who extends their hands and opens and closes their fist likely wants something. A child who points to a bird up in a tree likely wants to get their caregiver’s attention so that they can share in the delight together. Sometimes, children’s early vocalizations are accompanied by gestures, for example, a child might raise both of their hands in the air and says “up!” Indeed, the social and communicative routines that these gestures allow children to establish with their caregivers may form the supportive context in which early language learning happens (Bruner 1985). Gestures thus are an important aspect of children’s communicative development. Early gestures have long been thought to have a common mental status with later-developing linguistic accomplishments because both may reflect the child’s understanding of symbols, i.e., that a name or gesture can “stand in” for things in the world. The classic theories of Piaget (1962) and Werner and Kaplan (1963) proposed that all symbols have their origins in actions carried out on objects and moreover, such symbols can be manifested in either the vocal or the gestural domain. These proposals suggest a common underlying mental function that is critical to the development of all symbolic skills, both language and in certain types of gestures. While the strong representational claims in these theories may be too extreme by modern standards, they do (correctly) predict the developmental continuity between early gesture use and children’s later lexical and syntactic development (e.g., Bates, Camaioni, and Volterra 1975; Thal and Bates 1988). For example, children’s ability to point to distant objects is linked to the onset of the production of first words (Fenson et al. 2007; Brooks and Meltzoff 2008), and children with delayed onset of pointing are likely to also be delayed in first word production (ref). In addition, children’s early gesture use is correlated with their later comprehension abilities (Bates, Bretherton, and Snyder 1991), and children’s use of gestures in combinations with words is linked to the later production of multiword combinations (e.g., Goldin-Meadow 1998, @iverson1994). These early correlational findings could simply reflect a common cause: Children who use gestures might also be better better at learning words. More recent studies have demonstrated more specific links between early gesture use and later lexical and syntactic development, however (e.g., Rowe and Goldin-Meadow 2009). For example, the particular lexical items that enter a child’s vocabulary are likely to be names for objects that are labeled using a gesture several months earlier (Iverson and Goldin-Meadow 2005). Moreover, early gesture vocabulary is specifically linked to later word vocabulary, whereas early gesture plus word combinations are linked specifically to children’s later word combination skills (Rowe and Goldin-Meadow 2009). Taken together, the pattern of data suggests that children’s early gestures provide an important social, communicative, and linguistic foundation for later language development. Early gestures serve many different functions. Children typically first begin to use “deictic gestures,” for example, giving, pointing, or showing (e.g., Volterra and Caselli 1985). Such deictic gestures are clear precursors to important linguistic and communicative functions, including establishing reference and promoting shared attention (Carpenter et al. 1998). However, these deictic gestures do not necessarily have symbolic content per se (i.e., they do not stand for objects in the world, Bates et al. 1980). Early on, pointing gestures generally may serve an imperative function, e.g., to request something from an adult, whereas, later, pointing is more likely to direct a caregiver’s attention to another object or person (Bates, Camaioni, and Volterra 1975; Masur 1990; Vygotsky 1980). Children might also use gestures as part of a social activity, for example, waving “bye bye” or signaling “all done.” At first, social gestures might occur simply as imitations, but then later, a child may be able to produce these social gestures spontaneously in certain communicative contexts. Children’s social gestures also reflect children’s ability to engage in certain activities during pretend play, e.g., talking on a pretend phone or pretending to stir a soup. Such social gestures reflect children’s ability to tune into contextual cues, mentally reconstruct activities, and engage in sequences of events. Later, children’s gestures might take on a “true” symbolic meaning, as a child might use a conventional gesture to recognize or classify objects as an instance of a category (e.g., pretend to drink from a cup or sniff a flower). Children’s ability to use gestures in this symbolic way may reflect a common underlying “vocabulary” in both the verbal and gestural domain (e.g., Acredolo and Goodwyn 1985; Bates et al. 1980). This chapter contains analysis of the “early gesture” items from the CDI. Our goals here are to examine (1) the robustnesses of the measurement properties of these non-verbal parent-report measures, (2) the degree of cross-linguistic consistency and variability of reporting milestones like first pointing, as well as social routines like waving hi and playing peekaboo, (3) the relationships between gestural development and linguistic development, and (4) the relationship between gestural development and two demographic variables: sex and socio-economic status. 7.1 Measurement properties of CDI gestures 7.1.1 Measuring the development of gesture Unlike the word items on the CDI , which typically ask parents to make a binary decision about whether a word is in their child’s vocabulary (although comprehension and production are separate decisions), the First Gestures on CDI forms ask parents to make a 3-way decision, determining if their child produces a given gesture “often”, “sometimes”, or “not yet.” We begin by asking whether parents responses are sensitive to this distinction, as the choice of whether to treat all three levels as meaningful impacts downstream analytic decisions. We perform this sensitivity analysis on the American English CDI as it is the inventory for which we have the best a priori intuitions. The Figure below shows the proportion of American English learning children who give each of these responses. If each of the three responses is meaninfully different, the developmental trajectory of each should be distinct and predictable. The proportion of children whose parents indicate that they do “not yet” produce each gesture declines predictably over development. However, the other two responses – “sometimes” and “often” – do not appear to have reliably different trajectories. Perhaps they are used differently by different parents or in different samples. For comparision, we collapse the “sometimes” and “often” into a single value, and plot the proportion of children at each age whose parents report that they produce each gesture. The trajectories look generally smooth and prima facie reasonable, with the potential exception of the “smacklip” gesture for which there is very litte developmental change (this gesture, which corresponds to the vocalization “yum yum,” may be unusual or less stereotyped). While these gestures are categorized on the CDI as “first gestures,” the form also asks parents about a variety of other kinds of gestures that children produce, including those involved in games and pretend play. Do these gestures have similar trajectories? The Figure below plots developmental trajectries for these other categories of gesture. While some are clearly learned later than the early gestures, a number of these appear to be learned quite early as well – for example, peekaboo and pretend play with cups and spoons. They all also appear to have generally smooth and increasing trajectories with the exception of “so big” (from the Games gestures) which, like “smack lips” from the First Gestures section appears to be either less stereotyped, more difficult to identify, or more variable across children. Taken as a whole, it is clear that almost all of the gesture items have developmental trajectories not unlike word items, and that they thus have the potential for informative analyses. Further, trajectories look qualitatively similar across categories. Consequently, for general cross-linguistic analyses, we will consider all of the gestures together, and compress “often” and “sometimes” into a single affirmative choice. To estimate the coherence of these categories, we compute Age of Acquisition estimates for each of the American English gestures by gesture type: First Gestures (e.g. “pick me up”, “point”), Game Gestures (e.g. “play peekaboo”, “chase”), Object Gestures (e.g. “brush teeth”, “push car”), Adult gestures (e.g. “type”, “use pen”), and Parent Gestures (e.g. “sweep”, “feed from a spoon”). These estimates were produced by fitting a robust linear regression to the proportion of children who produce each gesture and estimating the age at which 50% of children produce the given gesture. These categories vary in coherence, but overall First Gestures and Games tend to be produced early, and Adult and Parent gestures – more representative of pretend play – are produced relatively later. The object gestures vary substantially in their ages of acquisition. 7.1.2 Consistency of the First Gestures While the “First Gestures” are not universally learned before the other gestures measured, they are among the earliest learned. Because of the particular theoretical importance of these early communicative gestures (i.e. deictics like pointing and showing, showing routines like “pick me up”), we analyze the cross-linguistic consistency of these at the item level. Unilemma mean sd n pick me up 8.0 1.7 7 give 8.9 1.5 7 show 8.9 1.2 9 point 9.1 2.2 8 request 9.8 4.2 8 shake head 9.9 1.9 8 wave 9.9 1.9 8 smack lips 10.9 3.9 7 nod head 14.5 3.8 8 hush 15.2 3.0 7 shrug 15.7 3.8 7 blow kiss 16.0 1.9 6 The figure below shows both consistency and variability across items. As in the learning of words, the means and variances of these ages of acquisition were correlated (r = 0.46; Mollica and Piantadosi 2017). The primary outliers were “request”, which appears to be produced surprisingly late in American English, and “shrug” which was produced surprisingly late by French-learning infants. In general, however, most of the cross-linguistic differences appear to be consistent across the gestures (i.e. French-learning infants gestures later). It is difficult to tell from this small sample of mostly European languages whether these differences are driven by linguistic factors or rather by properties of our samples or variability in parents’ interpretation of the form. Nonetheless, they provide some evidence for consistency in the process of gestural development cross-linguistically. To get additional leverage on this process, we next consider the full set of gestures. 7.1.3 Intercorrelation among gestures Given both the similarity and the variability in the developmental trajectories of different gestures, as well as the cross-linguistic variability in first gestures, and a natural next is to quantify the relationship of gestures to each-other. We begin by computing the average intercorrelation between each of these gesture categories. In this analysis, we take gestures in pairs (e.g. “adult gestures” and “first gestures”) and ask how the proportion of items that kids know in one predict the proportion of items they know in the other. For American English learning children, the proportion of gestures they know across categories is correlated at p = 0.6000678–nearly identical to the value of ~6 reported by Fenson et al. (1994). For comparison, the same intercorrelation computed across categories of words (e.g. “animals” and “places”) yield 0.643456 for production and 0.5657221 for comprehension. This cross-category intercorrelation is quite similar cross-linguistically, ranging from 0.56 in French (French) to 0.84 in Korean. The full table of intercorrelations can be found below. language mean sd English (American) 0.60 0.113 French (French) 0.56 0.178 Hebrew 0.60 0.141 Italian 0.68 0.104 Korean 0.84 0.129 Norwegian 0.57 0.110 Slovak 0.69 0.080 Spanish (Mexican) 0.67 0.087 7.2 The relationship between language and gesture A critical theoretical question in early communicative development concerns the relationship between language and gesture. As alluded to above, a number of early influential theories (e.g., Piaget 1962; Werner and Kaplan 1963) held that gesture and language should be intimately related becuase of their reliance on a shared system of symbolic reasoning. To the extent that they are underpinned by the same system, words and gestures should have related developmental trajectories–children who gesture early should also speak early and vice versa (Bates, Bretherton, and Snyder 1991). Following in the footsteps of Fenson et al. (2007), we ask this question at larger scale, and cross-linguistically. To assess this relationship, we will look at the correlations between children’s gestural and linguistic vocabularies. To first provide a baseline, however, we compute the correlation between children’s language and gesture development and their age. As the table below shows, gesture shows as mnuch or more development than comprehension and production over the ages measured by the CDI Words and Gestures forms, and the variability in the correlation with age in all three measures hangs together within-language: Languages where there is more developmental change in linguistic developmnet also tend to have more gestural development. language gesture comprehension production English (American) 0.73 0.60 0.46 French (French) 0.56 0.31 0.29 Hebrew 0.66 0.67 0.65 Italian 0.81 0.76 0.61 Korean 0.54 0.61 0.44 Norwegian 0.70 0.72 0.55 Slovak 0.66 0.66 0.50 Spanish (Mexican) 0.71 0.55 0.36 However, as we noted in Chapter 4, comprehension and production do not proceed in lock-step and comprehension generally outpaces production. This is, in part, because production requires additional control over the developming motor systems necessary for speech. To the extent that gesture and language are related by their shared reliance on symbolic understanding, their correlation should be highest when only this shared system is tapped. In this case, we should predict that gesture production and language comprehension are more tightly correlated than gesture production and language production. In contrast, if the correlation is due primarily to a shared desire to communicate and engage socially with caregivers, we should predict a stronger correlation between gesture production and language production. Across these 8 language, children’s production of gestures is consistently more highly correlated with their comprehension (Table below). language comprehension production English (American) 0.75 0.53 French (French) 0.67 0.37 Hebrew 0.78 0.65 Italian 0.81 0.49 Korean 0.51 0.45 Norwegian 0.69 0.50 Slovak 0.63 0.54 Spanish (Mexican) 0.76 0.55 7.3 Gesture and Demographic Variables Type and sex. Small female advantage overall, but big interaction in gestures_parent term estimate std.error statistic (Intercept) 0.082 0.039 2.09 age 0.044 0.001 40.47 sexMale -0.009 0.021 -0.44 typegestures_games 0.154 0.017 8.96 typegestures_objects -0.432 0.017 -26.07 typegestures_parent -0.622 0.017 -37.22 typegestures_adult -0.551 0.017 -33.13 age:sexMale -0.002 0.001 -1.57 age:typegestures_games -0.007 0.001 -6.00 age:typegestures_objects 0.020 0.001 17.51 age:typegestures_parent 0.019 0.001 15.77 age:typegestures_adult 0.019 0.001 16.10 sexMale:typegestures_games -0.038 0.024 -1.58 sexMale:typegestures_objects 0.095 0.023 4.15 sexMale:typegestures_parent 0.232 0.023 9.99 sexMale:typegestures_adult 0.001 0.023 0.06 age:sexMale:typegestures_games 0.003 0.002 1.88 age:sexMale:typegestures_objects -0.006 0.002 -3.76 age:sexMale:typegestures_parent -0.024 0.002 -14.96 age:sexMale:typegestures_adult 0.006 0.002 3.57 Type and ses. Very small low-ses advantage? term estimate std.error statistic (Intercept) -0.497 0.051 -9.8 age 0.064 0.001 60.9 typegestures_first 0.585 0.015 39.4 typegestures_games 0.739 0.015 49.8 typegestures_objects 0.129 0.015 8.7 typegestures_parent 0.027 0.015 1.8 seslow -0.020 0.020 -1.0 age:typegestures_first -0.026 0.001 -25.8 age:typegestures_games -0.030 0.001 -29.7 age:typegestures_objects -0.005 0.001 -5.4 age:typegestures_parent -0.017 0.001 -17.1 typegestures_first:seslow 0.068 0.007 9.9 typegestures_games:seslow -0.054 0.007 -7.8 typegestures_objects:seslow 0.069 0.007 10.1 typegestures_parent:seslow 0.095 0.007 13.8 age:seslow 0.001 0.001 0.4 "],
["items-consistency.html", "8 Consistency in Early Vocabulary", " 8 Consistency in Early Vocabulary Which words do children learn first? In spite of tremendous individual variation in rate of development (Fenson et al. 1994; Hart and Risley 1995), the first words that children utter are strikingly consistent (Tardif et al. 2008): they tend to talk about important people in their life (“mom”, “dad”), social routines (“hi”, “uh oh”), animals (“dog”, “duck”), and foods (“milk”, “banana”). As children learn from their experiences and according to their own interests (Mayor and Plunkett 2014) their vocabulary grows rapidly, typically adding more nouns, but also verbs (“go”) and other predicates (“hot”) to their production repertoires. Indeed, variability in the difficulty of words–and presumably the consistent of this difficulty across children–is a key feature of models that attemtpt to characterize global features of language learning(e.g McMurray 2007; Mollica and Piantadosi 2017; Blythe, Smith, and Smith 2010). In the latter part of this chapter, we ask why some words are learned before others. In future chapters, we will take up the question of why some words are learned before others. In this chapter, we as the prior question: Are words learned in the same order, and at the same rate, across languages? Similar trajectories–no matter their proximal causes–suggest that these causes are consistent across languages. As detailed in the Chapter 2, the items on each language’s form are adaptations and not translations: They are intended to capture the spirit of the items on the English form rather to replicate them exactly. Nonetheless, when translation equivalents exist on multiple forms we can look at the variability in how quickly they are acquired across languages. To estimate the similarlity of each item’s trajectories, we use a single measure of it’s difficulty: Age of acquisition (AOS)–The age at which 50% of children in each language are estimated to have acquired it (Appendix D). We analyzed consistency in both comprehension and production, with production ages of acquisition estimated by stitching across both forms. Consequently, we analyzed only the 29 languages for which data for both forms was available. In total, we estimated ages of acquisition for 945 total words spread across the 29 languages. Unfortunately, not evey word appeared on all forms. The figure below shows the cumulative proportion of forms on which every word appears. For our consistency analysis, we considered only the 335 words that appeared in at least 8 of the 15 languages. Following Tardif et al. (2008), we begin by examining the first 10 words acquired by children across the 15 languages we measured. Similar words appeared in the Top 10 across languages, especially in children’s first productions. These words consisted primarily of important family members (“mommy”, “daddy”, “grandma”), social routines (“hi”, “bye”, “peekaboo”), and sounds (“yum yum”, “vroom”, “woof woof”). Unfortunately, we cannot determine if the greater consistency found in early production is a real regularity about children’s lexical development, or is instead a measurement artifact arising from the greater difficulty of reporting on a child’s comprehension (see Chapter 4). Production Comprehension Despite these differences between comprehension and production, words reported to be acquired early in one are also generally reported to be acquired early in the other. The Figure below shows the relationship between the mean age of acquisition in production and the mean age of acquisition of the each of these 335 words across the 15 languages. The correlation between the two measures was quite high: 0.8 (p = &lt; .001). Consistency across languages Production and comprehension consistency Production dendrogram Comprehension dendrogram Consistency across acquisition order Consistency across acquisition order "],
["items-demographics.html", "9 Demographic Variation in Individual Words18 9.1 Methods 9.2 Results 9.3 Conclusions", " 9 Demographic Variation in Individual Words18 In Chapter 6, we documented demographic differences in total vocabulary. But where do these differences reside? Concretely, if girls say more words than boys, which words do they say? Is it the case that they simply produce each word more with some probability, or are there individual words that are more likely to be produced? Or are both true? In this chapter, we consider the possibility that individual words carry this demographic signal. We assess which words are learned differentially earlier or later by girls vs. boys, by first-born vs. later-born children, and by children with different levels of maternal education. 9.1 Methods 9.1.1 Data Various subsets of the datasets in Wordbank are coded for one or more demographic variables. Here we examine the child’s birth order, level of maternal education, and assigned sex at birth. For these analyses we extract all of the instruments with demographically coded data and combine them into two datasets: comprehension from WG forms, and production from both WG and WS forms. (We use the “by item stitching” approach described in Appendix C). This approach creates six different analyses, one for each combination of demographic variable and measure. We exclude a language from a given analysis if it has fewer than 50 children for that demographic variable and measure. The demographic variables are coded into the values First / Second / Third+ for birth order, Below Secondary / Secondary / College and Above for maternal education, and Female / Male for sex. Each dataset yields a trajectory for each word, created by smoothing the number of children that ar are reported to understand or produce the word over age. These trajectories can be computed separately for each value of the demographic variable. For example, in the figure above, these are the trajectories for some sample items in English for production data split by birth order. Note that the wqord “brother” is spoken much later by first-born children than by later-born children, whereas “green” is spoken much later by later-born children. Averaging all of these trajectories together reproduces the general demographic achivement curves reported in Chapter 6. The goal of the analyses is to quantify the overall effect of each demographic variable, i.e. the differences among the above curves, and the individual contribution of each item to that effect. 9.1.2 Models There are a number of complementary methods to estimate individual item effects. In Chapter 6, we explored a simple, non-parametric approach to estimating demographic effects across groups. Here we are interested in estimating these effects for individual items, and thus data are sparser for each individual item. Thus, it is more effective to use a multi-level, model-based analysis in which demographic effects are estimated both at the level of all items and specifically for individual items. In particular, we use a mixed-effects logistic regression to predict how many children produce/understand items from their age and their level for a given demographic variable, with a random effect for item. A model of this type is fit separately for the data for each language and measure. For example, the model for birth order would be specified as: cbind(num_true, num_false) ~ (age + birth_order | definition) + age + birth_order For each demographic variable, we specify the contrasts such that their coefficient compares each level of the variable to the previous level. For example, the coefficents for birth order reflect the overall difference between second-born children as compared to first-born and the overall difference between third- (and later-) born as compared to second-born. The items’ random slopes for each demographic indicate for each individual item, the contribution to those same differences over the main effect. 9.2 Results The primary target of our analysis are the item random effects for each demographic variable, indicating our best estimate of the specific effect of a particular demographic on a particular item. These item random effects factor out the fixed, main effect of the demographic (the effects we reported in Chapter 6), thus they are centered at zero. But their magnitude and direction can be interpreted for individual effects. The plots below show the distribution of item random effects for each demographic variables and measure, with the top and bottom 3 items labelled. As well as the general qualitative shape of the distributions, it is these extreme items that we are most interested in. One interesting question is the extent to which extreme items differ. The plot above shows the distribution of demographic random effects across all languages (selecting only sex effects for production), using a quantile-quantile (QQ) plot. In QQ plots, points on a diagonal line indicate conformity to the standard normal distribution, while deviations suggest differences in distributional form. Looking at the resulting plot yields a broad, low-slope diagonal (a normal distribution) with skewed tails. Further, the majority of coefficients are within a very tight range: only 1.6% of coefficients are outside of .5 logistic units in magnitude. Thus, as hypothesized, all of the action is in the tails of the distribution: a few words vary substantially in how often they are produced according to some demographi feature. In the following subsections we examine the coefficients and their distributions for individual words/languages. 9.2.1 Sex As shown in Chapter 6, there is a highly consistent advantage for females in language production. This advantage is slightly less pronounced for comprehension but still present. However, independently of this advantage, we also see specific items emerge as understood differentially for males or females. The figure above gives the full distribution for comprehension, and the table gives the items outside of the .5 logistic units threshold, across all languages. These are almost exclusively traditionally gendered items – for English, for example, the words with a substantial male advantage are vehicle-related and “hammer”, while the female advantage words are “purse” and “necklace.” Thus, our first impression is that these tend to be specific content items assocciated with gendered play. The figure and table above give the same measures for production. There are considerably more words per language with substantial gender biases for production (11.36) than for comprehension (3.8333333). But the content of these is extremely similar. For English, we see a male bias for vehicles and objects associated with traditionally male activities (e.g., sports), and a female bias for genital words and clothing. This pattern is replicated quite robustly across languages, although with varying magnitudes. In sum, there appear to be two different processes at work in the gender effects we observe. The first is a general shift in the the probability that any word will be produced or understood such that females are slightly more likely to produce it. The average magnitude of this fixed effect is -0.42. In other words, if a female had a 50% chance of saying a word, a male would on average have a 40% chance of saying it. However, beyond this fixed effect, there are also variable effects for individual words. Most of these effects are small, but a few of them are quite large. For example, if an English-speaking female child had a 50% chance of saying the word “dress” (clothing), a male child would have an 12% chance of saying it. 9.2.2 Birth order Again following Chapter 6, we consider individual items that are more or less likely in the vocabularies of first-born vs. later-born children. Here we consider both the contrast between second- and first-born children as well as between third- or later-born and second-born children. The number of languages for which we have birth order data is dramatically smaller, however, so conclusions are necessarily more tentative. The figure and table above again represent random effects coefficients for particular items in comprehension. In general there are few surprises here: the words for “brother” and “sister” are much more likely for second-born children to understand, and even more likely for later-born children. The Norwegian data additionally show a few other words that second- and later-born children might be more likely to be exposed to via their siblings, including “skole” (school) and “sukkertøy” (sweets, hard candy). The same general patterns are present in the production data, with further evidence that having elder siblings appears to be related exposure to sweets, at least in some cultures: “popsicle,” “donut,” and “candy” all appear now in the English data, and “tyggegummi” (gum) and several soda- and candy-related words appear in the Nowegian data. (“Hate” also appears in the English data, suggesting some emotional expressions due to having a sibling). We interpret this pattern with caution, however, as birth order is likely partially confounded with socio-economic status, and so later-born children might also be from low-SES families who have more environmental exposure to “junk foods” like soda and candy. 9.2.3 Maternal Education Our final set of analyses examine vocabulary items that are differentially present in the vocabulary of children with lower maternal education. As noted in Chapter 6, there are substantial cross-linguistic differences in how large the overall socioeconomic stratification is. For example, we observe large differences in children’s vocabulary size in the English (American) data, with children of less educated mothers reporting substantially lower production vocabulary. The figure and table above show comprehension results. The majority of words that exceed our (somewhat arbitrary) .5 bound come from the English (American) data. This finding is consistent with the idea that there may be more substantial maternal education effects in this dataset more generally. The words that are more likely to be understood by children of college- and secondary- educated mothers are often animal-related and may speculatively be related to reading books about animals (since these farm animals might not be prominent in all children’s experience). “Read” is also on this list, perhaps related to reading practices (or the perception of the importance of these practices). Negatively linked words include “cake” (supporting the speculation above) and a number of other items that are perhaps harder to interpret as being SES-linked. Production data show a similar but more extreme picture, with a larger number of words linked to maternal education. Examination of the English data suggests that animal vocaulary is again more prevalent for the children of more educated parents (as are babysitters). Again supporting the birth-order/maternal education link, “brother” is less common for the children of more highly educated moms, as are “candy,” “gum,” and “soda.” Again, the most extreme linkage to maternal education was found in the English (American) sample. 9.3 Conclusions Demographic factors like sex, birth order, and maternal education are related to children’s vocabulary size. But in addition to these more global associations, they appear to be specifically associated with particular vocabulary items. Many of these are straighforwardly explicable in terms of differences in the environmental frequency (and importance) of particular lexical items for children in different circumstances. For example, there are many reasons why second-born children should say “brother” or “sister” more frequently than first-born children! More generally, item level variation relates to two issues of interest within the context of our project. The first is the validity of CDI-based measuserment. From a psychometric perspective, the sort of variation reported here is known as “differential item function” (Hambleton, Swaminathan, and Rogers 1991) and is a negative characteristic of tests that impairs their validity. Thus, from a test-design perspective, items like “babysitter” (or even “brother”) should probably not be included. (See Chapter 4 for more details on this issue). The second broader issue is the question of mechanisms responsible for the demographic associations documented in Chapter 6. Sex differences in vocabulary appear quite consistent across languages. Why is this? We gain one small piece of leverage on the issue by noticing that there appear to be two qualitatively different processes involved in the demographic effects we observed: first, girls have a small bump in their probability of producing almost every word, and second, there are a small number of particular words for which their production probability is substantially different. To the extent these are separable, we might look for causal mechansisms that would provide a broader boost to language (rather than trying to explain the small number of spefically gender-linked items identified above). Such hypotheses might appeal to dyadic factors like differences in amount of language input directed to girls, or learner-internal factors like stronger social cognition. An earlier version of the gender analyses below was presented to the Boston University Conference on Language Development in 2016↩ "],
["items-prediction.html", "10 Predictive Models of Individual Words19 10.1 Methods 10.2 Results 10.3 Discussion", " 10 Predictive Models of Individual Words19 As discussed in Chapter 1, one classic approach to word learning focuses on the specific mechanisms that children bring to bear on the learning problem. For example, across many laboratory experiments, a variety of mechanisms have been identified as plausible drivers of early word learning, including co-occurrence based and cross-situational word learning (Schwartz and Terrell 1983; Yu and Ballard 2007); social cue use (Baldwin 1993); and syntactic bootstrapping (Gleitman 1990; Mintz 2003). The ability to identify which of these mechanisms is most explanatory has been challenging. Indeed, many theories of early word learning take multiplicity of cue types and mechanisms as a central feature (e.g., Hollich et al. 2000; Bloom 2000). As important as this work is, though, these studies typically are aimed at understanding how one or a small handful of words are learned in the laboratory under precisely-defined learning conditions. They do not directly address questions regarding the developmental composition and ordering of growth in the lexicon across many different children in their natural environments nor whether these patterns are consistent across different languages. Why are some words learned so early and some much later? This question about the order of the acquisition of first words can provide a different window into the nature of children’s language learning. Posed as a statistical problem, the challenge is to find what set of variables best predicts the age at which different words are acquired. Previous work using this approach has revealed that, in English, within a lexical category (e.g., nouns, verbs), words that are more frequent in speech to children are likely to be learned earlier (Goodman, Dale, and Li 2008). Further studies have found evidence that a variety of other semantic and linguistic factors are related to word acquisition, such as salience and iconicity (Hills et al. 2009; Stokes 2010; Perry, Perlman, and Lupyan 2015; Roy et al. 2015; Swingley and Humphrey 2017). These exciting findings are limited in their generality because each study used a different dataset and focused on different predictors. In addition, nearly all studies to date have exclusively analyzed data from English-learning children, providing no opportunity for cross-linguistic comparison of the relative importance of the many relevant factors under consideration. Such cross-linguistic comparisons are critical. Identifying commonalities (and differences) across languages is our best strategy for uncovering the universal mechanisms that are in play for all children and differentiating them from patterns of acquisition that emerge due to the particulars of a given language or culture (Slobin 1985; Bates and MacWhinney 1987). In this chapter, we use the Wordbank data to extend these classic approaches and assess the degree to which the predictors of word learning are consistent across different languages and cultures, as well as whether there are similar patterns across different word types (e.g., nouns vs. verbs). We conduct cross-linguistic comparisons of the age of acquisition of particular words. We integrate estimates of words’ acquisition trajectories from the Wordbank data with independently-derived characterizations of the word learning environment from other datasets. The use of secondary datasets for these analyses is warranted because no currently available resource provides data on both children’s language environments and their learning outcomes for more than a small handful of children. In particular, we derive our estimates of the language environment from transcripts of speech to children in the CHILDES database (MacWhinney 2000). This data-integration methodology was originated by Goodman, Dale, and Li (2008); it relies on large samples to average out the (substantial) differences between children and care environments. While introducing additional sources of variability, it also allows for analyses that cannot be performed on smaller datasets or datasets that measure only child or environment but not both. As our particular measures of environmental input, we estimated each word’s (a) frequency in parent speech to children, (b) mean length of the parent utterances containing that word (MLU), (c) frequency as a sole utterance constituent, and (d) frequency in utterance-final position. While these measures are crude, they are both easy to compute and relatively comparable across the languages in our sample. To derive proxies for the meaning-based properties of each word, we accessed available psycholinguistic norms using adult ratings of each word’s (a) concreteness, (b) valence, (c) arousal, and (d) association with babies. Integrating these two groups measures, which are based respectively on estimates of children’s linguistic environment and words’ meaning, we predict each words’ acquisition trajectories. We assess the relative contributions of each predictor, as well as how those predictors change over development and interact with the lexical category of the word being predicted. Since vocabulary composition differs in comprehension and production (e.g., Benedict 1979), we conduct our analyses on measures of each. These analyses address two questions. First, we ask about the degree of consistency across languages in the relative importance of each predictor. Consistency in the patterning of predictors would suggest that similar information sources are important for learners, regardless of language. Such evidence would suggest that superficial linguistic dissimilarities (e.g., greater morphological complexity in Russian and Turkish, greater phonological complexity in Danish) do not dramatically alter the course of acquisition. Conversely, variability would show the degree to which learners face different challenges in learning different languages, posing a challenge for more universalist accounts. Further, systematicity in the variability between languages would reveal which languages are more similar then others in the structure of these different challenges. Second, we ask which lexical categories are most influenced by linguistic environment factors, like frequency and utterance length, compared with meaning-based factors like concreteness and valence. Division of dominance theory suggests that nouns might be more sensitive to meaning factors, while predicates and closed-class words might be more sensitive to linguistic environment factors (Gentner and Boroditsky 2001). And on syntactic bootstrapping theories (Gleitman 1990), nouns are argued to be learned via frequent co-occurrence (operationalized by frequency) while verbs might be more sensitive to syntactic factors (operationalized here by utterance length) (Snedeker, Geren, and Shafto 2007). Thus, examining the relative contribution of different predictors across lexical categories can help test the predictions of influential theories of acquisition. 10.1 Methods 10.1.1 Acquisition trajectories Since analyses in this chapter rely on unilemma mappings (see Chapter 3), the set of languages represented is smaller than in other chapters. We use data from the items on WG forms for our comprehension measure, and data from the items in common between WG and WS forms for our production measure. Table gives an overview of our acquisition data. Each of the datasets were conducted in contexts in which the particular language was the language of the community, e.g., the Mexican Spanish CDI data were collected in several areas of Mexico; longitudinal administrations were excluded. Language CDI items N Ages N Ages Types Tokens Croatian 388 627 8-30 250 8-16 12,064 218,775 Danish 381 6,112 8-36 2,398 8-20 4,956 195,658 English 393 7,312 8-30 1,792 8-18 45,597 7,679,042 French 396 1,364 8-30 537 8-16 28,819 2,551,113 Italian 392 1,400 7-36 648 7-24 7,544 188,879 Norwegian 380 7,466 8-36 2,374 8-20 10,670 231,763 Russian 410 1,805 8-36 768 8-18 5,191 32,398 Spanish 399 1,891 8-30 788 8-18 33,529 1,609,614 Swedish 371 1,367 8-28 467 8-16 8,815 359,155 Turkish 395 3,537 8-36 1,115 8-16 6,503 44,347 See Figure for example item curves of the type being predicted in our subsequent analyses. Figure 10.1: Example production trajectories for the words “dog” and “jump” across languages. Points show the proportion of children producing each word for each one-month age group. Lines show the best-fitting logistic curve. Labels show the forms of the words in each language. 10.1.2 Word properties For each word that appears on the forms in each of our 10 languages, we used corpora of child-directed speech in that language from CHILDES to obtain an estimate of its frequency, the mean length of utterances in which it appears, its frequency as the sole constituent of utterance, and its frequency in utterance final position (with frequency residualized out of solo and final frequencies). Additionally, we computed each word’s length in phonemes. To capture meaning-based factors in acquisition, we included ratings of each word’s concreteness, valence, arousal, and relatedness to babies. All of these ratings were compiled based on previous studies using adult raters. In addition, since existing datasets for all of these ratings are primarily available for English, we mapped all the words in our datasets onto translation equivalents across CDI forms, verified by native speaker judgement, allowing us to use the ratings for English words across languages. Of the resulting translation equivalent meanings, 35% occur only in one language, 51% occur in more than one but not all languages, and 14% occur in all languages. While necessarily imperfect, this method allows us to examine languages for which limited resources exist. Example words for these predictors in English are shown in Table . Table 10.1: Items with the highest and lowest values for each predictor in English. Predictor Highest Lowest Arousal naughty, money, scared blanket, asleep, shh Babiness baby, bib, bottle jeans, penny, donkey Concreteness apple, baby, ball that, now, how Final frequency book, it, there put, when, give Frequency you, it, that babysitter, rocking chair, grrr MLU when, day, store ouch, thank you, peekaboo Number phonemes refrigerator, cockadoodledoo, babysitter i, eye, ear Solo frequency no, yes, thank you feed, bathroom, tooth Valence happy, hug, love ouch, hurt, sick Previous studies have shown robust consistency in the types of words that children learn very early (Tardif et al. 2008). These words seem to describe concepts that are important or exciting in the lives of infants in a way that standard psycholinguistic features like concreteness do not. Capturing this intuition quantitatively is difficult, but Perry, Perlman, and Lupyan (2015) provides a proxy measure as a first step. This measure is simply the degree to which a particular word was “associated with babies.” Intuitively, we expect this measure to capture the degree to which words like “ball” or “bottle” feature heavily in the environment (and presumably, mental life) of many babies. Each numeric predictor was centered and scaled so that all predictors would have comparable units. For each predictor, missing values (CDI items that were not in the relevant corpus or norms) were imputed from the mean for their respective language and measure. Placeholder items, such as “child’s own name,” were excluded. Frequency. For each language, we estimated word frequency from unigram counts based on all corpora in CHILDES for that language. Frequencies varied widely both within and across lexical categories. Each word’s count includes the counts of words that share the same stem (so that “dogs” counts as “dog”) or are synonymous (so that “father” counts as “daddy”). For polysemous word pairs (e.g., “orange” as in color or fruit), occurrences of the word in the corpus were split uniformly between the senses on the CDI (there were only between 1 and 10 such word pairs in the various languages; in the absence of cross-linguistic corpus resources for polysemy sense disambiguation, this is a necessary simplification). Counts were normalized to the length of each corpus, Laplace smoothed (i.e., count of 0 were replaced with counts of 1), and then log transformed. Solo and Final Frequencies. Using the same dataset as for frequency, we estimated the frequency with which each of word occurs as the sole word in an utterance, and the frequency with which it appears as the final word of an utterance (not counting single-word utterances). As with frequency, solo and final counts were normalized to the length of each corpus, Laplace smoothed, and log transformed. Since both of these estimates are by necessity highly correlated with frequency, we then residualized unigram frequency out of both of them, so that values reflect an estimate of the effects of solo frequency and final frequency over and above frequency itself. MLU. MLU is only a rough proxy for syntactic complexity, but is relatively straightforward to compute across languages (in contrast to other metrics). For each language, we estimated each word’s MLU by calculating the mean length in words of the utterances in which that word appeared, for all corpora in CHILDES for that language. For words that occurred fewer than 10 times, MLU estimates were treated as missing. Number of phonemes. In the absence of consistent resources for cross-linguistic pronunciation, we computed the number of phonemes in each word in each language based on phonemic transcriptions of each word obtained using the eSpeak tool (Duddington 2012). We then spot-checked these transcriptions for accuracy. Concreteness. We used previously collected norms for concreteness (Brysbaert, Warriner, and Kuperman 2014), which were gathered by asking adult participants to rate how concrete the meaning of each word is on a 5-point scale from abstract to concrete. Valence and Arousal. We also used previously collected norms for valence and arousal (Warriner, Kuperman, and Brysbaert 2013), for which adult participants were asked to rate words on a 1-9 happy-unhappy scale (valence) and 1-9 excited-calm scale (arousal). Babiness. Lastly, we used previously collected norms of “babiness”, a measure of association with infancy (Perry, Perlman, and Lupyan 2015) for which adult participants were asked to judge a word’s association with babies on a 1-10 scale. Lexical category. Category was determined on the basis of the conceptual categories presented on the CDI form (e.g., “Animals”, “Action Words”), such that the Nouns category contains common nouns, Predicates contains verbs and adjectives, and Function Words contains closed-class words (following Bates et al. 1994). Colinearity. A potential concern for comparing coefficient estimates is predictor collinearity. Fortunately, in every language, the only relatively correlations were between MLU and solo frequency (mean over languages \\(r =\\) -0.54), as expected given the similarity of these factors, along with modest correlations between frequency and concreteness (mean over languages \\(r =\\) -0.39) and between frequency and number of phonemes (mean over languages \\(r =\\) -0.35), a reflection of Zipf’s Law (Zipf 1935). More importantly, the variance inflation factor for each of the predictors in each language is no greater than 2.4550255, indicating that multicollinearity among the predictors is low. 10.1.3 Analysis We used mixed-effects logistic regression models (fit with the MixedModels package in Julia; Bates et al. 2018) to predict whether each child understands/produces each word from the child’s age, properties of the word, and interactions between age and each property of the word. Each model was fit to all data from a particular language and included a random intercept for each word and a random slope of age for each word. We also fit such models separately to the words in each lexical category. The magnitude of the standardized coefficient on each feature gives an estimate of its effect on whether words are learned earlier or later. Interactions between features and age give estimates of how this effect is modulated for earlier and later-learned words. For example, a positive effect of association with babies (“babiness”) means that words associated with babies are learned earlier; a negative interaction with age means that high babiness primarily leads to higher rates of production and comprehension for younger children. 10.2 Results Figure 10.2: Estimates of coefficients in predicting words’ developmental trajectories for English comprehension data. Larger coefficient values indicate a greater effect of the predictor on acquisition: positive main effects indicate that words with higher values of the predictor tend to be understood by more children, while negative main effects indicate that words with lower values of the predictor tend to be understood by more children; positive age interactions indicate that the predictor’s effect increases with age, while negative age interactions indicate the predictor’s effect decreases with age. Error bars indicates 95% confidence intervals; filled in points indicate coefficients with p &lt; 0.05. Figure 10.3: Estimates of coefficients in predicting words’ developmental trajectories for all languages and measures. Each point represents a predictor’s coefficient in one language, with the large point showing the mean across languages. Predictor effects. Figure shows the coefficient estimates for English comprehension data, while Figure shows the coefficient estimate for each predictor in each language. We find that frequency (mean over languages and measures \\(\\bar{\\beta} =\\) 0.29), babiness (\\(\\bar{\\beta} =\\) 0.27), concreteness (\\(\\bar{\\beta} =\\) 0.23), and solo frequency (\\(\\bar{\\beta} =\\) 0.21) are relatively stronger predictors of acquisition across languages (as well as all having significant effects at \\(\\alpha = 0.05\\) in at least 15 of the 20 languages and measure). These effects, along with final frequency and valence, are positive in all or almost languages (so words with higher babiness tend to be known by more children); while the effects of number of phonemes and MLU are negative in all or almost all languages (so longer words tend to be known by fewer children). Given the emphasis on frequency effects in the language acquisition literature (Ambridge et al. 2015), one might have expected frequency to dominate, but several other predictors are just as strong in this analysis. In addition, some factors previously argued to be important for word learning, namely valence and arousal (Moors et al. 2013), appear to have limited relevance when compared to other factors (both have \\(\\bar{\\beta} &lt;\\) 0.06 and are only significant in 4 languages and measures). These results provide a strong argument for our approach of including multiple predictors and languages in our analysis. Figure 10.4: Correlations of coefficients estimates between languages. Each point represents the mean of one language’s coefficients’ correlation with each other language’s coefficients, with the vertical line indicating the overall mean across languages. The shaded region and line show a bootstrapped 95% confidence interval of a randomized baseline where predictor coefficients are shuffled within language. Figure 10.5: Dendrograms of the similarity structure among languages coefficients. Figure 10.6: Estimates of coefficients in predicting words’ developmental trajectories for each language, measure, and lexical category. Consistency. Overall, there is considerable consistency in the magnitudes of predictors across languages. In almost all, babiness and frequency were highest, while valence and arousal were smaller. A priori it could have been the case that different languages have wildly different effects of various factors (e.g., due to lingusitic or cultural differences in acquisition process), but this pattern is not what we observe. Instead, Figure shows the mean pairwise correlation of predictor coefficients across languages (i.e., the correlation of coefficients for English with coefficients for Russian, for Spanish, and so on). These means are far outside of bootstrapped estimates for the average pairwise correlation in a randomized baseline created by shuffling predictor coefficients within language, meaning that coefficient estimates are far more consistent across languages than would be expected by chance. Variability. While some particular coefficients differ substantially from the trend across languages (e.g., the effect of frequency for Spanish is near 0), these individual datapoints are difficult to interpret. Many unmeasurable factors could potentially account for these differences. For example, Spanish frequency estimates could be less accurate due to corpus sparsity or idiosyncrasy, the samples of children in the Spanish CDI data and CHILDES data could differ more demographically, or Spanish-speaking children could in fact rely less on frequency in acquisition. Rather than attempting to interpret individual coefficients, we instead ask how the patterns of difference among languages reflect systematic substructure in the variability of the effects. To examine the substructure of predictor variability, we used hierarchical clustering analysis to find the similarity structure among the pairwise correlations between languages’ predictors. The resulting dendrograms are shown in Figure , which broadly reflect language typology (especially for production data). This result suggests that some language-to-language similarity data is captured by the profile of coefficient magnitudes our analysis returns. Comprehension vs. production. Word length is the one predictor of acquisition that varied substantially between measures: it is far more predictive for production than comprehension. Thus as measured here, length seems to reflect effects of production constraints (i.e., how difficult a word is to say) rather than than comprehension constraints (i.e., how difficult it is to store or access). This result may explain why the hierarchical clustering analysis above appears more similar to linguistic typology in the production case than the comprehension case: the role of production difficulty may be more similar for more typologically related languages. Developmental change. We also wanted to examine how the relative contributions of the predictors changes over development. For both comprehension and production, positive age interactions can be seen in at least 9 out of 10 languages for concreteness and frequency. Conversely, there are negative age interactions for babiness, valence, and arousal for comprehension in at least 9 out of 10 languages. This suggests that while concreteness and frequency facilitate learning, they tend to do so more later in the development; and while babiness, valence, and arousal facilitate learning as well, they then to do so more earlier in development. This result is consistent with the speculation above that the babiness predictor captures meanings that have special salience to very young infants. Lexical categories. Previous work gives reason to believe that predictors’ relationship with age of acquisition differs among various lexical categories (Goodman, Dale, and Li 2008). To investigate these effects, we separated our data by lexical category and fit separate models for each category. Figure shows the resulting coefficient estimates. Across languages, frequency had the highest magnitude for nouns and a lower magnitude for function words. In contrast, MLU was almost irrelevant for both nouns and predicates, but highly predictive for function words. These patterns are supportive of the hypothesis that different word classes are learned in different ways, or at least that the bottleneck on learning tends to be different, leading to different information sources being more or less important across categories. Additionally, the mean pairwise correlation of coefficients between languages is much larger for nouns (0.7) and predicates (0.57) than for function words (0.3). The higher between-language variability for function words suggests the learning processes differ substantially more across languages for function words than they do for content words. 10.3 Discussion What makes words easier or harder for young children to learn? Previous experimental work has largely addressed this question using small-scale lab studies. While such experiments can identify sources of variation, they typically do not allow for different sources to be compared directly. In contrast, observational studies allow the effects of individual factors to be measured across ages and lexical categories (e.g., Goodman, Dale, and Li 2008; Hills et al. 2009; Swingley and Humphrey 2017). Such work has identified a number of candidate predictors of word learning. Our work expands the scope of these studies dramatically, leading to several new findings. First, we found consistency in the patterning of predictors across languages at a level substantially greater than the predictions of a chance model. This consistency supports the idea that differences in culture or language structure do not lead to fundamentally different acquisition strategies, at least at the level of detail we were able to examine. Instead, they are likely produced by processes that are similar across populations and languages. Such processes could include learning mechanisms or biases internal to children, or interactional dynamics between children or caregivers. We believe these consistencies should be an important topic for future investigation. Second, predictors varied substantially in their weights across lexical categories. Frequent, concrete nouns were learned earlier, consistent with theories that emphasize the importance of early referential speech (e.g., Baldwin 1995). But for predicates, concreteness was somewhat less important. And for function words, MLU was more predictive, perhaps because it is easiest to decode the meanings of function words that are used in short sentences (or because such words have meanings that are easiest to decode). Overall, these findings are consistent with some predictions of both division of dominance theory, which highlights the role of conceptual structure in noun acquisition (Gentner and Boroditsky 2001), and syntactic bootstrapping theory, which emphasizes linguistic structure over conceptual complexity in the acquisition of lexical categories other than nouns (Snedeker, Geren, and Shafto 2007). More generally, our methods here provide a way forward for testing the predictions of these theories across languages and at the level of the entire lexicon rather than individual words. In addition to these new insights, several findings emerged that confirm and expand previous reports. Environmental frequency was an important predictor of learning, with more frequently-heard words learned earlier (Goodman, Dale, and Li 2008; Swingley and Humphrey 2017). Predictors also changed in relative importance across development. For example, certain words whose meanings were more strongly associated with babies appeared to be learned early for children across the languages in our sample (as in Tardif et al. 2008). Finally, word length showed a dissociation between comprehension and production, suggesting that challenges in production do not carry over to comprehension (at least in parent-report data). The contents of this chapter are lightly adapted from Braginsky et al. (n.d.).↩ "],
["categories-syntactic.html", "11 Vocabulary Composition: Syntactic20 11.1 Introduction 11.2 Methods and Data 11.3 Results 11.4 Discussion", " 11 Vocabulary Composition: Syntactic20 This chapter focuses on splitting vocabulary data into syntactic categories and analyzing consistency and variability across languages in the acquisition of these. We quantify the “noun bias” across languages. In addition, we report the degree of bias for or against verbs and closed-class words. In Chapter 14, we consider variation of this sort within individuals. 11.1 Introduction Over the first few years, young children are exposed to a “sea of words” across many different contexts and from many different people (Goodman, Dale, and Li 2008, 516). And despite the fact that children vary tremendously in the rate at which they learn, the first words that children utter are strikingly consistent (Tardif et al. 2008; Schneider, Yurovsky, and Frank 2015): They tend to talk about important people in their life (mom, dad), social routines (hi, uh oh), animals (dog, duck), and foods (milk, banana) (Goodman, Dale, and Li 2008, @bates1995; Nelson 1973; Clark 1979). Soon thereafter, they begin to add verbs (go) and adjectives (pretty) in greater proportions than earlier in development and may even begin to use closed-class forms, such as determiners (the). These patterns seem to suggest a developmental course that follows distinct “waves” of learning for words from different classes. That is, along with early social routines, nouns tend to predominate early vocabularies, while other types of words, such as predicates and closed class forms, are learned later. This pattern may be further qualified by differences in the types of words learned in comprehension vs. production (Benedict 1979). The composition of early vocabulary is complicated by the fact that we categorize words by their adult syntactic category. We do so in the discussion below without presupposing that children themselves do this categorization, however (Tomasello 2000). Children may be sensitive to these categories very early in development (Valian 1986; Yang 2013) or they may discover them either gradually (Pine and Lieven 1997) or more quickly (Meylan et al. 2017). Importantly, though, we treat adult syntactic categories as an analytic convenience that describes certain regularities in how groups of words are distributed in language samples and how they function in different contexts, rather than as an ontological fact about children’s knowledge. Chapter 10 breaks down these categories further, asking what sorts of information predicts the order of acquisition for individual words, both within and across categories. Figure 11.1: Figure from Bates et al. (1994), showing developmental trends in the categorical composition of early vocabulary Bates et al. (1994) characterized these patterns of vocabulary composition in the following way. The figure above (reprinted from that paper) shows average vocabulary composition of nominals, predicates and closed class forms as a function of children’s vocabulary size for English-speaking children from the original norming study of CDI: Words &amp; Sentences form (Fenson et al. 1994). Note that when children only know a few words (e.g., fewer than 50 words), the nominals comprise the greatest proportion of the words that children are reported to produce, with very few predicates or closed class forms (&lt; 10%). As the children learn the next hundred words or so, the proportion of nominals increases even more dramatically with a gradual increase in the proportion of children’s vocabularies that are predicates. Closed class forms remain a much smaller proportion over the period. Yet after about 300 words or so, children tend not add nouns to their vocabularies at the same pace that they did earlier in development, reflected in the proportion of nominals tending to decrease.21 It is during this developmental period that proportion of predicates tend to increase, followed by a growing proportion of closed class forms. Why do children learn nouns before verbs and other types of words? This question has received a great deal of attention in the literature, and we can briefly summarize some of the major issues here. One reason for this “noun bias” could be that nouns are simply more frequent in the talk to young children. It is well-established that children learn the words that they hear more often (e.g., Hart and Risley 1995). Many observational studies of English-speaking caregivers have demonstrated that caregivers use more nouns than verbs (types or tokens) with their children (e.g., Fernald and Morikawa 1993; Goldfield 1993; Gopnik, Choi, and Baumberger 1996; Kim, McGregor, and Thompson 2000; Poulin-Dubois, Graham, and Sippola 1995; Tardif, Shatz, and Naigles 1997). Other researchers have framed the “noun bias” in terms of universals about what and how different words “partition” things in the world.For example, Gentner (1978) has argued that children learn nouns before verbs because the meanings of nouns are easier to encode since they identify things that can be differentiated in the world (e.g., common everyday objects). Verbs and other predicates, in contrast, express relations among things in the world. Hence, the meanings of verbs are less accessible to children through common, everyday experiences and hence, are more difficult to map onto word forms without additional linguistic or social support. Other reasons that nouns might be easier than verbs for young children is that nouns tend to be less morphologically complex than verbs (e.g., Tardif, Shatz, and Naigles 1997). For example, in many languages, nouns are typically marked only for number, whereas, verbs carry both person and tense information. In English, at least, verbs might also be harder to learn because they tend to occur in sentence-medial position (rather than sentence final), which make verbs less salient in the input that children hear (Slobin 1985; Caselli et al. 1995). Finally, differences in children’s preferences for nouns vs. verbs might result from differences in what contexts children hear nouns vs. verbs in the speech from caregivers (e.g., Choi and Gopnik 1995; Tardif, Gelman, and Xu 1999). Several researchers have examined what caregivers talk about using naturalistic data of caregiver-child interactions. For example, caregivers in some cultures tend to emphasize the names for objects, spending a great deal of time labeling objects for their children. In other cultures, caregivers do so much less frequently, instead focusing on the actions in which those objects engage (e.g., Fernald and Morikawa 1993; Gopnik, Choi, and Baumberger 1996). These differences in input to children can influence the words that are salient for children, and hence, the words that they are most likely to learn. What is the evidence that a noun bias is a universal feature of children’s vocabularies? Documenting the extent to which the noun bias is universal is relevant to understanding mechanisms of language learning, in particular, the presence of conceptual biases in early acquisition and the role of cross-cultural variability in the input that children receive from caregivers. The evidence varies across languages, as well as across methodologies (for example, naturalistic observation vs. parent report). Some studies find consistent evidence for a noun bias in English, as well as in Korean and Italian (Bates et al. 1994; Au, Dapretto, and Song 1994; Caselli et al. 1995; Kim, McGregor, and Thompson 2000). Other studies do not find evidence of a noun bias in languages as varied as French, German, Chinese, Estonian, and Korean (Bassano 2000; Bloom, Tinker, and Margulis 1993; Choi and Gopnik 1995; Kauschke and Hofmeister 2002; Tardif 1996; Tardif, Gelman, and Xu 1999; Schults and Tulviste 2016). In sum, identifying the extent of cross-linguistic variation vs. universals has been difficult since variation across studies may be due to the different methodologies that are used. For example, even within a single language, for example, Korean, parent reports of children’s first words find a noun bias (e.g., Au, Dapretto, and Song 1994), whereas, studies using direct observational methods find less evidence for this pattern (e.g., Gopnik, Choi, and Baumberger 1996). Further, few studies have had the scope to directly compare the extent of the noun bias across multiple languages using a common methodology. One notable exception in a literature where samples have been small – in terms of both languages and children – is Bornstein et al. (2004), in which the researchers compared vocabulary composition in seven different languages. In this chapter, we follow this comparative approach (see also Tardif et al. 2008). Since we have access to many more observations, our approach offers a more comprehensive approach than these earlier studies. Moreover, we attempt to quantify the estimates of the extent to which languages show a noun bias: we develop a statistical method for quantifying the extent of the noun bias across the entire developmental range in which a particular form is used. 11.2 Methods and Data Each CDI form contains a mixture of words in different classes. We adopt the categorization of Bates et al. (1994), categorizing words into nouns, predicates (both verbs and adjectives), function words (also referred to as “closed class” words), and other words. For each child’s vocabulary, we compute the proportion of the total words in each of these categories that they are reported to produce. Following the approach developed by Bates et al. (1994), for each of the languages in our sample, we plot these proportions against total vocabulary. Each dot represents a child’s knowledge of a particular class, while curves show the relationship between a class and the whole vocabulary. If categories grow independently of one another, these curves should approximate the diagonal. We limit our analysis to traditional WS and WG forms (along with variants in these classes) because short forms like the British English TEDS don’t typically include category information. The sample sizes included in this analysis are given above. Figure 11.2: Schematic of our vocabulary composition analysis. Building on the method of Bates et al. (1994), our analyses relies on plotting the proportion of words known in a particular category (e.g., nouns) in a child’s vocabulary by the proportion of all words in the child’s vocabulary. This approach is shown schematically above. If every time a child learns a word, that word is sampled randomly from the different words available on the form, then the proportion of nouns in vocabulary should track perfectly with the proportion of total vocabulary (the diagonal). In contrast, if nouns are over-represented, the child will be represented by a point above the diagonal; if nouns are under-represented, they will be under the diagonal. The figure above shows this analysis, carried out with English (American) WS data. Each point shows an individual child’s vocabulary, and each panel shows a different lexical class (thus each child is represented once in each panel). We capture the overall trend in this plot by estimating a linear model over the data, predicting category proportion as a function of total production. This model is fit with third-order polynomials (so as to allow both concave/convex functions and also changes in convexity). We fit these models with the constraint that they must predict the point [1,1] so that they are guaranteed to arrive at the diagonal point in the special case that all words on a form are checked. These model fits are shown by the lines. The final step in our method is to capture the overall bias in a particular sample by estimating the difference in area between the curve and the diagonal. If the curve is substantially above the diagonal, this difference will be positive (indicating e.g., a positive noun bias). In contrast, if the curve is below the diagonal, the difference will be negative. To capture uncertainty in this area estimate, we conduct a resampling analysis where we randomly resample the population 1000 times with replacement, then recompute the area measurement. Confidence intervals below are based on this resampling procedure. Critically, this analysis controls for a number of confounds in previous analyses. First, because our interest is in the shape of the overall curve, under-representation of children in some age-band should add uncertainty but not bias. Of course, if data are too sparse, estimates will be unconstrained, but particulars of age sampling should not bias our estimates. Second, in principle, the analysis should not be biased by the number of items in a particular category, as the analysis is relative to the numerical representation of a particular class on the form. Thus, in principle we should be able to compare across forms with larger or smaller numbers of items in particular sections. 11.3 Results We present results of this analysis across languages, beginning with comprehension on WG-type forms and moving to production in WS-type forms. We do not analyze WG production data here. For the most part, production estimates on WG forms are quite low, and hence curves are relatively unconstrained (or determined by a small number of children who are reported to have very large early vocabulary). 11.3.1 Comprehension: Words and Gestures Comprehension results are shown above. Overall, the largest trend that is visible in these plots is the under-representation of function words, with nouns and predicates appearing quite close to one another. For further comparison, we show summaries of curve areas for each language below. Nouns are over-represented in many – but not all – languages. Portuguese, Turkish, Korean, and Slovak, a set of typologically- and culturally-distinct languages, show slight under representation, with BSL and British English showing the largest over-representation of nouns. Predicates are under-represented in some languages and over-represented in others. As seen above, there is a strong anti-correlation between noun and predicate bias measures (\\(r\\)(21) = -0.83). (This correlation should be interpreted with caution as nouns + predicates + function words are constrained to sum to 1, so some degree of correlation is built into the measure). Function words are substantially under-represented across nearly every language in our sample (except Slovak). Note the scale difference – the function-word values are far more extreme than the noun and predicate values. These results likely reflect some combination of true under-representation of function-words as well as the difficulty of reporting on function-word comprehension in very early language (see Chapter 4 for more details on this issue). Such issues may also vary across cultures, languages, and administration methods. Function-word representation might plausibility differ due to linguistic factors such as morphological complexity, pronoun dropping, agreement, etc. However, it is also notable that the two lowest function-word scores come from Kiswahili and Kigiriama (Alcock et al. 2015), a study in which the parents may have had substantially less meta-linguistic awareness as a result of many being illiterate. 11.3.2 Production: Words and Sentences We next turn to production data from WS-type forms. We can immediately see the same function-word trend as was visible in comprehension. In addition, in many but not all languages, a noun bias is evident. Turning to the language summaries, we see a larger pattern of variation in nouns and predicate representation. Every language has a relative over-representation of nouns, though the degree of this over-representation varies, with German and Korean especially high, and Mandarin and Cantonese especially low (we return to this trend below). Overall this trend is more extreme and more consistent in production data than comprehension. Predicate representation is both more variable and more negative than we observed for comprehension. Here we see Mandarin and Cantonese as the only two languages with substantial over-representation for predicates. Noun and predicate representation is again anti-correlated, at \\(r\\)(25) = -0.65, though this correlation is somewhat weaker than for comprehension. The negative representation of function words is relatively consistent in overall magnitude with that seen in comprehension. Across all languages, children are reported to produce fewer function words than would be expected by chance sampling. 11.3.3 Reliability of bias estimates One natural question is how consistent estimates of bias are across comprehension and production. The plot above shows – for the sample of languages in which we have data from matched WG- and WS-type instruments – the relative bias we recovered in the analysis above. Somewhat surprisingly, correlations between these different instruments are quite low. Function word bias is negatively correlated between production and comprehension (\\(r\\)(19) = -0.39, \\(p\\) = 0.078). This result is likely due to Kiswahili and Kigiriama, discussed above, the lowest points for function word comprehension. But predicate bias estimates are close to uncorrelated with one another (\\(r\\)(19) = 0.031, \\(p\\) = 0.89), and the correlation between noun bias estimates is modest though positive (\\(r\\)(19) = 0.46, \\(p\\) = 0.034). This analysis is relatively low power; it only conducted with 19 languages and hence is relatively low power (despite the many thousands of children necessary to carry it out). Despite this, it raises some important questions. A number of explanations of the data are consistent: Bias differs between comprehension and production, such that differences are related to type of response. Estimates of bias are influenced by the composition of specific forms, so much so that WS- and WG-type forms yield radically different estimates of bias. Bias differs developmentally. Perhaps different biases are evident earlier vs. later in acquisition. We assess each of these explanations in turn. In order to assess comprehension/production differences as a source of bias, we examine the Oxford CDI, which is relatively unique in that it includes comprehension questions even later in development. Data on production from standard WG forms is simply too sparse to perform our bias assessment method; since most children do not produce half of the words on the form, the shape of the bias curves is driven primarily by older children. In contrast, for the Oxford CDI, it is possible to compare directly. The measured noun bias for comprehension is 0.048; for production it is 0.069. These values for predicates are -0.032 and -0.082, respectively. These values are somewhat similar to one another, but they do vary beyond the average confidence interval on each (+/- 0.0054). Thus, there is some evidence for production/comprehension asymmetries. What might be the mechanism for these aysmmetries? For languages that do not allow argument dropping, producing a predicate typically requires producing other words as well – English-speaking children do not often produce bare predicates, for example. Thus, predicate production may be limited by other constraints on production in such languages; in contrast, predicate comprehension has no such limits. Further, felicitous predicate production requires some ability to combine words syntactically; in contrast, comprehension of predicates (especially verbs) can often be accomplished by guessing based on known arguments (e.g., Gillette et al. 1999). For these reasons, there may be a greater bias against predicates in production compared with comprehension. This explanation is consistent with our data, in which the average production predicate bias is -0.021, while the average for comprehension is 0.013. Thus, production comprehension asymmetries likely explain some part of the differences we observed above. Another potential explanation is that form composition relates to bias estimates. For example, a form with more predicates might actually show a lower degree of predicate bias – more predicates on the form would imply that some of those predicates are relatively more difficult (simply because the form designer had “run out” of easy predicatess) and hence would not be checked as frequently by parents. We assess this hypothesis in two ways. First, we examine the relationship between predicate bias and predicate representation (making use of predicates because they are a minority on the form). Second, we consider the case of Mandarin where we have data from two forms with different compositions. As shown above, there is no reliable relationship between the proportion of predicates on a form and the predicate bias that is demonstrated (\\(r(25) = 0.15\\), \\(p = 0.45\\)). Thus, a simple relationship between form composition and bias is not supported. On the other hand, it does appear that there is greater variance in this area for those languages with larger numbers of predicates on the form, and those languages with the highest predicate representation do have the highest number of predicates on the form as well. Perhaps the causality is reversed: Greater numbers of predicates have been included in forms for languages like Cantonese, Mandarin, and Korean where the predicate bias is an open theoretical question (or where the acquisition of predicates is of special interest). The existence of two different forms for Mandarin opens the possibility of a further, more direct test of this issue. The Mandarin WS form (Tardif et al. 2009) and the Mandarin TC (toddler checklist; Hao et al. 2008) are completely independent forms but represent large datasets collected on Beijing Mandarin specifically. The Mandarin WS form is 33% predicates and shows overall a 0.07 predicate preference, while the TC form is 28% predicates and shows overall a 0.01 predicate preference. The intersection of these forms yields 330 items, with 30% predicates. Interestingly, the predicate representation for the TC and WS samples, analyzing only shared predicates still differs, if anything more substantially: for WS it is 0.095 and for TC, 0.0036. This result is worrisome – these are samples from the same city and using the same items. They even include very similar age ranges: 16–30 month-olds and 17–30 month olds respectively, with approximately uniform sampling. The suggestion is then that differences in predicate bias can be substantial based on relatively minor details, such as specifics of administration or form context or specifics of sample composition. Despite the apparent stability of these estimates under resampling (confidence intervals for bias estimates are around +/- .005 in the analysis above), we should be cautious in over-estimating our degree of certainty in particular bias estimates. Further, these data provide more data against the notion that form composition (or at least the specific sample of predicates being assessed) is the primary determinant of bias. The final hypothesis that we examine is that there are development differences in bias. Such differences would help to explain the observed differences between bias in early comprehension and later production. To address this question, we split data from each language and form into older and younger groups at the median of the data for that sample. We then recomputed our bias estimates, shown above. There was a developmental difference such that older children showed less of a negative function word bias, but differences in noun and predicate bias were very slight for most languages. Thus, overall we do not see evidence that bias estimates for nouns and verbs are globally different for older vs. younger children. In sum, we did not find strong support for effects of form composition or age on bias estimates. Each of these factors of course could contribute in part to the mismatch between WG comprehension and WS production estimates, but neither one was particularly. On the other hand, data from the Oxford CDI suggested some differences in bias estimates between comprehension and production on the same form, with the bias against predicates and for nouns being substantially more pronounced for production than for comprehension. Further, data from two different Beijing Mandarin datasets suggest possible factors relating to population and administration. 11.4 Discussion This chapter presented a comprehensive examination of the issue of biases for and against particular syntactic categories in acquisition. Building on earlier work by Bates et al. (1994), we created a quantitative measure of noun, predicate, and function word bias and examined variability in these measures across languages. Overall, a number of generalizations emerged. Nearly every language showed a positive bias for nouns, though the degree of this bias varied. Every language showed a substantial bias against function words, supporting the generalization that these are acquired much later than content words, despite their typically higher frequency (see 10). This bias was larger on average than biases in type of content words. In comprehension there was variability in the degree of predicate representation; in production, as has previously been reported, languasges were mostly biased against predicates. There were a few notable exceptions among the East-Asian languages. Measures of bias in production and comprehension were not highly correlated with one another, especially for predicates and function words. There are likely many causes of these, but greater predicate comprehension compared with production appears to be one likely culprit. An earlier version of this work was reported to the Boston University Conference on Language Development in 2015 by Braginsky, Marchman, Yurovsky, &amp; Frank.↩ This effect may also reflect aspects of CDI form design, e.g. “running out of nouns” to learn: children may increasingly learning nouns that are not on the forms.↩ "],
["categories-semantic.html", "12 Vocabulary Composition: Semantic 12.1 Introduction and Methods 12.2 Global Results 12.3 Individual conceptual items 12.4 Discussion", " 12 Vocabulary Composition: Semantic Following the approach in the previous chapter, we investigate the consistency of semantic content categories across languages. By analogy with the “noun bias,” are some languages “vehicle-focused”? These analyses are expected to reveal cultural and linguistic differences in the specific words learned by children (perhaps due to differences in the content of their environment). 12.1 Introduction and Methods In contrast to the “noun bias” literature, where a wide variety of hypotheses have been articulated over the preceding decades, differences in content have been less explored and so these analyses are far more exploratory. To limit the scope of this exploration, we focus on WS-type forms and production measures, which we have reason to believe will be most reliable. In these analyses, we take advantage of the fact that CDI forms are typically structured into semantic categories (e.g., “animals” or “body parts”). As the figure above shows, while some semantic categories are shared across many instruments, there are others that are quite rare (many corresponding to specific syntactic categories that are of interest in particular languages). We focus on those semantic categories with greater representation in the data. Further, to avoid duplicating our analysis in Chapter 11, we focus on those semantic categories that fall into “nouns” and “other” lexical classes. (In general, “action words” and “descriptive words” tend to be broad predicate classes without as much clear semantic differentiation). This filtering step leaves 14 categories: animals, body_parts, clothing, food_drink, furniture_rooms, games_routines, household, outside, people, places, sounds, time_words, toys, and vehicles. Samples included in this analysis are shown below We first illustrate this approach using data from the English WS form alone. Analogous to the plots in 11, the plot above shows areas where the data deviate from the pattern of category acquisition predicted by random item sampling. The size of the shaded region above vs. below the diagonal gives evidence of over- vs. under-sampling for a particular semantic category. Many of the results of this analysis for English are expected. Sounds items are heavily over-represented, as are Body Parts, Games and Routines, and to a slightly lesser extent, Toys, Animals, and Vehicles. These particular biases are likely related particular parenting practices, cultural emphases (for example, on animal names), and young children’s’ idiosyncratic interests. For a more in-depth examination of the consistencies in very early vocabulary, see Chapter 8; for more detail on what makes particular words easier or harder to learn, see Chapter 10. The largest under-representation across categories is Time Words. This pattern is consistent with a body of work on children’s acquisition of the semantics of time words that suggests that children struggle with understanding these complex terms through age five (Tillman and Barner 2015; Tillman et al. 2017). We next turn to how this pattern varies across languages. 12.2 Global Results Because there are so many different languages represented in this analysis, the simplest analysis examines the spread of languages across categories. Somewhat surprisingly, the ordering of categories looks quite similar to what was observed in English. Sounds, Games and Routines, and Body parts are all over-represented. Vehicles, Food and Drink, Animals, and Clothing all are variable across cultures, as is People. Household, Outside, and Furniture and Rooms show variability but overall less bias. Finally, Places and Time Word are both under-represented systematically across all languages. We can zoom in on the most highly over-represented categories. The highest mean comes from body parts, which are over-represented in just about every language. Interestingly, the three datasets with the lowest proportion of body parts are the two Mandarin datasets (WS and TC) and the Cantonese WS data. Games and routines are generally over-represented but somewhat more variable, with Kiswahili, Kigiriama, and Mandarin TC data lowest. Sounds are quite highly variable but almost all positive, with Russian sounds being the outlier. Inspection of these items shows negative developmental trajectories for a number of animal sounds. We believe these data are likely an artifact of parents feeling that they “trade off” with noun labels for animals, and hence should be discounted. Finally, vehicles appear more variable with positive preferences across language families. We end by considering people, places, and time words. People is a highly-variable category, with some languages under-representing and others over-representing. Tardif et al. (2008) speculated that names for people were a substantial part of children’s earliest words, but that may reflect that study’s use of Mandarin and Cantonese data where people terms are very over-represented due to cultural emphasis on family connections. Surprisingly, despite the relatively multi-generational and family-centric nature of children’s experience in Kenya (Alcock and Alibhai 2013), people words were relatively under-represented in Kiswahili and Kigiriama. In contrast to the heterogeneity in people words, words for places and, especially, time words were almost uniformly under-represented in children’s vocabulary. As noted above, time is known to be conceptually difficult for children. Interestingly, though, less has been written about children’s understanding of geographical vocabulary. Time words offer a number of conceptual challenges in terms of mapping an ordered set of durations (second &lt; minute &lt; hour &lt; day, etc.) to a set of concepts that do not map cleanly onto perceptual experience. In some sense, many of the same conceptual difficulties hold true for larger locational/geographical hierarchies (neighborhood &lt; city &lt; state &lt; country). Or alternatively, the under-representation of places in children’s early vocabulary may simply reflect the relative lack of diversity of their experiences with some of the items that traditionally populate this section (e.g., beach, camping, church, circus to name the first four). See Chapter 4 for some evidence that camping especially may be variable in children’s experience. 12.2.1 Dimensionality reduction Our next analysis of these data takes an exploratory dimensionality-reduction approach. Rather than examining each semantic category individually, we consider the space defined by variation in semantic preferences by running principal components analysis (PCA) on these data. PCA is a dimensionality reduction technique that projects high-dimensional data (e.g., bias by semantic category for each language) into a set of orthogonal dimensions where lower dimensions capture as much of the variance as possible. Standard PCA requires no missing data, thus we removed languages with missing categories. This analysis thus includes 22 language/form combinations and 13 categories (we exclude sounds because of the issue with Russian sounds and other missing data). The figures above show the data projected into the space of the first two principal components and the loadings of semantic categories on these two components, respectively. Several observations emerge: Mandarin and Cantonese WS data are very far towards the direction of people (indicating that these datasets are unusual in this respect). Second, Kiswahili and Kigiriama are especially far in the direction of outside and place words, perhaps consistent with the datasets being collected in rural and semi-rural areas. Many Northern European datasets (as well as Korean) are clustered at the far left, with high scores on vehicles, clothing, animals. Overall, this analysis reveals some interesting structure, but care should be taken not to over-interpret. In particular, within culture differences (e.g., Mandarin TC vs. Mandarin WS) are as large in size as between-culture differences. 12.3 Individual conceptual items In this section, we isolate individual items from specific domains of interest. Our approach is to use the “universal lemma” mappings (see Chapter 3) to find matching lexical items across languages. The specific domains we consider are time, color, body parts, and logical words. We also investigated spatial prepositions and number words, but do not include them here. Spatial prepositions present a wide variety of mapping issues since lexical items “cut up” space differently across languages (see e.g., Bowerman 1996). And number words are not found on enough CDI forms to have sufficient data for inclusion. 12.3.1 Time As discussed above, the semantics of time words are very challenging for children through middle childhood (Tillman and Barner 2015; Tillman et al. 2017). Despite this, parents report that children do produce them by age 2.5. The set of words with sufficient translation equivalents for inclusion was day, later, morning, night, now, today, tomorrow, and yesterday. The plot above shows trajectories for these lexical items across languages, sorted by difficulty. Because night is typically signaled by darkness, it is perceptually very concrete and likely easier. Similarly, now seems relatively more straightforward given that it has a common imperative meaning in sentences like “give me that right now.” In contrast, the latest-acquired is yesterday, which is highly abstract and deals with a specific part of the past. 12.3.2 Color Color word acquisition has been a focus of interest at least since early work by Carey (1978)’s influential study of “fast mapping.” Although early work suggested that color words were learned almost simultaneously (Bartlett 1977), more recent studies have described a more protracted trajectory of partial knowledge. Many children learn some color words and overextend these to cover the rest of color space (Wagner, Dobkins, and Barner 2013). Adding to the complexity of this issue is substantial cohort changes in the age at which colors are learned: while school-aged children struggled with their colors 50-100 years ago, more recently children learn colors in the age range spanned by the CDI forms (Bornstein 1985). There is tremendous cross-linguistic variation in color vocabulary (Kay et al. 2009). We take advantage of the fact that most of the languages in our dataset have relatively larger color vocabularies, which we can assume means that individual colors probably have relatively similar extensions.22 Despite this, most CDI forms do not include all the basic level color words. The set of color words with sufficient translation equivalents for inclusion was black, blue, green, red, white, and yellow. In this set of words, we see that red is typically the first learned, although their is substantial variability in when it is learned. It is followed by yellow, blue, and green, with black and white following behind (consistent with reports by Wagner, Dobkins, and Barner (2013). We additionally see an ordering across languages in which have higher rates of color word production reported. As in other analyses (see Chapter 5), Mandarin WS has the highest level of production. American and Australian English also tend to have high levels of color production. Interestingly, Kiswahili has by far the lowest level of color production, perhaps related to the availability of manufactured toys of contrastive colors (Bornstein 1985). 12.3.3 Body parts Words for body parts are produced very early by most children, and variance is quite low across languages (with the exception of a few terms in Cantonese and Cypriot Greek). One interesting pattern that is visible in these data is the ordering of hand and foot before leg and arm. 12.3.4 Logic Finally, we examine words for logical operators. The only items that are available across significant samples of languages are all, none, some, no, and not. The negative words are learned early, with an ordering consistent with Bellugi (1967) and Pea (1982). No is very early, and not later. Interestingly, the quantifiers are not ordered as shown by Katsos et al. (2016) in a massive cross-linguistic study. In that study – as well as in our own work in English (Horowitz, Schneider, and Frank 2017) – all was found to be understood better than none. In contrast, here we tend to find none learned earlier than all and definitely learned earlier than some. One possibility is that these uses are only found in a restricted set of cases. Another is that contextualized production of negation is simpler than de-contextualized comprehension, as we have found in some of our work on the comprehension of negation in context (Nordmeyer and Frank 2014, ???). 12.3.5 Category variability Finally, we quantify the variability across languages for each of these restricted sets of lexical items. For 22-26 month-olds (chosen somewhat arbitrarily to be an age range of high coverage across forms that does not encompass too much developmental change), we compute the coefficient of variation for children at each age on each lexical item. (We first average across ages and then across lexical items; reported Ns are for the average number of contributing languages). We additionally add animal words for the sake of comparison. The table below gives the coefficient of variation for each category. Body words as well as animal words are highly consistent across languages. In contrast, color, logic words, and time words are far less consistent. These effects are likely somewhat affected by floor and ceiling effects, but inspection of individual items confirms the robustness of the general conclusion. 12.4 Discussion In these exploratory analyses, we considered representation of different semantic categories across the different languages in our dataset. We found some surprising consistencies. Place words and time words were under-represented, while sounds, games and routines, and body parts were over-represented. These consistencies were also contrasted with some areas of greater variability: for example, the preference for vehicles, clothing, and animals appeared to be a somewhat coherent dimension in our data, with many (northern) European languages higher on this dimension than non-European languages. Still, substantial caution is necessary in interpreting these results as the sample of non-European languages is small. Finally, we found that acquisition of complex conceptual words in categories like color, time, and logical words was highly variable across languages. Such an assumption would not be warranted if we were considering languages with just a handful of color terms, in which the extension of a term like “red” would be much larger than in English.↩ "],
["grammar.html", "13 Morphology, Grammar, and the Lexicon23 13.1 Introduction 13.2 Goals of the current analyses 13.3 Methods 13.4 Results 13.5 Discussion", " 13 Morphology, Grammar, and the Lexicon23 How does abstract structure emerge during language learning? On some accounts, children’s early syntax emerges from direct generalizations from particular lexical items, while on others, syntactic structure is acquired independently and follows its own timetable. CDI data can help us decide between these two views. In this chapter, we summarize the state of grammatical development across languages (noting the challenges posed by radically different representations of grammar across CDI forms). We also replicate and generalize analyses linking grammatical generalization to children’s vocabulary size. We end by investigating the idea that that age modulates the relationship between grammar and the lexicon. 13.1 Introduction For many children, their first words are spoken in isolation. While these single word utterances sometimes seem to be picking out objects in the world (e.g., ball!), others seem to convey more complex ideas or desires (e.g., up! for Mommy, pick me up!). But by two years of age, many children have acquired a large repertoire of words, and are beginning to use them in two- or three-word combinations (e.g., Mommy up! or kitty sleep here). These utterances will gradually increase in length and complexity in various ways, forming sentences that increasingly reflect the grammatical structure of their native language (e.g., Mommy, the kitty is sleeping here). Children also begin to add more verbs, adjectives and other predicates to their working vocabularies (see Chapter 11), and substantively increase their use of prepositions, articles and other closed class forms that do grammatical work, including the productive use of inflectional morphemes (e.g., English past tense ed or ing). Understanding the origins of grammar is critical because children’s ability to use morphosyntactically-rich language is thought to reflect the uniquely-human mental machinary that enables speakers to produce novel utterances that have never been heard in the input (Berko 1958; Pinker 1991). The questions surrounding the development of grammar are challenging. How do abstract morphosyntactic structures emerge during language learning? What mechanisms underlie the formation of generalizations that support such inferences and allow children to apply them during language production? Does an understanding of the abstract rule-structure of language emerge from the interactions of individual words, or is that structure independently acquired and represented separately? Broadly speaking, theoretical views on grammatical development generally take one of two forms. On nativist theories like Principles and Parameters (Chomsky 1981; Baker 2005), grammar emerges independently from lexical knowledge following its own, largely maturational, timetable. Moreover, grammatical regularities are mentally represented in a format that is distinct from that used by the lexical system. In contrast, according to lexicalist theories, mental representations of morphosyntactic structure generally emerge from graded generalizations on the basis of lexical items, and at least early in development, there may be little or no representation of morphosyntactic rules or regularities per se (Tomasello 2003, @elman1996). Even when syntactic structures are eventually represented, these representations are directly related to more concrete lexical structures (Bannard, Lieven, and Tomasello 2009). Historically, the study of individual differences has been critial to this debate. While variation in word learning is generally uncontroversial, individual differences in grammatical development are less clearly predicted under a universalist, nativist perspective. In contrast, lexicalist theories predict that variation in grammatical development should be tightly yoked to variation in lexical development (Bates and Goodman 1999). Research has shown that, as with lexical development, there is sizeable variation in exactly when and how children move into using more grammatically complex utterances in their everyday speech. While some children use primarily multi-word phrases and many closed class forms by 24 months, other children are still primarily producing nouns in single word utterances at that same age (e.g., Bates, Bretherton, and Snyder 1988; Bates and Goodman 1999). Moreover, there is also variation in the kinds of multi-word utterances that children produce. For example, some children build up sentences from individual words (e.g., want dat!), whereas other children seem to produce utterances that reflect “unanalyzed” chunks of more complex speech (e.g., iwantdodat!). Associations between individual differences in lexical and grammatical development have been robustly substantiated in the literature. In the original norming data from the English CDI: Words &amp; Sentences, children with more sophisticated grammatical productions were also those children with the largest vocabularies (Bates et al. 1994). Using that same dataset, Marchman and Bates (1994) found that size of verb vocabulary was concurrently related to children’s overregularization of past tense inflections (e.g., daddy goed), productions that are viewed as a major milestone in the development of grammatical rule-based knowledge. Links between lexical development and grammar have also been reported longitudinally (Bates, Bretherton, and Snyder 1988; Bates and Goodman 1997), in late talkers (e.g., Paul 1996; Rescorla, Dahlsgaard, and Roberts 2000; Rescorla, Roberts, and Dahlsgaard 1997; Thal et al. 1997), early talkers (Thal et al. 1996, 1997), and children with neurodevelopmental disorders, such as Williams syndrome (e.g., Singer Harris et al. 1997). Similar relationships have also been demonstrated in many other languages, including Slovenian (Marjanovič-Umek, Fekonja-Peklaj, and Podlesek 2013), Hebrew (Maital et al. 2000), Icelandic (Thordardottir, Weismer, and Evans 2002), Italian (Caselli, Casadio, and Bates 1999; Devescovi et al. 2005), Bulgarian (Andonova 2015), Finnish (Stolt et al. 2009), Spanish (Mariscal and Gallego 2012; Thal, Jackson-Maldonado, and Acosta 2000), and German (Szagun et al. 2006). Finally, and perhaps most intriguingly, in behavioral genetic studies of monozygotic and dizygotic twins, the relation between lexical and grammatical level has been found to be strongly heritable (Dale et al. 2000; Dionne et al. 2003). In other words, even though genetic factors contribute relatively weakly to each aspect of language as assessed individually, the genetic factors that influence lexical growth are the same as those that influence grammatical growth, perhaps operating in a bidirectional manner. While these studies substantiate that vocabulary and grammar development are strongly associated developmentally, the interpretation of these relations is still under debate. Some researchers have interpreted these links to suggest that domain-general learning mechanisms guide the child’s construction of a working linguistic system at many different levels, in this case, learning words and learning grammatical rules (e.g., Elman et al. 1996). As Bates and MacWhinney (1987) proposed many years ago, “the native speaker learns to map phrasal configurations onto propositions, using the same learning principles and representational mechanisms needed to map single words onto their meanings” (p. 163). Other proposals suggest that the process of learning words involves learning both their lexical-semantic and their morphosyntactic properties (e.g., in what constructions they can legally appear and what inflectional morphemes are required), and that grammatical knowledge is generally built up on a case-by-case basis (Tomasello 2003). Early word combinations are often highly routinized and situation specific, suggesting that learning grammar, like word learning, is guided by learning mechanisms that are item specific and frequency dependent. It is only later that grammatical structures become encoded in terms of their abstract syntactic form (e.g., Lieven, Pine, and Baldwin 1997; Tomasello 2003). Yet other accounts view the relation as reflecting mechanisms that operate in the opposite direction. On these views, grammatical analysis is a driving force behind word learning, such that the process of analyzing sentences into their constituent grammatical parts facilitates the further acquisition of lexical-semantic knowledge (Anisfeld et al. 1998; Naigles 1990). Finally, other studies have proposed that the lexical-grammar relations may not be as direct as previously proposed, actually being driven by common third-party influences such as the speech that children hear (Hoff, Quinn, and Giguere 2017). 13.2 Goals of the current analyses In this chapter, we explore relations between estimates of children’s vocabulary size based on the vocabulary checklist and responses on other sections of the Words and Sentences instruments. Many versions of the instruments provide indices of grammar learning by asking about children’s use of inflected forms (e.g., walked), children’s use of overgeneralizations (e.g., goed), and the complexity of their multi-word combinations (e.g., kitty sleeping / kitty is sleeping). While many studies have examined associations between lexical and grammatical development crosslinguistically, the scope and power of these early studies were limited, with few opportunities for direct comparisons of the nature or extent of these relations across multiple languages at the same time. In contrast, our data allow analyses of lexical-grammar relations with enhanced statistical power and broader cross-linguistic representation. In addition, we explore a hypothesis that was not explicitly tested in these earlier studies: that there remains age-related variance in grammatical development unexplained by vocabulary development. While the overall relationship between grammar and the lexicon provides support for lexicalist theories, the identification of age-related variance would suggest the presence of developmental processes that regulate grammar learning, above and beyond those captured by measures of vocabulary size. Such age-related processes could be either maturational or experiential, and either domain-general (like working memory) or language-specific (like grammatical competency). Importantly, since both nativist and constructivist theories could in principle predict age-linked variance in grammatical development, our goal is not to differentiate these theories, but instead to test this novel prediction and explore its implications for future work on understanding the processes of grammatical development. An additional contribution of work is that, due to the size of our dataset, we are able to make more fine-grained distinctions than the initial cut between grammar and the lexicon. In particular, we distinguish morphology from multi-word syntax, since morphological generalizations might be more specifically dependent on vocabulary size than those requiring more global, sentence-level syntactic regularities. 13.3 Methods In all 12 languages included in these analyses, the CDI forms contain both vocabulary checklists and other questions relevant to the child’s linguistic development. All of the data reported here come from Words &amp; Sentences type forms, administered to children ages 12– 36 months (most in the 16–30 month range). In addition to the vocabulary checklist items, these forms typically contain a single item asking whether the child is combining words yet at all; Word Form section, which asks whether the child produces each of around 30 morphologically inflected forms of nouns and verbs (e.g., feet, ran); and a Complexity section, which asks whether the child’s speech is most similar to the syntactically simpler or more complex versions of around 40 sentences (e.g., two foot / two feet, there a kitty / there’s a kitty). Importantly, each instrument for languages other than English is not just a translation of the English form, but rather was constructed and normed to reflect the lexicon and grammar of that language. Thus, there are substantial differences in the content of these items and their coverage of different morphological and grammatical phenomena. The major commonality is that the form developers believed that they provided a good survey of important developmental phenomena in their language. Word Form items can be browsed in the table below: Complexity items are shown in the table below: To analyze lexical and grammatical development, we derive several measures. Each child’s Vocabulary Size is computed as the proportion of words on the corresponding CDI form that the child is reported to produce. Similarly, each child’s Word Form score is the proportion of word forms they are reported to produce, and their Complexity score the proportion of complexity items for which they are reported to use the more complex form. We compute all of these quantities as proportions to make the scales comparable across languages. 13.4 Results We present four sets of results. First, we show analyses of the “combines” item, which is a binary item in which parents indicate whether their child is combining words. Second, we give analyses of the relationship between vocabulary size and Word Form/Complexity items. Third, we follow up on a pattern found in the “combines” item, namely age-related modulation of the grammar-lexicon relationship. Finally, we investigate the degree to which the age-related pattern is found in individual items. 13.4.1 Combine The plot above shows the probability of a parent checking that their child combines words, plotted by the child’s chronological age (left) and raw productive vocabulary size (right). As can be seen, across 7 languages, there is some consistency in the chronological trajectories for this item. By 24 months, around 75% of children are reported to be combining words, though this estimate is substantially earlier in Quebec French. One possibility is that the phrasing of the “combines” item contributes – some forms (including Quebec French, but also Norwegian and Danish) give examples of simple combinations, which could encourage earlier reporting. Vocabulary-related trajectories were more variable, however. In general, children who were marked as combining had vocabularies larger than around 100 words. However, as noted in Chapter 5, raw Mandarin vocabulary in the WS form is unusually high, but the “combines” item does not appear to be comparably accelerated. Thus, Mandarin children appear to be producing words only after producing substantially more vocabulary items. On the opposite side, children learning Quebec French and Korean were reported to be combining with quite small vocabularies. To investigate the quantitative relationship between word combination (as measured with this item), age, and vocabulary, we fit a linear mixed effects model predicting combination as a function of vocabulary (proportion), age, and their interaction. We also included random intercepts by language and random slopes for both vocabulary and age. Coefficient estimates are shown below: Estimate Std. Error z value Pr(&gt;|z|) (Intercept) -4.326 1.011 -4.281 0.000 production_prop 18.680 1.777 10.514 0.000 age 0.134 0.042 3.191 0.001 production_prop:age -0.337 0.048 -6.962 0.000 This model shows an extremely large effect of vocabulary, with a relatively smaller amount of variance due to age. In addition, there was a substantial negative interaction of vocabulary and age, reflecting that older children were more likely to be combining words, even with less vocabulary. This result parallels others reported below suggesting that there are age-related components in grammatical performance that are unaccounted for by vocabulary. All coefficients were highly significant due to the large amount of data. Overall, although there was some cross-linguistic variation – perhaps due to true variation and perhaps due to idiosyncrasies of individual forms or datasets – word combination emerged around 24 months and 100 words for most children. 13.4.2 Grammar and lexicon relationship We next examine the correlation between the proportion of Word Form/Complexity items completed and the proportion of vocabulary items completed. First reported by Bates et al. (1994), these correlations are extremely robust, and can be observed in essentially all of our datasets. Our first plot shows this relation for Word Form items. We fit linear regressions predicting vocabulary as a function of linear, quadratic, and cubic predictors (subtracting the intercept to ensure that the function passed through the origin). The total \\(r^2\\) for these relationships ranged from 0.8164153 to 0.9294908. Complexity items show the same relationship, typically with equal or greater strength (depending on data density and number of items). \\(r^2\\) values varied from 0.5646192 to 0.944244. Overall, these data provide strong cross-linguistic support to the contention of Bates et al. (1994) and others that the emergence of grammatical competence in production is related across individuals to the size of the productive vocabulary. 13.4.3 Age effects In our next analysis, we follow up on the relationship between age and grammatical ability found in the “combines” analysis above. In that analysis, we noted that less vocabulary was needed for older children to be marked as combining words. We investigate this pattern in the full Word Form/Complexity item set by splitting data from each language by age. We plot the same curves as above, but separately for children older and younger than the median. In essentially every language, for both Word Form and Complexity items, we see a higher curve for older children than younger. This finding is consistent with the idea that older children have less vocabulary per unit grammar (mirroring the negative interaction shown for the “combines item.” This pattern is further summarised in the plot above, where we show the area under the grammar/lexicon curvefor younger and older children. The upward slope of nearly every line demonstrates the consistency of the age effect, which we discuss further below. In addition, there is a trend for age effects to be larger in Complexity rather than Word Forms, suggesting a more syntactic locus for the effect. 13.4.4 Individual items In our final analysis, we examine the individual items on the Word Form and Complexity sections. Given the heterogeneous nature of the CDI instruments, particularly in the Complexity sections, we attempted a more fine-grained item-analysis by classifying items as capturing either more morphological or more syntactic phenomena. Items for which the difference between the simple and complex sentences is in the inflection of a noun or verb (such as doggie kiss me / doggie kissed me) were coded as morphological. The remainder of the items were coded as Syntactic, since they involved the use of some sentence-level syntactic construction (such as doggie table / doggie on table). We then fit logistic regression models with linear, quaratic, and cubic predictors (as above) separately for every item. The plot above shows the age effect coefficient of each item. In general, age effect were smaller for Word Form items, then Morphological Complexity items, and largest for Syntactic Complexity items, suggesting that more syntactic phenomena likely have greater age contributions. 13.5 Discussion We revisited classic findings on the relationship between grammar and the lexicon, further exploring novel questions regarding the role of age in this relation. Our results provid general support for a lexicalist view, in that, in 12 languages, variance in vocabulary production strongly aligned with variance in grammar. However, we also estimated additional age-related contributions, specifically contrasting the links to morphological forms vs. syntactic constructions, and for different lexical categories. In general, we find that measures of grammar that are more closely aligned with syntax are modulated by age to a greater extent than those reflecting inflectional morphology. As with the correlations reported in Chapter 7, parent bias is a potential confound for these correlational analyses. If some parents tend to over-report on their child’s language than others – whether for reasons of sensitivity, optimism, greater time spent with the child – then this over-reporting would likely extend across linguistic domains. Thus, in principle an observed correlation between two sections of a single parent report form could be driven by parent bias acting independently on each section without any connection. Two studies provide evidence against this deflationary hypothesis. First, Moyle et al. (2007) used a variety of instruments to provide evidence for the same relation in both typically-developing and late-talking children. Second, Brinchmann, Braeken, and Lyster (2018) give a similar analysis using cross-lagged structural equation models. Critically their work relied only on direct testing of the child (not parent report) using standardized instruments. In their model, they found a strong correlation between the time-invariant (trait-like) components of vocabulary and grammar (\\(r = 0.72\\)). While this correlation is smaller than the correlations we report, it is still quite large – and it appears in a model that also controls for a number of other relationships. Intriguingly, however, this study suggests that as grammar-lexicon correlations are cross-lagged, grammar to vocabulary links are stronger than vocabulary to grammar links, and neither are that strng This finding suggest that syntactic bootstrapping effects – as well as correlations driven by shared input may be responsible for the relationship between the two abilities. Regardless, these two studies suggest that reporting bias is very likely not the sole cause of the correlations we observded. Our analyses go beyond earlier work by also investigating the relationship of age to vocabulary and grammar. One possibility is that age-related developments are dependent on maturational factors that operate on grammatical development in a domain-specific way, independent of lexical-semantic processes. Another possibility is that age-related effects represent more domain-general learning mechanisms, such as attention or working memory, that provide differential support for sentence-level processes than word-internal ones (Gathercole et al. 2013). Future studies should also explore the extent to which lexical and age-related processes are shaped, either independently or in tandem, by features of the learning environments that children experience (e.g., Weisleder and Fernald 2013; Hoff, Quinn, and Giguere 2017; ???). Questions about the nature of morphosyntactic representations in early language have often seemed deadlocked. But by mapping out developmental change across large samples and multiple languages, our findings here challenge theories across the full range of perspectives to more fully describe the mechanistic factors underlying the interaction of vocabulary, grammar, and development. Material in this chapter first reported in Braginsky et al. (2015).↩ "],
["style.html", "14 Individual Variation in Vocabulary 14.1 Variation in Vocabulary Composition 14.2 “Spurts” in Vocabulary 14.3 Variation in Production vs. Comprehension 14.4 Conclusions", " 14 Individual Variation in Vocabulary Of all the individual differences described to date in the literature on early child language, variations in rate present the least interesting challenge to traditional ‘universalist’ models of development, If it can be shown that all children go through the same basic sequence, activating a common set of structures and processes, then small variations in the onset time for specific language milestones might represent little more than a minor perturbation to a maturational theory (like variations in the onset of puberty). Putative variations in style of development are more problematic, because they raise questions about the order in which structures are acquired, and the mechanisms used to acquire those structures. (Bates et al. 1994) Preceeding chapters have dealt with the degree of variability between individuals in Chapter 5 and the stability of individuals’ learning in Chapter 4. Then Chapters 6 and 9 used demographic factors to explain variability. In general, our treatment of variability has focused on issues of learning rate in the sense discussed by Bates et al. in the quote above (or, to be more precise, vocabulary size). With the exception of Chapter 9, which examined the rate of learning individual words, we have not dealt yet with issues of style. What does it mean for two children to show differences in language learning style? Intuitively, some aspect of the learning process should differ. Unfortunately, from the data that we use here, we cannot observe process – we can only observe the outcome of learning: knowledge. Thus, children must exhibit some differences in the way their vocabulary grows. This difference could be distributional and inferred indirectly from cross-sectional data or it could be shown directly through longitudinal data (though this move limits the number of datasets we can use from Wordbank). One prominent candidate for a stylistic difference in language acquisition is the distinction between “referential” and “expressive” children. In an early report on individual differences in vocabulary acquisition, Nelson (1973) noticed that there was substantial variation in how many nouns children had in thir vocabulary. She called children who had more than half of their vocabulary devoted to nouns “referential” children. They tended to have speech that was less syntactically complex and showed faster vocabulary growth. In contrast, “expressive” children had speech that was more syntactically complex and had fewer nouns. Dore (1974) proposed a related version of this distinction, focusing on speech acts from two children in the middle of the second year and labeling them as “code oriented” (focused on labeling, similar to “referential”) vs. “message oriented” (instrumental, social requests, similar to “expressive”). Since this seminal work, the referential/expressive distinction has become enshrined in the literature as a canonical aspect of variation in children’s style. Yet further debate about the consequences of this stylistic distinction continued in the literature. For example, Bates, Bretherton, and Snyder (1988) observed a correlation between the proportion of nouns in the children’s vocabulary and their vocabulary size and suggested the possibility that a referential style might be more effective for learning. Reacting to this claim, Pine and Lieven (1990) argued that the direction of causality might be reversed, however: perhaps having a bigger vocabulary (at least at a certain point) would lead to a greater representation for nouns.24 While exploring the referential/expressive phenomenon more rigorously, Bates et al. (1994) presented analyses largely supporting that view: much systematic variation in the “referentiality” (proportion nouns) in children’s vocabularies was due to the size of their vocabulary. As children’s vocabularies grow, they tends to increase in their over-representation of nouns (as shown also in Chapter 11). Thus, two children of the same age who have different proportions of nouns may also have different overall vocabulary sizes. After controlling for this factor, Bates et al. (1994) found only more limited evidence for stylistic variation. In the first subsection of this chapter, we pick up these analyses and apply them broadly to our dataset. A second area of stylistic variation that has been much discussed is whether some children go through a vocabulary “spurt,” defined as a change in the rate of vocabulary growth. The idea of a “spurt” or “explosion” occurs in a wide variety of discussions of early vocabulary (e.g., Nelson 1973; Kamhi 1986; Bates, Bretherton, and Snyder 1988, see e.g., @dapretto2000 for review). Clearly, from the average growth rates observed in Chapter 5, children’s vocabulary growth accelerates dramatically during the period following first birthday and the emergence of production. Investigations of this acceleration have focused on two distinct features: its variation across children and its explanation. Although there has been a tremendous amount of discussion of explanations for accelerations in vocabulary growth, we will not investigate this topic further here. Our data not allow us to investigate issues of mechanistic process directly. In addition, a short but convincing analysis by McMurray (2007) suggests that such acceleration is over-determined in the sense that it will likely emerge from almost any plausible mechanism acquisition mechanisms. Assuming that words vary in difficulty as a normal distribution, vocabulary growth will naturally accelerate with increases in a child’s ability. Thus, making reverse inferences from the presence of acceleration to a particular mechanism is unwarranted. The second issue – variation in acceleration – is related our aim here, however. Does every child’s vocabulary acceleration follow the same general pattern, or is there substantial variation in the type of growth that is followed, for example in the point at which acceleration begins, or the specific shape of the growth curve? Ganger and Brent (2004) report a systematic study of a subpart of this issue: whether there is a discontinuity in growth rate for individual children. Definining a spurt specifically as a change in the rate of acceleration, they conduct a quantitative analysis of whether such a change occurs. Our second set of analyses follows up on this general issue. The final area of stylistic variation that we address in our third subsection is the question of whether there are some children who are more fluent producers vs. others who have a large vocabulary in comprehension but more limited production. At the clinical extreme significant variation in this respect must be present, because there are some children with various apraxias of speech that have strong comprehension but serious production difficulties. The question is whether, in a typically developing population, we can detect systematic variation on this dimension. 14.1 Variation in Vocabulary Composition In this subsection we examine the question of variation across children in referential vs. expressive vocabulary. Following Bates et al. (1994), we operationalize the notion of a “referential” vocabulary as one that has a greater proportion of nouns relative to other classes (the definition of “noun” is the same here as in Chapter 11. While there might be other more nuanced measures that we could construct, this one has the advantage of being directly related to the framework in Chapter 11; thus, we use that same framework to investigate vocabulary composition in individuals here. The proportion of children’s vocabulary that is made up of nouns is shown in the figure above. There is a general trend for an over-representation of nouns, as shown by the blue line (representing the smoothed mean proportion nouns) being above the red dashed line (total porportion nouns on the form). The size of this over-representation is the topic of Chapter 11. Here we examine its variability across children. Is a referential style associated with having a larger vocabulary? The proportion of nouns in a child’s vocabulary should then be a predictor of vocabulary size, over and above age. A simple model of this hypothesis is a GLM predicting the number of CDI words a child produces as a function of age and proportion nouns.25 The coefficients of such a model, fit to the data from each language, are shown above. Age coefficients are positive, indicating more words with age. Proportion of nouns is also negative, indicating that having more nouns is related to a smaller vocabulary, controlling for age. (Standard errors are plotted, but are typically tiny and hence invisible.) This result appears to provide support for the opposite to the claimed relationship between the referential/expressive distinction and vocabulary size. Those children with more referential vocabularies have smaller vocabularies, controlling for age. The trouble is that these variables – age, noun bias, and total vocabulary size – have a complex relationship to one another. For a young child, having a bigger noun bias is correlated with having a bigger vocabulary (because they are on the early part of the “noun over-representation” curve shown in Chapter 11). In contrast, for an older child, having a bigger noun bias is correlated with having a smaller vocabulary because they are on the later part of the curve. Thus, the directionality of the relationship that you discover is largely determined by what part of your sample is densest. Put another way, proportion nouns could be predictive of vocabulary size not because children with a particular style have bigger vocabularies, but because having more nouns in your vocabulary tends to indicate that you are further along a standard prorgession. Put another way, perhaps all children follow the same trajectory through the noun bias. Even in this scenario, knowing the size of a child’s noun bias will tell you something about vocabulary size, without that implying that the child is following a different trajectory. This point is made in different ways by both Bates et al. (1994) and Lieven, Pine, and Barnes (1992). One way to circumvent this critique statistically is to measure whether a particular child has a greater-than-average, vocabulary-adjusted noun-bias. In other words, if we remove the average correlation with noun bias and vocabulary, can we still find a relation with individuals’ degree of noun bias and vocabulary size? The figure above shows both the English noun-proportion data (plotted now by vocabulary size) and the residuals of that distribution when fit via a cubic model (blue curve). The next question we can ask is how this “residualized style” relates to other variables like age, grammatical ability, and (in longitudinal data) further vocabulary growth. Note that we cannot compare this variable to other aspects of concurrent vocabulary size because features like, for example, number of closed class items in the vocabulary are non-independent (since the more nouns you have, by definition the fewer closed class items). Our first analysis looks at the correlation between vocabulary-residualized noun bias and age. The plot above shows coefficient estimates on this analysis. Now most age coefficients are reliably negative, suggesting that a greater residual noun bias is associated with being younger. Two of the main outliers here are from Mandarin, which, as discussed in Chapter 11, has the smallest noun bias of any of the languages in our dataset. Next we examine correlations with grammatical ability. Lieven, Pine, and Barnes (1992) was interested in the possibility that an alternative route into language from a referential style would be the use of construction-based generalizations. For grammatical complexity scores, we see that vocabulary-residualized noun bias is reliably related to grammatical complexity. Because of the residualization procedure, this relationship is over and above the correlations between grammar and lexicon (as reported in Chapter 13). Thus, those children with more nouns than expected for their vocabulary size produce less complex language. (Again, Mandarin is an exception). As seen above, they are also younger than expected. We next repeat the analysis of complexity while controlling for age and total production. The coefficients are shown above. Production of course has a positive relationship to grammatical complexity, as does age (see Chapter 13). Even controlling for these two factors, howver, we still observe a consistent negative relationship between residual noun bias and complexity. Summarizing, we were interested in this subsection in whether we found cross-linguistic evidence for different strategies for language learing, in particular the referential vs. expressive distinction. Operationalizing this distinction, we asked whether children with a larger noun-bias show differences in their language learning trajectory than children a smaller one. The relationships between overall noun bias and vocabulary are complex to interpret due to the non-linear relationships between these variables and age. To circumvent this, we examined a residualized noun bias measure that controls for total vocabulary. This measure was related to age and to grammatical complexity: children with relatively more nouns in their vocabulary tended to be younger and to be producing less complex speech, across languages. Taken together, these data provide some cross-linguistic support for the idea that children show variability beyond differences in rate of vocabulary acqisition. One dimension of variability is that, for a particular level of vocabulary size, there appear to be children who are younger, know more nouns, and combine words less (perhaps the “referential” children referred to in previous literature); other children will tend to be older, have a more diverse vocabulary (including more predicates), and will tend to use these to combine words more. 14.2 “Spurts” in Vocabulary Perhaps the most obvious aspect of early vocabulary is that it picks up speed over the second year after birth. First words are hard-won but soon children’s language appears to “explode.” This acceleration is easily visible in the plot above, which shows the median productive vocabulary from 8 - 18 months (English (American) Words and Gestures data). (We could measure the rate of learning by taking the derivative of this curve; but this rate calculation is slightly misleading for cross-sectional data and so we postpone this analysis until below). This increase in the rate of vocabulary learning has been much remarked on in the literature, as discussed above. Our starting point here is a study by Ganger and Brent (2004), who provide a detailed, curve-fitting analysis of the question of vocabulary “spurts.” They evaluate whether individual children’s longitudinal growth patterns are better fit by a model with constant acceleration in growth rate, or whether some children have a discontinuous “step” in terms of their growth rate. In our view, this is a productive approach, but presupposes some descriptive facts about children’s growth rate generally. For example, using longitudinal data, we can simply examine features of rate and acceleration and how they change with time. For these analyses we focus on longitudional production data from Norwegian and English WS and WG forms. Because we are interested in computing (potentially non-linear) changes in rate, we need four datapoints from each child as a minimum, and because we are interested in early changes, we set the restriction that the first time-point reported should have fewer than 50 words reported (50 words is often used as a semi-arbitrary cutoff for the vocabulary spurt; Dapretto and Bjork 2000; Ganger and Brent 2004). The decision to exclude children with larger vocabularies at their first recorded measurement means that we have some bias present to include children with slower vocabulary growth. In particular, from the WS data we exclude a substantial proportion of children even from the youngest groups (e.g., 0.22% of Norwegian 16-month-old). So as not to bias the analysis further by including a large proportion of older, slower learners, we only include children younger than 21 months in this sample. We now have a population of children for whom we can evaluate the rate of vocabulary growth and how it varies as a function of age. This winnowing leaves us with data from 290 children, whose growth curves are shown in the figure above. We exclude datapoints associated with large decreases in vocabulary (negative rates). Although some small negatives would be expected based on measurement error or forgetting, large negative spikes are rare and likely due to errors in the data (e.g., a partially filled form). We exclude rates of -10 words/month and below (0% of data). The figure above shows the child’s estimated growth rate in the measurement period leading up to that month (number of words learned since the last longitudinal measurement divided by number of months since that measurement) plotted by total words produced in that month. There is a clear quadratic shape to this pattern, almost certainly caused by ceiling effects for children who are “running out of words” on the form. The question of vocabulary spurts, as posed by Ganger and Brent (2004), is the way that vocabulary growth rate increase for individual children. Clearly it increases (because vocabulary growth picks up speed generally) – but does it grow smoothly, indicating constant acceleration? Or does it move from one equilibrium to another (indicating an initial “spurt”)? Ganger and Brent (2004) propose analyzing children’s growth rate as a function not of age, but of total vocabulary. To examine this question, we need to focus in on the initial 250 words when the average rate appears to be increasing linearly (before ceiling effects are found; see red curve above), and identify children with more than 4 CDIs before this time (to ensure sufficient density). Further, we need to examine the rate trajectories of individual children. The plot above shows this analysis for a randomly sampled subset of children in our available datasets. Ganger and Brent (2004) analyzed the question of developmental spurts by fitting different curve types to the rate function in their data. They compared the likelihood ratio of quadratic and logistic rate curves for each child’s data. The quadratic curve represented the hypothesis of smooth growth in rate (smooth acceleration). In contrast, the logistic curve was of the form \\[R \\sim \\frac{\\alpha}{1 - e^{-\\beta (W - \\gamma)}}\\] where \\(R\\) is the rate of acceleration, and it is assumed to be distributed as a function of \\(\\alpha\\), the asymptotic rate, \\(\\beta\\), the slope of the change between the initial and final rates, \\(W\\) (the total vocabulary), and \\(\\gamma\\), the point at which the spurt occurs. This curve captures a discrete “spurt” – a movement from one equilibrium to another. We fit these functions (as well as a simple linear function) to our data. Fitted curves for children with more than 7 datapoints are shown above. The basic visual impression from these data is that, even with the longitudinal depth we have for individual children, there is substantial uncertainty in the best-fitting curve. However, it does not appear that there are many children who show something that looks clearly like a spurt. A few children rise quickly and then show one datapoint that levels off. But there is a puzzle. We can only confirm that the rate has leveled off if we have data at higher levels of production. But for vocabulary size over 300 words, every child will level off in their rate because they have “run out of words” on the form. This example illustrates some of the difficulties in making strong inferences from data of this type. We next conducted the full model comparison analysis that Ganger and Brent (2004) conducted, over the 0 separate longitudinal records included.26 In Ganger &amp; Brent’s analysis, they used only two models (linear and quadratic), which had the same number of parameter. Accordingly, they compared only the likelihoods of the data under these models. In contrast, we compared a linear function with intercept at 0 (1 parameter), standard linear (2 parameters), quadratic (3 parameter), and logistic (3 parameter) curves. To make up for the difference in parameters, we computed Akaike’s Information Criterion (a measure of model goodness of fit, where smaller is better) for each model for each participant. Dataset linear linear0 logistic quadratic English (American) WS 1 2 0 0 Norwegian WG 2 35 20 17 Norwegian WS 3 11 6 4 The table above shows the proportion of children in each dataset for which different model types fit best. Overall, children were split between models, with some children best fit by the logistic. The linear functions, which were simpler, however, fit more participants better, with the 1-parameter linear model with no intercept best fitting more children than any other. The 26 children (out of 101 total) with a best-fitting quadratic model are shown above. Some of these children do appear to have data that are well-fit by the quadratic model. But for many, this fit appears to be the product of a signle datapoint; assuming some error, a more parsimonious model (e.g. simple linear) might do just as well. Thus, with more children but less density, our conclusion tends to be similar to Ganger and Brent (2004): there is limited evidence for a vocabulary spurt in most children. To further examine this issue in a denser dataset, we used data from Roy et al. (2015)’s in-depth study of a single child. This is an ultra-dense dataset with millions of words of transcribed speech and hand-checked age-of-acquisition data for over 600 words up to the child’s second birthday. The comparable curves for this dataset are shown above. Using the same AIC method, the quadratic model fits best, but the linear model is clearly close as well. Stepping back, in this subsection we examined the growth rate of children’s vocabulary. To a first, group-wise approximation, children’s vocabulary growth accelerates linearly with vocabulary size during the initial period (up to around 250 words). After this point, we run into substantial measurement issues because the CDI does not contain enough words to be certain of the pattern of growth. Further, when we examined individuals’ growth, it also often appeared to be linear or quadratic; only in a minority of individuals was there any evidence for a “spurt” (a discrete change). This conclusion was tempered, however, by the difficulty of drawing conclusions without even denser longitudinal data concerning the very beginnings of language. 14.3 Variation in Production vs. Comprehension Our next investigation concerns the question of how tightly comprehension and production are yoked within CDI data. Our assumption is that there is variability between children on this dimension – while some children produce a large amount of language, others appear to produce less but still understand substantial amounts. How does the ratio of production to comprehension vary across ages, and across cultures? It is important to be clear that some of the pattern in this variable could be due to variation between parents in under- or over-reporting comprehension (or for that matter, production, but we assume – and Chapter 4 confirms – that production reports likely carries more signal). For example, we might be detecting variation in the threshold at which parents assume that a response indicates comprehension. Some parents might be very liberal and recall a generally-understood story that included a particular word, while others might be searching for a specific anecdote that clearly illustrates comprehension of that word. Of course this type of analysis can only be conducted on WG-type forms, because of the presence of comprehension information. We begin by investigating the American English WG data as an example. The figure above shows individual children’s comprehension and production plotted against one another. The diagonal indicates a child who comprehends and produces exactly the same number of words. In practice, this measure is always below the diagonal because by the design of the form, a child cannot “say but not understand” a particular word, they can only “understand” or “say and understand.” We can convert these data into a productivity ratio: \\[productivity = \\frac{\\# produced}{\\# understood}\\] and plot this ratio for all children. The resulting scatterplot is quite interpretable. It contains a few outliers at the very top of the range for very young children (whose parents report them producing and comprehending the same number of words). But for most others, the ratio is low, increasing from about 10% to 30% by the top of the form. The figure above plots these productivity ratios by language for an age-restricted subset between 8 and 18 months. Plots are sorted by the mean productivity ratio. While the majority of languages show the same pattern as English (an increase from around 10% to 30%) there are some outliers that show a flatter slope. We can see this pattern even better by plotting the best-fit lines across languages. Nearly all of these go up with age and have similar slopes. Going back to the scatter plots, however, in nearly every language to one degree or another, we see some number ratios &gt; .95, indicating that parents are essentially not using “understands” as a separate option. The table above shows the proportion of children showing more than 95% productivity. A number of samples have substantial proportions of parents reporting comprehension in this way. While it is possible that these numbers represent actual children whose production is synchronized with their comprehension, a more parsimonious explanation is that there are local variations in administration, leading to some fraction of parents not completing the form properly. In particular, it does not appear that these “no comprehension without production” children are the tail of a shifted distribution of productivity ratios; instead, they appear to be due to a separate small population. Yet despite that they appear to have an outsized effect on our estimates of the development of productivity ratios across languages. In sum, although the relationship between production and comprehension is a fascinating locus for individual differences, we may not be able to measure this relationship effectively using cross-linguistic comprehension data. Further, these analyses underscore the importance of instructions regarding comprehension in CDI administration. 14.4 Conclusions Summarizing the conclusions from our various different sub-analyses: The traditional referential vs. expressive distinction is supported by cross-linguistic analysis that suggests that, even at a given level of vocabulary size, some children tend to be younger, use more nouns, and combine less; others will tend to be older, know more predicates, and combine words more. Vocabulary growth is approximately linear for the first 250 words, and a “vocabulary spurt” is not reliably observed across most children (ratifying earlier work by Ganger and Brent 2004). It is tricky to use comprehension data to estimate variability between individuals in how much they produce vs. comprehend, due to likely cross-linguistic differences in the uptake of instructions regarding comprehension. Caught up in this discussion is the question of whether there is a route into language via the memorization of “frozen phrases.” This is an independent theoretical question that is difficult to address with CDI data as it is a question about the repetitive use of chunks of language in production. One observation is that, due to evidence of early verb generalization (e.g., Gertner, Fisher, and Eisengart 2006), the original discussion about limited generalization in children’s early syntax has been somewhat subsumed into a discussion about differences between general comprehension and conservative production.↩ We omit interactions from most of the models below for interpretability; including interactions leads to unstable coefficient estimates.↩ This number consolidates data between WG and WS forms when a child has both, to maximize our use of the available longitudinal data.↩ "],
["conclusion-consistency.html", "15 Variability and Consistency 15.1 Measuring variability and consistency 15.2 Synthesis", " 15 Variability and Consistency In the preceding chapters, we have have presented evidence from a wide range of analyses of the Wordbank dataset. These analyses have revealed both striking variability across our units of sampling – children, primarily, but also words and even languages – but they have also revealed substantial consistency. In this synthetic chapter we begin by presenting a set of analyses of the empirical consistency and variability of specific phenomena. We then discuss the interplay and tension between these two ideas, variability and consistency, and how they interact with and inform theoretical conceptions of language acquisition more broadly. 15.1 Measuring variability and consistency In each of the substantive chapters of this book (roughly speaking from Chapter 5 to 14), we have presented analyses of specific phenomena of theoretical interest. Wherever possible, we have generalized these analyses across languages so that their relative consistency can be examimined and discussed. The goal of the current analysis is to bring together these analyses into a single meta-analysis (in the general sense, not the specific statistical sense). This strategy executes the general idea discussed in Chapter 1. Our analyses identify “signatures” of language development that have been central to theoretical discussion. We then quantify these signatures numerically and measure their variation across languages. The resulting quantities are an empirically-derived measure of which aspects of language development appear more similar across different languages and contexts. We discuss the types of inferences licensed and not licensed by these analyses below. 15.1.1 Methods Each measure for which we compute the CV will have both a different base unit and a different number of languages contributing. For example, when considering the correlation between grammar and the lexicon (Chapter 13), we will be looking at the CV of a set of correlations with one specific set of languages contributing. When we look at the size of the noun bias (Chapter 11) we will be looking at a group of bias estimates that have different units and a different set of languages. Thus, caution is warranted in interpreting these variability estimates, even as we believe that they are informative. To assist in interpretation, we exclude measures that can be computed in fewer than 7 languages; provide the N contributing languages for all analyses; and compute an estimate of the standard error of the CV (\\[SEM \\approx CV / \\sqrt{2N}\\]). We begin by identifing a small number of measures computed in each chapter to serve as the “signatures” to be promoted into this analysis. For each measure, we compute its cross-linguistic variability using a standardized measure of variance, the coefficient of variation (CV, the standard deviation divided by the mean). This measure can range from 0 (with a phenomenon completely invariant across languages) to infinity (with higher numbers indicating greater variation). These CV values provide a single common measure to allow comparability of otherwise very different quantities, allowing inferences across analyses and datasets – albeit with some cautions that we describe below. Each measure for which we compute the CV will have both a different base unit and a different number of languages contributing. For example, when considering the correlation between grammar and the lexicon (Chapter 13), we will be looking at the CV of a set of correlations with one specific set of languages contributing. When we look at the size of the noun bias (Chapter 11) we will be looking at a group of bias estimates that have different units and a different set of languages. Thus, caution is warranted in interpreting these variability estimates, even as we believe that they are informative. To assist in interpretation, we exclude measures that can be computed in fewer than 7 languages; provide the N contributing languages for all analyses; and compute an estimate of the standard error of the CV (\\(SEM \\approx CV / \\sqrt{2N}\\)). The measures we include in this analysis are necessarily a subjectively-determined subset of the possible measures we have examined in the book. And of course those in turn are a subset of the measures we could have computed. Wherever possible we have attepted to make reasonable decisions, but some of these are by necessity somewhat arbitrary. An example of such a decision comes from the summary of Chapter 5. In that chapter we noted that population variability appears quite consistent across languages. We summarised population variability in production via a statistic, MMAD – but what is the appropriate range of ages to include in a single estimate? We noted that there appears to be a ceiling effect in the later ages, and so include variability in production from 12 – 24 months. But this decision is data-dependent and so of course there is a risk of circularity. We point the issue out not to undermine this particular analysis; we believe the ceiling effect is quite clear and other aspects of the age choice do not lead to much change in the CV estimate. Rather we intend to highlight that the summary we give is not a theory-neutral estimate but rather a “best guess” – an attempt to navigate the myriad choices involved in our analysis in a reasonable way. One example of such a choice is that we have made the decision to omit estimates of early production from WG-type forms. Our judgment was motivated by the fact that such estimates routinely are very noisy due to the sparsity of early production. In chapter after chapter, we found unreliable or uninterpretable results that are plausibly due to data sparsity; thus, we choose to omit these patterns. For the sake of our analysis, we have divided measures from the preceding chapters into four categories. These are: Measures of the composition of vocabulary, from Chapters 11 and 12. These measures describe the over- and under-representation of various word categories in vocabulary. The units over which CV is computed are bias scoresl; these are bounded from -.5 to .5 (deviation from unbiased acquisition of a particular category). Predictors of word difficulty, from Chapter 10. The consistency of different regression predictors of age of acquisition are here represented by their cross-linguistic consistency. This analysis is distinct from the analysis presented in that chapter (which focused mostly on the magnitude rather than variability of the coefficients themselves). Despite that, we include it here for comparison with other signatures. The units over which CV is computed are standardized regression coefficients. Relational measures. These measures are from Chapters 7 and 13. These measures are originally correlations between vocabulary size and other aspects of early language. Vocabulary signatures. These measures document patterns in the overall size of vocabulary across individuals and demographic groups. They are extracted from Chapters 5 and 6 and the original units are themselves variability-based (MMAD scores). 15.1.2 Results The figure above shows the coefficient of variation across languages for all measures in each of these categories. Error bars show standard error of the CV. Dot size shows the number of languages included in the analysis. Color shows whether the measure was computed on comprehension or production. Points are ordered from lowest CV to highest. A number of patterns are immediately apparent, providing a synthesis across the different parts of our broader enterprise. First, comprehension is almost always more variable than production, even when an even number of languages are included. The only obvious exception to this regularity is for coefficient weights on arousal in the Predictors category – and we can discount this example: arousal was on average one of the weakest predictors of acquisition order overall. Why would comprehension be more variable across languages than production, especially given evidence that comprehension vocabulary tends to be less idiosyncratic than production (Mayor and Plunkett 2014)? One strong possibility is the psychometric properties of comprehension vs. production reports. As described in Chapter 4, while comprehension scores still appear to be a reliable and valid index of children’s abilities in the aggregate, individual comprehension questions tend to carry less information. Thus, there may simply be more noise in these measurements, leading to less cross-linguistic stability. This regularity illustrates a point we have made earlier and will return to below: the inferences from consistency and variability are asymmetric. In the case of consistency, we can make relatively strong inferences about some kind of shared process or mechanism. In contrast, in the case of variability, there are many sources of variance (including measurement error) that can account for a specific pattern of performance. Second, relational measures are highly invariant across languages. These relations include correlations between the size of children’s lexicon (in production or comprehension) and their gesture, morphology, and grammatical complexity. These findings can be measured in a relatively small set of languages (due to limited data availability for the gesture and complexity items on the form). Nevertheless, the high level of consistency is striking. Of course, as we disussed in the associated chapters, one possible confound in these findings is general parent reporting bias, but – as other evidence militates against this explanation – we are forced towards a view of early language as a highly coherent construct (following e.g., Bornstein and Haynes 1998). Third, demographic predictors – birth order, maternal education, and sex – are somewhat variable, likely reflecting at least some cultural variation. The most variable of these is the relation of maternal education with vocabulary. Maternal education is plausibly a proxy for socioeconomic status (SES); in turn the relation of SES to vocabulary is likely mediated by many local- and national-level policies including access to childcare, parent leave, pre- and post-partum education and services. Thus, we view variation on this dimention as highly plausible a priori. In contrast, as we asserted in Chapter 5, the consistency of children’s variability is quite striking: the variability of children across instruments is almost completely constant, especailly for production. Around the world, toddlers appear to be have similar levels of variability in their level of production. As we explored in Chapter 5, one suggestive explanation of this fimding is that much of this variability is endogenous to the child (or the child-caregiver dyad) rather than being a product of specific variation in the environment. Fourth, generalizations about vocabulary composition span the range from extremely consistent (early over-representation of body parts) to extremely variable (bias for – or against – predicates). Overall, however, it is interesting to see that there are some consistencies in the things that children talk about early: in particular the bias for body parts and animal words seems consistent with some of the results on the predictive power of “babiness” (things babies like to talk about) in Chapter 10. In contrast, it’s the hard and abstract domains that are somewhat more variable, e.g. color, time, logic words (and function words more generally). These analyses are limited by the relatively small set of lexical items that are shared across languages and aross the CDI forms for those languages, however. Finally, while predictors of word difficulty are consistent relative to a chance baseline (see Chapter 10), they are also on the higher end of variability. Especially in comparison to some of the relational signatures (e.g., the correlation between grammatical complexity and vocabulary), their variability is high. Plausibly some of this variability is due to additional variation added to these estimates by the use of external resources (e.g., corpus counts). In particular, as we discussed in that earlier chapter, there is an unknown amount of noise added by estimating frequencies from smaller-scale cross-linguistic corpora. 15.2 Synthesis What is the picture of language development that emerges from the analysis above? In this section we return to the theoretical speculation of Chapter 1. The goal of characterizing areas of consistency in theoretically-relevant signatures of early language was to be able to provide constraints on theory. We turn back to the question of these constraints and how they intersect with existing theories of language development. In Chapter 1, we introduced the idea of “process universals.” These cannot be universals of content as all of the content being reported by parents filling CDI forms is language-specific. Intead, the idea of process universals is that there are processes that operate in different language context to produce the observed pattern of phenomena. These processes could be – but need not be – learner-internal. They could also operate at the level of the child-caregiver dyad, for example. In what follows, we move away from the term “universal.” Although in principle our theoretical goal is process universals, in practice thelimitations of the analysis above are such that we can only speak about “consistent processes.” Not only do we have a maximum of 43 distinct language/instrument samples represented in any estimate, we have a maximum of 29 languages or dialects in any analysis (and often considerably fewer) . This sample, while strong in terms of the within-language estimates, is only a weak start in terms of cross-language estimates (see Piantadosi and Gibson 2014 for guidance on claims about strict universals). Further, there is a strong Indo-European and WEIRD (western, educated, industrialized, rich, democratic) bias amongst the languages in the database (Henrich, Heine, and Norenzayan 2010). Thus, some consistencies that we observe are probably conditioned on environmental consistencies as well as dyadic and child-internal processes. In the remainder of this chapter, we speculate on some of these. So what sort of developmental process of vocabulary learning could lead to these universals? Any claim of this sort must be very speculative. If pushed, we would point to the following (weak) proposals regarding processes that are consistent with some of our putative universals. Demographic differences are – at least – consistent with interactional-input theories of vocabulary development (Hart and Risley 1995; Hoff 2003; Weisleder and Fernald 2013) in which the more and higher-quality the input the child receives, the faster vocabulary grows. Under this hypothesis, first-born, female, and higher-maternal education children all are likely to receive more and higher-quality input: female children through the route of their somewhat greater social/interactional abilities (an extra assumption), first-born children through their greater allocation of parent attention, and high maternal-education children through greater parental awareness of the role of input, differering parental practices, and greater amount of leisure time to spend with children among other factors. Both the noun bias and the age-of-acquisition prediction results are consistent with the broader cross-situational viewpoint on acquisition (Smith and Yu 2008; Gleitman 1990). On this view, nouns are easy to learn because the more they are heard, the more opportunities children get to build consistent mappings between the words and their referents. In contrast, verbs and other predicates rely more on a base of nouns and a basic comprehension of the syntactic structures in which they appear in order to infer meaning in context. Thus they should be acquired relatively later and with relativel more support from shorter, easier-to-parse utterances (MLU as a predictor, for example). Cross-linguistic exceptions will tend to be for languages like Mandarin where many early-learned verbs are semantically-transparent enough to be learned cross-situationally. Correlations between grammar and the lexicon, as well as the greater role of MLU in predicting acquisition of function words are both consistent with views that posit gradual syntactic abstraction and generalization. Versions of such viewpoints exist throughout the broad theoretical space of language acquisition (Yang 2016; Tomasello 2003; Meylan et al. 2017), but all proposals rely on a learning mechanism in which generalizations about structure are graded and rely on the amount of evidence available. "],
["conclusion-scale.html", "16 Language Development at Scale 16.1 Content themes 16.2 Methodological themes 16.3 Theoretical Themes 16.4 Conclusions", " 16 Language Development at Scale What have we learned about language development through the analyses presented in this book? Are there empirical generalizations that we can make fo This chapter synthesizes knowledge gained from the broader enterprise, in the sense of attempting to make generalizations about early language development that hold true across the different datasets in our sample. 16.1 Content themes Across children, variability is a constant in early language. The first words are very consistent across languages. Gender, first-born, and SES Early social/communicative gesture is correlated with language. While there is some noun bias in nearly all languages, verbs/adjective bias varies by language. No explanation yet for sources. The growth of grammar is linked to vocabulary growth. Style??? 16.2 Methodological themes Wordbank embodies our belief that scale is in itself transformative. The existence of a noun bias is a fascinating observation, but this observation gives limited leverage to differentiate theories. The magnitude of a noun bias provides more leverage for quantiative theorizing. And the distribution of magnitudes across many of the world’s languages gives greater leverage still. Our hope is that, by generalizing and applying many influential analyses by many contributors, our work here can affect theory more broadly. More ABOUT POWER TO MEASURE MEAN AND VARIANCE REPRODUCIBILITY 16.3 Theoretical Themes 16.4 Conclusions Developmental psychology often appears to be divided between two groups that do not communicate with one another. On the one hand, there are researchers interested in the ontogenetic and phylogenetic origins of knowledge – the epistemological project of understanding how we reason about objects, communicate using language, or learn from other people (???, @spelke2007, @tomasellooriginoflanguage). On the other hand, there are researchers interested in growth, change, and variation across individuals in psychometric constructs like executive function, working memory, and personality (???, other cites). The first type of research has led to a productive union of philosophical and psychological ideas, addressing many of the most exciting questions in the history of philosophy using empirical methods (???, @carey). The second type has had success in its connections to educational policy (Nelson 2007; Diamond and Lee 2011, others?). In many areas of research, these two traditions have little interchange with one another. They read different journals, record different measures, use different research designs and statisical models, and often appear to be pursuing entirely different goals. Yet language learning is an area where these traditions come together. The knowledge being acquired – the stock of words in the child’s lexicon – is both the epistemic construct whose origins we are studying and the psychometric construct whose reliability across individuals we wish to assess. By studying the variability and consistency in the early lexcion, we can both study the origins of knowledge and the processes and factors by which human beings differ from one another across different cultural contexts, family environments, and genetic endowments. "],
["appendix-data.html", "A Individual Datasets", " A Individual Datasets This appendix give the specifics of the data represented in each of the languages of the book. English (American) Dataset name: Marchman Instrument: WS Contributor: Larry Fenson, San Diego State University Citation: Fenson, L., Marchman, V. A., Thal, D., Dale, P., Reznick, J. S. &amp; Bates, E. (2007). MacArthur-Bates Communicative Development Inventories: User’s Guide and Technical Manual. 2nd Edition. Baltimore, MD: Brookes Publishing Co. Dataset name: Marchman Instrument: WS Contributor: Virginia Marchman, Stanford University Citation: Dataset name: Marchman Instrument: WS Contributor: Virginia Marchman, Stanford University Citation: Dataset name: Smith Instrument: WS Contributor: Linda Smith, Indiana University Citation: Dataset name: Smith Instrument: WS Contributor: Linda Smith, Indiana University Citation: Dataset name: Byers Instrument: WS Contributor: Krista Byers-Heinlein, Concordia University Citation: Dataset name: Thal Instrument: WS Contributor: Donna Thal, San Diego State University Citation: Thal, D. J., Marchman, V. A. &amp; Tomblin, J. B. (2013). Late talking toddlers: Characterization and prediction of continued delay. In L. Rescorla &amp; P. Dale (Eds.). Late Talkers: Language Development, Interventions, and Outcomes. Baltimore, MD.: Brookes Publishing. Dataset name: Thal Instrument: WS Contributor: Donna Thal, San Diego State University Citation: Thal, D. J., Marchman, V. A. &amp; Tomblin, J. B. (2013). Late talking toddlers: Characterization and prediction of continued delay. In L. Rescorla &amp; P. Dale (Eds.). Late Talkers: Language Development, Interventions, and Outcomes. Baltimore, MD.: Brookes Publishing. Dataset name: Marchman Instrument: WG Contributor: Larry Fenson, San Diego State University Citation: Fenson, L., Marchman, V. A., Thal, D., Dale, P., Reznick, J. S. &amp; Bates, E. (2007). MacArthur-Bates Communicative Development Inventories: User’s Guide and Technical Manual. 2nd Edition. Baltimore, MD: Brookes Publishing Co. Dataset name: Byers Instrument: WG Contributor: Krista Byers-Heinlein, Concordia University Citation: Dataset name: Thal Instrument: WG Contributor: Donna Thal, San Diego State University Citation: Thal, D. J., Marchman, V. A. &amp; Tomblin, J. B. (2013). Late talking toddlers: Characterization and prediction of continued delay. In L. Rescorla &amp; P. Dale (Eds.). Late Talkers: Language Development, Interventions, and Outcomes. Baltimore, MD.: Brookes Publishing. Dataset name: Thal Instrument: WG Contributor: Donna Thal, San Diego State University Citation: Thal, D. J., Marchman, V. A. &amp; Tomblin, J. B. (2013). Late talking toddlers: Characterization and prediction of continued delay. In L. Rescorla &amp; P. Dale (Eds.). Late Talkers: Language Development, Interventions, and Outcomes. Baltimore, MD.: Brookes Publishing. Spanish (Mexican) Dataset name: Marchman Instrument: WS Contributor: Donna Jackson-Maldonado, Universidad Autónoma de Querétaro Citation: Jackson-Maldonado, D., Thal, D., Marchman, V., Newton, T., Fenson, L, &amp; Conboy, B. (2003). MacArthur Inventarios del Desarrollo de Habilidades Comunicativas. User´s Guide and Technical Manual. Brookes, Baltimore. Dataset name: Marchman Instrument: WG Contributor: Donna Jackson-Maldonado, Universidad Autónoma de Querétaro Citation: Jackson-Maldonado, D., Thal, D., Marchman, V., Newton, T., Fenson, L, &amp; Conboy, B. (2003). MacArthur Inventarios del Desarrollo de Habilidades Comunicativas. User´s Guide and Technical Manual. Brookes, Baltimore. Danish Dataset name: Bleses Instrument: WS Contributor: Dorthe Bleses, University of Southern Denmark Citation: Bleses, D., Vach, W., Slott, M., Wehberg, S., Thomsen, P., Madsen, T. &amp; Basbøll, H. (2008). The Danish Communicative Development Inventories: validity and main developmental trends. Journal of Child Language, 35, 619-650. Norwegian Dataset name: Kristoffersen Instrument: WS Contributor: Hanne Simonsen and Kristian Kristoffersen, University of Oslo Citation: Simonsen, H. G., Kristoffersen, K. E., Bleses, D., Wehberg, S., &amp; Jørgensen, R. N. (2014). The Norwegian Communicative Development Inventories: Reliability, main developmental trends and gender differences. First Language, 34(1), 3-23. DOI: 10.1177/0142723713510997 Dataset name: Kristoffersen Instrument: WS Contributor: Hanne Simonsen and Kristian Kristoffersen, University of Oslo Citation: Simonsen, H. G., Kristoffersen, K. E., Bleses, D., Wehberg, S., &amp; Jørgensen, R. N. (2014). The Norwegian Communicative Development Inventories: Reliability, main developmental trends and gender differences. First Language, 34(1), 3-23. DOI: 10.1177/0142723713510997 Dataset name: Kristoffersen Instrument: WG Contributor: Hanne Simonsen and Kristian Kristoffersen, University of Oslo Citation: Simonsen, H. G., Kristoffersen, K. E., Bleses, D., Wehberg, S., &amp; Jørgensen, R. N. (2014). The Norwegian Communicative Development Inventories: Reliability, main developmental trends and gender differences. First Language, 34(1), 3-23. DOI: 10.1177/0142723713510997 Dataset name: Kristoffersen Instrument: WG Contributor: Hanne Simonsen and Kristian Kristoffersen, University of Oslo Citation: Simonsen, H. G., Kristoffersen, K. E., Bleses, D., Wehberg, S., &amp; Jørgensen, R. N. (2014). The Norwegian Communicative Development Inventories: Reliability, main developmental trends and gender differences. First Language, 34(1), 3-23. DOI: 10.1177/0142723713510997 Croatian Dataset name: CLEX Instrument: WG Contributor: Melita Kovacevic, University of Zagreb Citation: Kovacevic, M., Babic, Z., &amp; Brozovic, B. (1996). A Croatian language parent report study: Lexical and grammatical development. Paper presented at the VIIth International Congress for the Study of Child Language, July 1996, Istanbul, Turkey. Dataset name: CLEX Instrument: WS Contributor: Melita Kovacevic, University of Zagreb Citation: Kovacevic, M., Babic, Z., &amp; Brozovic, B. (1996). A Croatian language parent report study: Lexical and grammatical development. Paper presented at the VIIth International Congress for the Study of Child Language, July 1996, Istanbul, Turkey. German Dataset name: Szagun Instrument: WS Contributor: Gisela Szagun, University College London Citation: Szagun, G., Stumper, B. &amp; Schramm, A.S. (2009). Fragebogen zur frühkindlichen Sprachentwicklung (FRAKIS) und FRAKIS-K (Kurzform). Frankfurt: Pearson Assessment. Italian Dataset name: CLEX Instrument: WS Contributor: Christina Caselli, Institute of Cognitive Sciences and Technologies Citation: Caselli, M. C., Bates, E., Casadio, P., Fenson, J., Fenson, L., Sanderl, L., &amp; Weir, J. (1995). A cross-linguistic study of early lexical development. Cognitive Development, 10(2), 159-199. Russian Dataset name: CLEX Instrument: WG Contributor: Stella Ceytlin, SPb Russian Pedagogical University Citation: Е.А.Вершинина, М.Б. Елисеева, Т.С. Лаврова, В.Л. Рыскина, С.Н. Цейтлин. Некоторые нормативы речевого развития детей от 8 до 18 месяцев// Специальное образование: традиции и инновации: Сборник научно-методических трудов с международным участием. — СПб.: Изд-во РГПУ им. А. И. Герцена, 2011. Dataset name: CLEX Instrument: WS Contributor: Stella Ceytlin, SPb Russian Pedagogical University Citation: М.Б. Елисеева, Е.А. Вершинина. Некоторые нормативы речевого развития детей от 18 до 36 месяцев (по материалам МакАртуровского опросника) // Проблемы онтолингвистики – 2009. Материалы международной конференции 17-19 июбня 2009 г. Санкт-Петербург, С.72-78 Swedish Dataset name: CLEX Instrument: WG Contributor: Mårten Eriksson, University of Gävle Citation: Eriksson, M., &amp; Berglund, E. (2002). Instruments, scoring manual and percentile levels of the Swedish Early Communicative Development Inventory, SECDI. (FoU-Rapport 17). Gävle, Sweden: Institutionen för pedagogik, didaktik och psykologi. Dataset name: CLEX Instrument: WS Contributor: Mårten Eriksson, University of Gävle Citation: Eriksson, M., &amp; Berglund, E. (2002). Instruments, scoring manual and percentile levels of the Swedish Early Communicative Development Inventory, SECDI. (FoU-Rapport 17). Gävle, Sweden: Institutionen för pedagogik, didaktik och psykologi. Turkish Dataset name: CLEX Instrument: WG Contributor: Aylin Küntay, Koç University Citation: Acarlar, F., Aksu-Koç, A., Küntay, A.C., Maviş, İ., Sofu, H., Topbaş, S., Turan, F. (2009). Adapting MB-CDI to Turkish: The first phase. In S. Ay, Ö. Aydın., İ. Ergenç, S. Gökmen, S. İşsever, and D. Peçenel (Eds.) Essays on Turkish linguistics: Proceedings of the 14th International Conference on Turkish Linguistics, August 6-8, 2008. Harrassowitz Verlag: Wiesbaden, Germany. Dataset name: CLEX Instrument: WS Contributor: Aylin Küntay, Koç University Citation: Acarlar, F., Aksu-Koç, A., Küntay, A.C., Maviş, İ., Sofu, H., Topbaş, S., Turan, F. (2009). Adapting MB-CDI to Turkish: The first phase. In S. Ay, Ö. Aydın., İ. Ergenç, S. Gökmen, S. İşsever, and D. Peçenel (Eds.) Essays on Turkish linguistics: Proceedings of the 14th International Conference on Turkish Linguistics, August 6-8, 2008. Harrassowitz Verlag: Wiesbaden, Germany. Hebrew Dataset name: Shalev Instrument: WG Contributor: Hila Gendler Shalev, Tel-Aviv University Citation: Gendler-Shalev, H. (2005). תירבעל HCDI-WG םירוה ןולאש תמאתה. Dataset name: Shalev Instrument: WS Contributor: Hila Gendler Shalev, Tel-Aviv University Citation: Cantonese Dataset name: Tardif Instrument: WS Contributor: Twila Tardif, University of Michigan Citation: Tardif, T., Fletcher, P., Liang, W., &amp; Kaciroti, N. (2009). Early vocabulary development in Mandarin (Putonghua) and Cantonese. Journal of child language, 36(05), 1115-1144. Mandarin (Beijing) Dataset name: Tardif Instrument: WS Contributor: Twila Tardif, University of Michigan Citation: Tardif, T., Fletcher, P., Liang, W., &amp; Kaciroti, N. (2009). Early vocabulary development in Mandarin (Putonghua) and Cantonese. Journal of child language, 36(05), 1115-1144. British Sign Language Dataset name: Woll Instrument: WG Contributor: Bencie Woll, University College London Citation: Woolfe, T., Herman, R., Roy, P., &amp; Woll, B. (2010). Early vocabulary development in deaf native signers: a British Sign Language adaptation of the communicative development inventories. Journal of Child Psychology and Psychiatry, 51(3), 322-331. Mandarin (Beijing) Dataset name: Li Instrument: TC Contributor: Ping Li, Pennsylvania State University Citation: Hao, M., Shu, H., Xing, A., &amp; Li, P. (2008). Early vocabulary inventory for Mandarin Chinese. Behavior Research Methods, 40, 728-733. English (American) Dataset name: Frank Instrument: WG Contributor: Michael C. Frank, Stanford University Citation: Italian Dataset name: Caselli Instrument: WG Contributor: Christina Caselli, Institute of Cognitive Sciences and Technologies Citation: Caselli, M. C., Rinaldi, P., Stefanini, S., &amp; Volterra, V. (2012). Early action and gesture ‘vocabulary’ and its relation with word comprehension and production. Child Development, 83(2), 526-542. Danish Dataset name: CLEX Instrument: WG Contributor: Dorthe Bleses, University of Southern Denmark Citation: Bleses, D., Vach, W., Slott, M., Wehberg, S., Thomsen, P., Madsen, T. &amp; Basbøll, H. (2008). The Danish Communicative Development Inventories: validity and main developmental trends. Journal of Child Language, 35, 619-650. French (Quebecois) Dataset name: CLEX Instrument: WG Contributor: Natacha Trudeau, Université de Montréal Citation: Boudreault, M. C., Cabirol, E. A., Poulin-Dubois, D., Sutton, A., &amp; Trudeau, N. (2007). MacArthur Communicative Development Inventories: Validity and preliminary normative data. La Revue d’orthophonie et d’audiologie, 31(1), 27-37. Slovak Dataset name: Kapalkova Instrument: WG Contributor: Svetlana Kapalková, Comenius University Citation: Dataset name: Kapalkova Instrument: WS Contributor: Svetlana Kapalková, Comenius University Citation: French (Quebecois) Dataset name: Trudeau Instrument: WS Contributor: Natacha Trudeau, Université de Montréal Citation: Trudeau, N., &amp; Sutton, A. (2011). Expressive vocabulary and early grammar of 16-to 30-month-old children acquiring Quebec French. First Language, 0142723711410828. English (British) Dataset name: TEDS Instrument: TEDS Twos Contributor: Philip Dale, University of New Mexico Citation: Dale, P. S., Price, T. S., Bishop, D. V. M., &amp; Plomin, R. (2003). Outcomes of early language delay: I. Predicting persistent and transient difficulties at 3 and 4 years. Journal of Speech-Language-Hearing Research, 46, 544-560. Dataset name: TEDS Instrument: TEDS Threes Contributor: Philip Dale, University of New Mexico Citation: Dale, P. S., Price, T. S., Bishop, D. V. M., &amp; Plomin, R. (2003). Outcomes of early language delay: I. Predicting persistent and transient difficulties at 3 and 4 years. Journal of Speech-Language-Hearing Research, 46, 544-560. American Sign Language Dataset name: Marchman Instrument: FormA Contributor: Diane Anderson, University of California, Berkeley Citation: Anderson, D., &amp; Reilly, J. (2002). The MacArthur Communicative Development Inventory: Normative data for American Sign Language. Journal of Deaf Studies and Deaf Education, 7(2), 83–106. Dataset name: Marchman Instrument: FormBOne Contributor: Diane Anderson, University of California, Berkeley Citation: Anderson, D., &amp; Reilly, J. (2002). The MacArthur Communicative Development Inventory: Normative data for American Sign Language. Journal of Deaf Studies and Deaf Education, 7(2), 83–106. Dataset name: Marchman Instrument: FormBTwo Contributor: Diane Anderson, University of California, Berkeley Citation: Anderson, D., &amp; Reilly, J. (2002). The MacArthur Communicative Development Inventory: Normative data for American Sign Language. Journal of Deaf Studies and Deaf Education, 7(2), 83–106. Dataset name: Marchman Instrument: FormC Contributor: Diane Anderson, University of California, Berkeley Citation: Anderson, D., &amp; Reilly, J. (2002). The MacArthur Communicative Development Inventory: Normative data for American Sign Language. Journal of Deaf Studies and Deaf Education, 7(2), 83–106. Greek (Cypriot) Dataset name: Grohmann Instrument: WS Contributor: Kleanthes K. Grohmann, University of Cyprus Citation: Taxitari, Loukia, Maria Kambanaros &amp; Kleanthes K. Grohmann. 2015. ‘A Cypriot Greek Adaptation of the CDI: Early Production of Translation Equivalents in a Bi(dia)lectal Context’. Journal of Greek Linguistics 15, 1–24. Kigiriama Dataset name: Alcock Instrument: WG Contributor: Katie Alcock, Lancaster University Citation: Alcock, K., Rimba, K., Holding, P., Kitsao-Wekulo, P., Abubakar, A., Newton, C.R.J.C. (2015) Developmental inventories using illiterate parents as informants: Communicative Development Inventory (CDI) adaptation for two Kenyan languages. Journal of Child Language, 42, 763-785. Dataset name: Alcock Instrument: WS Contributor: Katie Alcock, Lancaster University Citation: Alcock, K., Rimba, K., Holding, P., Kitsao-Wekulo, P., Abubakar, A., Newton, C.R.J.C. (2015) Developmental inventories using illiterate parents as informants: Communicative Development Inventory (CDI) adaptation for two Kenyan languages. Journal of Child Language, 42, 763-785. Kiswahili Dataset name: Alcock Instrument: WG Contributor: Katie Alcock, Lancaster University Citation: Alcock, K., Rimba, K., Holding, P., Kitsao-Wekulo, P., Abubakar, A., Newton, C.R.J.C. (2015) Developmental inventories using illiterate parents as informants: Communicative Development Inventory (CDI) adaptation for two Kenyan languages. Journal of Child Language, 42, 763-785. Dataset name: Alcock Instrument: WS Contributor: Katie Alcock, Lancaster University Citation: Alcock, K., Rimba, K., Holding, P., Kitsao-Wekulo, P., Abubakar, A., Newton, C.R.J.C. (2015) Developmental inventories using illiterate parents as informants: Communicative Development Inventory (CDI) adaptation for two Kenyan languages. Journal of Child Language, 42, 763-785. Dataset name: Alcock Instrument: WS Contributor: Katie Alcock, Lancaster University Citation: Alcock, K., Rimba, K., Holding, P., Kitsao-Wekulo, P., Abubakar, A., Newton, C.R.J.C. (2015) Developmental inventories using illiterate parents as informants: Communicative Development Inventory (CDI) adaptation for two Kenyan languages. Journal of Child Language, 42, 763-785. Mandarin (Beijing) Dataset name: Li Instrument: IC Contributor: Ping Li, Pennsylvania State University Citation: Hao, M., Shu, H., Xing, A., &amp; Li, P. (2008). Early vocabulary inventory for Mandarin Chinese. Behavior Research Methods, 40, 728-733. Czech Dataset name: Smolik Instrument: WS Contributor: Filip Smolik, Academy of Sciences of the Czech Republic Citation: Markova, G., Smolík, F. (2014). What Do You Think? The Relationship between Person Reference and Communication About the Mind in Toddlers. Social Development, 23, 61-79. DOI: 10.1111/sode.12044 English (Australian) Dataset name: Kalashnikova Instrument: WS Contributor: Marina Kalashnikova, MARCS Institute for Brain, Behaviour and Development Citation: Kalashnikova, M., Schwarz, I.-C., &amp; Burnham, D. (2016). OZI: Australian English Communicative Development. First Language, 36, 407-427. English (British) Dataset name: Floccia Instrument: Oxford CDI Contributor: Caroline Floccia, Plymouth University Citation: Floccia, C. (2017). Data collected with the Oxford CDI over a course of 5 years in Plymouth Babylab, UK. With the permission of Plunkett, K. and the Oxford CDI from Hamilton, A., Plunkett, K., &amp; Schafer, G., (2000). Infant vocabulary development assessed with a British Communicative Development Inventory: Lower scores in the UK than the USA. Journal of Child Language, 27, 689-705. Dataset name: Floccia Instrument: Oxford CDI Contributor: Caroline Floccia, Plymouth University Citation: Floccia, C. (2017). Data collected with the Oxford CDI over a course of 5 years in Plymouth Babylab, UK. With the permission of Plunkett, K. and the Oxford CDI from Hamilton, A., Plunkett, K., &amp; Schafer, G., (2000). Infant vocabulary development assessed with a British Communicative Development Inventory: Lower scores in the UK than the USA. Journal of Child Language, 27, 689-705. Latvian Dataset name: Urek Instrument: WG Contributor: Olga Urek, The Arctic University of Norway Citation: Urek, Olga, Anna Vulāne, Roberts Darģis, Agrita Tauriņa, Tija Zīriņa, Hanne Gram Simonsen (to appear) Latvian CDI: methodology, developmental trends and cross-linguistic comparison. Dataset name: Urek Instrument: WS Contributor: Olga Urek, The Arctic University of Norway Citation: Urek, Olga, Anna Vulāne, Roberts Darģis, Agrita Tauriņa, Tija Zīriņa, Hanne Gram Simonsen (to appear) Latvian CDI: methodology, developmental trends and cross-linguistic comparison. Korean Dataset name: Yim Instrument: WG Contributor: Dongsun Yim, Ewha Womans University Citation: Dataset name: Yim Instrument: WS Contributor: Dongsun Yim, Ewha Womans University Citation: English (American) Dataset name: Marchman Instrument: WS Contributor: Anne Fernald, Stanford University Citation: Fernald, A., Marchman, V. A., &amp; Weisleder, A. (2013). SES differences in language processing skill and vocabulary are evident at 18 months. Developmental Science, 16, 234–248. http://doi.org/10.1111/desc.12019 Spanish (Mexican) Dataset name: Fernald Instrument: WG Contributor: Anne Fernald, Stanford University Citation: Weisleder, A., &amp; Fernald, A. (2013). Talking to children matters: Early language experience strengthens processing and builds vocabulary. Psychological Science, 24, 2143–2152. http://doi.org/10.1177/0956797613488145 Dataset name: Fernald Instrument: WS Contributor: Anne Fernald, Stanford University Citation: Weisleder, A., &amp; Fernald, A. (2013). Talking to children matters: Early language experience strengthens processing and builds vocabulary. Psychological Science, 24, 2143–2152. http://doi.org/10.1177/0956797613488145 Korean Dataset name: Pae Instrument: WS Contributor: Soyeong Pae, Hallym University Citation: Pae, S., &amp; Kwak, K. (2011). Korean MacArthur-Bates Communicative Development Inventories (K M-B CDI). Seoul: Mindpress. Dataset name: Pae Instrument: WG Contributor: Soyeong Pae, Hallym University Citation: Pae, S., &amp; Kwak, K. (2011). Korean MacArthur-Bates Communicative Development Inventories (K M-B CDI). Seoul: Mindpress. French (French) Dataset name: Bergmann Instrument: WG Contributor: Christina Bergmann (Max Planck Institute for Psycholinguistics), Anne-Caroline Fievet (Laboratoire de Sciences Cognitives et Psycholinguistique (ENS, EHESS, CNRS), Département d’Etudes Cognitives, Ecole Normale Supérieure, PSL Research University) Citation: Dataset name: VonHolzen Instrument: WG Contributor: Katie Von Holzen, University of Maryland Citation: Von Holzen, K., Nishibayashi, L.-L., &amp; Nazzi, T. (2018). Consonant and vowel processing in word form segmentation : An infant ERP study. Brain Sciences, 8(24), 1–15. doi: 10.3390/brainsci8020024. Dataset name: VonHolzen Instrument: WS Contributor: Katie Von Holzen, University of Maryland Citation: Von Holzen, K., Nishibayashi, L.-L., &amp; Nazzi, T. (2018). Consonant and vowel processing in word form segmentation : An infant ERP study. Brain Sciences, 8(24), 1–15. doi: 10.3390/brainsci8020024. Portuguese (European) Dataset name: Cadime Instrument: WG Contributor: Irene Cadime, University of Minho Citation: Dataset name: Cadime Instrument: WS Contributor: Irene Cadime, University of Minho Citation: Spanish (European) Dataset name: Karousou Instrument: WG Contributor: Alexandra Karousou, Democritus University of Thrace Citation: López Ornat, S., Gallego, C., Gallo, P., Karousou, A., Mariscal, S., &amp; Martínez, M. (2005). MacArthur: Inventario de desarrollo comunicativo. Manual y Cuadernillos. Madrid, TEA Ediciones. ISBN: 84-7174- 820-7 Dataset name: Karousou Instrument: WS Contributor: Alexandra Karousou, Democritus University of Thrace Citation: López Ornat, S., Gallego, C., Gallo, P., Karousou, A., Mariscal, S., &amp; Martínez, M. (2005). MacArthur: Inventario de desarrollo comunicativo. Manual y Cuadernillos. Madrid, TEA Ediciones. ISBN: 84-7174- 820-7 French (French) Dataset name: Kern Instrument: WS Contributor: Sophie Kern, Centre national de la recherche scientifique (CNRS) Citation: Mandarin (Taiwanese) Dataset name: Liu Instrument: WG Contributor: Huei-Mei Liu, National Taiwan Normal University Citation: Liu, H. M., &amp; Tsao, F. M. (2010). The standardization and application of Mandarin-Chinese communicative developmental inventory for infants and toddlers. Formosa Journal of Mental Health, (4)23, 503-534. doi: 10.30074/CJMH.201012.0001 Liu, H. M., &amp; Chen, Y. (2015). Developmental changes in the content and composition of early expressive vocabulary in Mandarin-speaking infants and toddlers. Bulletin of Educational Psychology, 24(7), 217-242. doi: 10.6251/BEP.20150205 Dataset name: Liu Instrument: WS Contributor: Huei-Mei Liu, National Taiwan Normal University Citation: Liu, H. M., &amp; Tsao, F. M. (2010). The standardization and application of Mandarin-Chinese communicative developmental inventory for infants and toddlers. Formosa Journal of Mental Health, (4)23, 503-534. doi: 10.30074/CJMH.201012.0001 Liu, H. M., &amp; Chen, Y. (2015). Developmental changes in the content and composition of early expressive vocabulary in Mandarin-speaking infants and toddlers. Bulletin of Educational Psychology, 24(7), 217-242. doi: 10.6251/BEP.20150205 "],
["appendix-variability.html", "B Measures of Variability", " B Measures of Variability In Chapter 5, we make use of non-parametric measures of variability. MADM and MMAD rather than the more standard coefficient of variation and Cohen’s \\(d\\). In this brief Appendix, we show that these are very similar in the limit with a large amount of data, although they can produce quite different answers for individual data points, especially those that are at the floor or ceiling of the particular form. Our first analysis plots Coefficient of Variation (CV) vs. MADM, with each point representing a single age group for a particular combination of form and language. The slope of the relationshup between the two measures is 1, despite some considerable variation. Overall, it appears that for the majority of the data, CV is slightly lower than MADM, but that it goes dramatically higher for some individual datasets. We speculate that this is due to floor/ceiling effect and small sample effects. Overall, this analysis suggests that MADM, the non-parametric estimate we use, is less subject to extreme flunctions than CV. Our second analysis is identical except that it plots Cohen’s \\(d\\) by MMAD. Each of these is the reciprocal of the related measure plotted above. (For example, \\(d = \\frac{\\mu}{\\sigma}\\) whereas \\(CV = \\frac{\\sigma}{\\mu}\\)). Thus, the same relation holds. "],
["appendix-stitching.html", "C Stitching Across Forms C.1 Item Stitching C.2 Form Stitching C.3 Item-Level Form Stitching", " C Stitching Across Forms Because we use different forms for different ages, there are sometimes good reasons to combine data across forms to get a broader range of ages in a particular analysis. We call this combination “stitching.” This appendix provides some motivation for the practice. C.1 Item Stitching For arbitrary items, stitching across English WS and WG tends to look pretty good. C.2 Form Stitching We can “stitch” across WS and WG forms to get a fuller picture of production across ages. There are several ways to accomplish this. The simplest is to use proportions for each form. This isn’t particularly good. You can also stitch item by item, this is trickier but better. C.3 Item-Level Form Stitching "],
["appendix-aoa.html", "D Estimating Age of Acquisition D.1 Empirical quantiles D.2 Basic GLM D.3 Robust GLM D.4 Bayes GLM D.5 Hierarchical GLM model D.6 Full comparison between models D.7 Sparsity simulations", " D Estimating Age of Acquisition In this Appendix, we systematically compare methods for estimating age of acquisition, using the English Words and Sentences data as a case study. All the AOA curves. Let’s compare methods. D.1 Empirical quantiles First try empirical quantiles. This loses many observations that never go above 50%. D.2 Basic GLM Now let’s try the basic GLM version. Compare. The GLM AOA gives some very early values, but it is OK with a lot of data (as in the case of English). D.3 Robust GLM Looks totally reasonable except for the two crazy ones. #&gt; [1] &quot;daddy*&quot; &quot;mommy*&quot; D.4 Bayes GLM Can we do a arm::bayesglm to regularize things a bit? Let’s explore a single curve. Basically, arm::bayesglm does exactly the same thing as GLM because of the huge amount of data, no matter what prior. Let’s try also robust GLM. Now apply this more broadly. Note that the 50% point for logistic regression = \\(- \\beta_1 / \\beta_2\\). arm::bayesglm is working very well here, basically moving Mommy and Daddy a bit more conservative but otherwise preserving most of the curve. arm::bayesglm with these made-up parameters fixes some of the issues, produces a better-looking distribution with fewer crazy outliers. D.5 Hierarchical GLM model Set some stan settings. The model. Constraints: No negative slopes - we don’t get worse at words. Strong prior on slopes, they should have mean and sd around .25 (empirical) Much weaker prior on intercepts, though yoked their SDs (perhaps too tightly? Now reformat the data to stan format and compute. Diagnostics. Explore parameters. and plot again: Check the histogram. What are the crazy ones? Don’t know what’s going on with these but everything else looks good. D.6 Full comparison between models Merge with previous data frame. AOA distribution Plot. And pairs plots. D.7 Sparsity simulations BGLM with fairly restricted priors appeared to perform well, giving us reasonably constrained estimates for early words and otherwise being very correlated with glm and the more computation-heavy hglm. One consideration remains: does it perform well with very sparse data? Examples of this process with 100 children actually look much stronger overall. ## Conclusion arm::bayesglm with hand-tuned priors seems to perform pretty well. To Do: * Test with WG comprehension * Test with another language "],
["appendix-vocabulary.html", "E Estimating Total Vocabulary E.1 Further thoughts on Mayor &amp; Plunkett model", " E Estimating Total Vocabulary First, connect to the Wordbank database and pull out the English WS and WG data. Now aggregate by item. Now arrange. Plot this with a glm sinusoid like in the Mayor &amp; Plunkett (2011) paper. Try a polynomial fit. Doesn’t work that well for the younger ages, though looks fine later. Note age interactions in the stats. #&gt; #&gt; Call: #&gt; glm(formula = produces ~ index * age, family = &quot;binomial&quot;, data = ordered) #&gt; #&gt; Deviance Residuals: #&gt; Min 1Q Median 3Q Max #&gt; -0.50672 -0.09538 -0.01262 0.07183 1.16279 #&gt; #&gt; Coefficients: #&gt; Estimate Std. Error z value Pr(&gt;|z|) #&gt; (Intercept) -4.688e+00 2.839e-01 -16.514 &lt; 2e-16 *** #&gt; index -7.773e-03 8.480e-04 -9.166 &lt; 2e-16 *** #&gt; age 2.639e-01 1.252e-02 21.089 &lt; 2e-16 *** #&gt; index:age 9.147e-05 3.489e-05 2.622 0.00875 ** #&gt; --- #&gt; Signif. codes: 0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1 #&gt; #&gt; (Dispersion parameter for binomial family taken to be 1) #&gt; #&gt; Null deviance: 4141.07 on 10199 degrees of freedom #&gt; Residual deviance: 174.34 on 10196 degrees of freedom #&gt; AIC: 5981 #&gt; #&gt; Number of Fisher Scoring iterations: 5 E.1 Further thoughts on Mayor &amp; Plunkett model The Mayor &amp; Plunkett (2011) model has two corrections. The first uses the parametric form of the logistic to fill in low-frequency words that are not on the CDI, the second uses the difference between diary study counts and CDI counts to find a multiplier for higher-frequency words that are omitted. I think there’s a bit of a conceptual issue here, as these two corrections should essentially be the same thing - there are some words that are not on the CDI, and more of these are the low frequency/hard words. So really, it all is a correction for missing words. Also - the first correction, which depends on the parametric form of the logistic, is much much smaller than the second. Take a look at this. Equation 3: \\[ p(w_i) = 1 - \\frac{1}{1 + e^{\\frac{-(i-a)}{b}}} \\] So adding the gray area gives us \\[ V_{corr_1} = b \\log (1 + e^(a / b)) \\] but then adding the second correction is just a multiplier on this: \\[ V_{corr_2} = \\alpha * V_{corr_1} \\] Note that (strikingly), M&amp;P2011 never give their value of \\(\\alpha\\) in the text. I estimate it below so that I can make an estimate of what correction 2 actually looks like… So you can see that the second correction dwarfs the first correction in size, and is really based on a few small diary studies. In sum, I’m worried about this model for a few reasons: The distributional form (logit) is clearly not correct, so using this distributional form for extrapolation may have bad consequences. The first and second corrections aren’t conceptually distinct: they both concern missing words. Both have to do with the sampling of words on the CDI from the broader vocabulary. The second correction, which does most of the work, is - for reasonable reasons of data etc.- assumed to be a strict multiplier, which makes it do a ton of work at the higher end of vocabulary. "],
["references.html", "References", " References "]
]
