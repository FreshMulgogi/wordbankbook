[
["conclusion-beyond-cdi.html", "Chapter 17 Beyond the CDI 17.1 Limitations of the CDI 17.2 What comes next? 17.3 Methodological morals", " Chapter 17 Beyond the CDI Throughout this manuscript we have attempted to gain the broadest possible understanding of children’s language learning by engaging deeply with data from the CDI family of instruments. We hope that readers agree that this exercise has been very fruitful in uncovering a variety of patterns in the data that can inform our understanding of the language learning problem. But it has also uncovered a wide variety of limitations to the CDI, which in turn limit the issues that we can comment on. In this chapter, we discuss these limitations and turn to the question of how language acquisition research can move beyond the CDI. We end by discussing some methodological morals from this work for psychology more broadly, engaging with issues of reproducibility and replicability. 17.1 Limitations of the CDI Following the metaphor we introduced in Chapter 1, the CDI is a “macro-economic” indicator. It tells us about the global profile of a child’s linguistic abilities, rather than revealing the local “micro-economic” dynamics of how individual words are represented. The local dynamics of children’s learning, pragmatic use, and comprehension in the moment have all been important targets for empirical imnvestigation (e.g., Clark 1988; Fernald et al. 1998; Smith and Yu 2008). But at best a CDI can reveals some emergent average of these processes over time, much the same way the gross domestic product of a nation must reveal the sum of all the contributing markets. The use of parents to provide a global picture of the child’s entire language system – from gestures to vocabulary and grammar – is also a weakness when it comes to addressing detailed questions about specific words. Because parents are not linguists, they cannot be profitably asked the kinds of targeted questions that might shed light on other theoretical questions. For example, a tremendous amount of research has investigated the development of children’s phonological system [REFS]. Research with the CDI must remain silent on this topic because we instruct parents to check “says” if the child produces any appropriate phonological form. Similarly, an important target for research on vocabulary learning is the type of semantic generalizations that children make, including whether words are initially over- or under-generalized (e.g., ???…) and how their appropriate extension is found (e.g., Markman 1990; Xu and Tenenbaum 2007). We hope that, on average, parents can detect appropriate comprehension of words in specific context and appropriate production as well. But these individual uses reveal relatively little about the nature of the semantic representations underlying the word – even for concrete objects but especially for descriptive or closed-class words. A clear example of this phenomenon appears in Chapter 11. We see that time words are under-represented in children’s vocabulary; but they are still present. Yet, according to Tillman and Barner (Tillman and Barner 2015; Tillman et al. 2017), 2.5-year-olds probably have incorrect or incomplete semantics for essentially all of these words. They still utter the words in appropriate contexts. But if the semantics were probed more carefully, gaps with adult-like representations would become readily apparent. 17.2 What comes next? Beyond these limitations, the CDI is not the appropriate tool for every queston the CDI has limitations that we’ve discussed - and it’s also overkill for some research we think that “new journaling” - e.g. wordful, speechome, seedlings - has a lot of potential but the promise of “bigger data” psychology is bigger than the CDI - and the approach to consistency and variability is more general as well 17.2.1 Web-based assessment 17.2.2 Adaptive approaches 17.2.3 App-based approaches 17.3 Methodological morals As we noted in Chapter 1, psychology has recently been plagued by concerns about reproducibility (e.g., Hardwicke et al. 2018) and replicability (e.g., Open Science Collaboration 2015). Our work here was inspired by considering these issues and their impact on the field of language development. The ultimate goal of research in this area is to create a quantitative theory that allows for precise predictions and principled explanations of developmental phenomena. Such a theory cannot be built on a series of non-reproducible findings and binary conclusions (Frank et al. 2017). Wordbank is a reply to this situation: by compiling the extant CDI datasets into a single open database, researchers can reproduce previous and new research conclusions that use these data. The analyses we report here using the Wordbank data are computationally reproducible through the availability of the code necessary to build the book and all its figures and analyses. In addition, by seeking a level of scale beyond previous efforts, we have attempted to avoid the variability inherent in “small-N” studies. Further, our work is built on the notion of replication. Nearly every one of the preceding substantive chapters is in some sense a “replication” of previous work – an analysis was taken from previous work with a particular CDI dataset and applied (sometimes with technical modifications) to other data. Yet the result is not a judgement on the original; we do not declare a binary success or failure of the replication attempt. Instead, we are interested in the degree to which a particular quantitative estimate varies across languages and cultures. This sort of analysis is superficially similar to the idea of “hidden moderators” that has plagued the replication debate (Van Bavel et al. 2016). But, this effort has largely been an effort to contextualize failures to replicate particular experimental effects by invoking unknown sources of variability across contexts. In contrast, our efforts here allow us to quantify variation across “replications” of the same effect and use these estimates as the signal – rather than an un-measured source of noise. One notable feature of our analytic strategy is that we try to rely very little on binary decision-theoretic inferences using null hypothesis significance testing. There are a handful p-values in occasional analyses, but few of these appear in any prominent inferential conclusion. Instead, our goal has been to measure quantities of interest with high precision, looking for statistical estimates that relate to particular theoretical goals. For example, the existence of a noun bias is a fascinating observation, but this observation gives limited leverage to differentiate theories. The magnitude of a noun bias provides more leverage for quantitative theorizing. And the distribution of magnitudes across many of the world’s languages gives greater leverage still. Our hope is that, by generalizing and applying many influential analyses by many contributors, our work here can affect theory more broadly. "]
]
