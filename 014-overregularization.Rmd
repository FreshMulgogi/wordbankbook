# Morphological Overgeneralization {#overregularization}

Although Chapter \@ref(grammar) examined broad patterns of morphological development (along with grammatical development), we did not conduct any specific analyses of morphological development. In this brief chapter, we rectify that omission by examining patterns of generalization and overgeneralization. We focus on this phenomenon because morphological generalization has been an influential case study for language learning -- and mental representation more broadly [@rumelhart1996;@pinker1990]. We begin by describing cross-sectional patterns of overgeneralization across languages and then turn to characterizing longitudinal change in overgeneralization in English and Norwegian. 

## Introduction and methods

```{r overreg-data, eval=FALSE}
grammar_items <- read_csv("data/overregularization/overreg_item_coding.csv")
overreg_items <- grammar_items %>%
  filter(group == "overregularized") %>%
  select(language, form, item_id, num_item_id, type, definition, lexical_category, stem)

get_overreg_data <- function(lang, lang_items) {
  print(lang)
  lang_admins <- admins %>% filter(language == lang, form == "WS")
  lang_data <- get_instrument_data(language = lang,
                                   form = "WS",
                                   items = lang_items$item_id,
                                   iteminfo = lang_items,
                                   administrations = lang_admins)
  
  lang_data %>%
    mutate(produces = !is.na(value) & value == "produces") %>%
    select(language, item_id, type, definition, 
           data_id, original_id, longitudinal, age, production, produces)
}

overreg_data <- overreg_items %>%
  mutate(lang = language) %>%
  nest(items = -lang) %>%
  mutate(data = map2(lang, items, get_overreg_data))

overreg_data_items <- overreg_data %>%
  select(-items) %>%
  unnest(cols = c(data)) %>%
  select(-lang) %>%
  left_join(overreg_items)

feather::write_feather(overreg_data_items, "data/overregularization/_overreg_data_items.feather")
```

```{r overreg-by_kid, eval=FALSE}
overreg_data_items <- feather::read_feather("data/overregularization/_overreg_data_items.feather")

form_words <- items %>%
  filter(form == "WS", type == "word") %>%
  group_by(language) %>%
  summarise(num_words = n())

overreg_by_kid <- overreg_data_items %>%
  group_by(language, type, lexical_category,
           data_id, original_id, longitudinal, age, production) %>%
  summarise(total = n(), num_true = sum(produces),
            num_false = total - num_true, prop = num_true / total) %>%
  ungroup() %>%
  left_join(form_words) %>%
  mutate(production_prop = production / num_words,
         lexical_category = as_factor(lexical_category))

feather::write_feather(overreg_by_kid, "data/overregularization/overreg_by_kid.feather")
```

```{r overreg-fits, dependson="overreg-by_kid"}
overreg_by_kid <- feather::read_feather("data/overregularization/overreg_by_kid.feather")
overreg_by_kid_nonzero <- overreg_by_kid %>% filter(prop != 0)

vocab_model <- function(inst_data) {
  lm(prop ~ I(production_prop ^ 4) + I(production_prop ^ 3) +
       I(production_prop ^ 2) + production_prop + 0, data = inst_data)
}

vocab_models <- overreg_by_kid_nonzero %>%
  group_by(language, lexical_category) %>%
  nest() %>%
  mutate(
    model = map(data, vocab_model),
    rsq = map_dbl(model, ~summary(.x)$adj.r.squared),
    rsq_print = glue("r² = {roundp(rsq)}")
    # rsq_print = glue("italic(r)^2 == {sprintf('%.2f', round(rsq, 2))}")
  )

vocab_step <- 0.01
vocabs <- tibble(production_prop = seq(0, 1, vocab_step))
vocab_fits <- vocab_models %>%
  mutate(fits = map(model, ~broom::augment(., newdata = vocabs))) %>%
  select(-data, -model) %>%
  unnest(cols = c(fits))


age_model <- function(inst_data) {
  lm(prop ~ I(age ^ 4) + I(age ^ 3) +
       I(age ^ 2) + age, data = inst_data)
}

age_models <- overreg_by_kid_nonzero %>%
  nest(data = c(-language, -lexical_category)) %>%
  mutate(
    model = map(data, age_model),
    rsq = map_dbl(model, ~summary(.x)$adj.r.squared),
    # rsq_print = glue("r² = {sprintf('%.2f', round(rsq, 2))}")
    rsq_print = glue("r² = {roundp(rsq)}")
  )
ages <- overreg_by_kid_nonzero %>%
  distinct(language, lexical_category, age) %>%
  nest(data = age)
age_fits <- age_models %>%
  select(-data) %>%
  left_join(ages) %>%
  mutate(fits = map2(model, data, ~broom::augment(.x, newdata = .y))) %>%
  select(-data, -model) %>%
  unnest(cols = c(fits))
```

Why morphological generalization, from an acquisition perspective (e.g., some languages have a lot more morphology than English - and even some have more morpho than grammar) 

Also theory (e.g., rules/connections) - morpho has become a case study for mental representation more broadly. But it's an open question whether this is right - morphology could be "special" (cf. some of the recent songbird stuff)

Turning to data. Descriptive studies of overregularization in child language - marcus, marchman

More recent work?

Our approach here depends on the fact that the original developers of the CDI were interested in this debate and included overregularizations as options in the morphological sections of the form. For example, an item like *foot* includes *foots* and *feet* as possible options to be checked. To take advantage of this, we coded overgeneralizations on each of the `r length(unique(overreg_by_kid$language))` WS-type forms for which we had access to data from these items (two from English dialects). We then used this coding to count the total proportion overregularizations by child, both overall and within noun and verb categories. We show analyses of these overregularizations for cross-sectional and longitudinal data below. 


## Cross-sectional data

```{r overreg-table, dependson="overreg-fits"}
overreg_by_kid %>%
  group_by(language, lexical_category) %>%
  summarise(mean = mean(prop),
            n = n()) %>%
  spread(lexical_category, mean) %>%
  rename(Language = language, 
         `Prop. noun overreg.` = nouns, 
         `Prop. verb overreg.` = verbs, 
         N = n) %>%
  kable(digits = 2,
        caption = "Proportion of noun and verb overregularization across languages.")
```

We begin by describing overregularization within the cross-sectional data. The proportion of overregularizations reported is not high overall. Slovak shows the highest rate, and it is still barely above 10% of total reports for these items. Thus, over-regularization is rare in a cross-sectional sample. Figure \@ref(fig:overreg-fits-age) shows each child's proportion of overregularized items plotted by age. The major generalization from these data is that curves tend to be surprisingly flat -- there are not large, consistent developmental increases for any language. The inset $r^2$ for each panel in this graph show the variance explained by quadratic models of overregularization by age, quantitatively confirming the visual impression of limited developmental change.  

```{r overreg-fits-age, fig.width=8, fig.height=3.5, fig.cap="Each child's proportion of items overregularized as a function of their age size in each language (curves show model fits).", dependson="overreg-fits"}
# age_ranges <- overreg_by_kid_nonzero %>%
#   group_by(language) %>%
#   summarise(range = max(age) - min(age))
ggplot(overreg_by_kid_nonzero, aes(x = age, y = prop)) +
  facet_grid(lexical_category ~ language, labeller = label_caps) + #, scales = "free_x") +
  coord_fixed(ratio = 21) +
  geom_jitter(alpha = 0.2, size = 0.75, shape = 1) +
  geom_line(aes(y = .fitted), size = 1.2, colour = .pal()(1),
            data = age_fits) +
  geom_text(aes(label = rsq_print), x = 15.1, y = 0.95, size = 3, hjust = 0,
            family = .font, #parse = TRUE,
            data = age_models) +
  scale_x_continuous(limits = c(16, 36),
                     breaks = seq(16, 36, by = 4),
                     name = "Age (months)") +
  scale_y_continuous(limits = c(0, 1), expand = c(0.01, 0),
                     breaks = c(0, 0.5, 1), labels = c(0, 0.5, 1),
                     name = "Proportion of items overregularized")
```

```{r overreg-fits-vocab, fig.width=8, fig.height=3.5, fig.cap="Each child's proportion of overregularization as a function of their vocabulary size in each language (curves show model fits).", dependson="overreg-fits"}
ggplot(overreg_by_kid_nonzero, aes(x = production_prop, y = prop)) +
  facet_grid(lexical_category ~ language, labeller = label_caps) +
  coord_fixed() +
  geom_jitter(alpha = 0.2, size = 0.75, shape = 1) +
  geom_line(aes(y = .fitted), size = 1.2, colour = .pal()(1),
            data = vocab_fits) +
  geom_text(aes(label = rsq_print), x = 0.05, y = 0.95, size = 3, hjust = 0,
            family = .font, #parse = TRUE,
            data = vocab_models) +
  scale_x_continuous(limits = c(0, 1), expand = c(0.01, 0),
                     breaks = c(0, 0.5, 1), labels = c(0, 0.5, 1),
                     name = "Productive vocabulary size (proportion of items)") +
  scale_y_continuous(limits = c(0, 1), expand = c(0.01, 0),
                     breaks = c(0, 0.5, 1), labels = c(0, 0.5, 1),
                     name = glue("Proportion of items overregularized"))
```

Interestingly, the same finding holds true for vocabulary. Overregularization does not appear to be tightly predicted by overall vocabulary size. Figure \@ref(fig:overreg-fits-vocab) shows findings from this analysis. While some slopes might be slightly higher (especially for verbs), overall the total developmental change predicted by vocabulary size seems limited. What predicts reports of overregularization then? 


```{r overreg-lexcat-comp, fig.width=8, fig.height=2.25, fig.cap="Each child's proportion of verbs overregularized against proportion of nouns overregularized (lines show linear model fits)."}
overreg_lexcat_comp <- overreg_by_kid %>%
  select(language, lexical_category, data_id, prop, age) %>%
  group_by(data_id) %>%
  # filter(!all(prop == 0)) %>%
  spread(lexical_category, prop)

lexcat_cors <- overreg_lexcat_comp %>%
  group_by(language) %>%
  summarise(rsq = cor(nouns, verbs) ^ 2,
            rsq_print = glue("r² = {roundp(rsq)}"))

ggplot(overreg_lexcat_comp, aes(x = nouns, y = verbs)) +
  facet_wrap(~language, nrow = 1) + #, scales = "free") +
  coord_fixed() +
  geom_jitter(position = position_jitter(width = 0.02, height = 0.02),
              colour = .grey, size = 0.9) +
  geom_smooth(method = "lm", se = FALSE, colour = .pal()(1)) +
  geom_text(aes(label = rsq_print), x = 0.05, y = 0.95, size = 3, hjust = 0,
            family = .font, data = lexcat_cors) + #parse = TRUE,
  scale_x_continuous(limits = c(0, 1), expand = c(0.01, 0),
                     breaks = c(0, 0.5, 1), labels = c(0, 0.5, 1),
                     name = "Proportion of nouns overregularized") +
  scale_y_continuous(limits = c(0, 1), expand = c(0.01, 0),
                     breaks = c(0, 0.5, 1), labels = c(0, 0.5, 1),
                     name = "Proportion of verbs\n overregularized")
```

One positive finding from our exploration is shown in Figure \@ref(fig:overreg-lexcat-comp). The majority of children do not overregularize, but those who do are doing so across nouns and verbs quite consistently, across all of the languages in our sample. *r*² values for the relationship between noun and verb over-regularizations range from `r roundp(min(lexcat_cors$rsq))` to `r roundp(max(lexcat_cors$rsq))`, considerably higher than the relationships documented above. Thus, at a minimum we see within-individual stability in this measure. But we do not yet have a good way of predicting when particular children will show non-zero overregularization.

## Longitudinal data

As in other chapters, we make use of the longitudinal data from the English (American) and Norwegian datasets. These data allow us to examine changes in generalization across individuals. Since data are sparser in the English data than the Norwegian, we pursue slightly different approaches to understanding these data. 

### English

For the English data, our analysis examines developmental changes within children. Figure \@ref(fig:overreg-eng-longs) shows developmental change for children with pairs of observations. 

```{r overreg-eng-longs}
overreg_longs <- overreg_by_kid %>%
  left_join(admins %>% select(data_id, source_name)) %>%
  group_by(language, lexical_category, source_name, original_id) %>%
  mutate(num_admins = n()) %>%
  filter(num_admins > 1)

eng_longs <- overreg_longs %>%
  ungroup() %>%
  filter(language == "English (American)") %>%
  group_by(lexical_category, original_id) %>%
  filter(!all(prop == 0)) %>%
  group_by(lexical_category, original_id) %>%
  mutate(num_ages = n_distinct(age))

# eng_ns <- eng_longs %>%
#   ungroup() %>%
#   distinct(lexical_category, original_id, num_ages) %>%
#   count(lexical_category, num_ages) %>%
#   group_by(lexical_category) %>%
#   arrange(lexical_category, desc(num_ages)) %>%
#   mutate(p = n / sum(n),
#          cum_p = cumsum(p))

eng_long_cats <- eng_longs %>%
  filter(num_ages > 2) %>%
  mutate(age_code = case_when(age == min(age) ~ "youngest",
                              age == max(age) ~ "oldest",
                              TRUE ~ "middle")) %>%
  group_by(lexical_category, original_id, age_code) %>%
  summarise(age = mean(age), prop = mean(prop), n = n()) %>%
  select(-age, -n) %>%
  spread(age_code, prop) %>%
  mutate(step_1 = case_when(middle > youngest ~ "increases",
                                     middle == youngest ~ "stays",
                                     TRUE ~ "decreases"),
         step_2 = case_when(oldest > middle ~ "increases",
                                   oldest == middle ~ "stays",
                                   TRUE ~ "decreases"),
         trajectory = case_when(
           step_1 == "stays" & step_2 == "stays" ~ "–",
           step_1 %in% c("stays", "increases") & step_2 %in% c("stays", "increases") ~ "/",
           step_1 %in% c("stays", "decreases") & step_2 %in% c("stays", "decreases") ~ "\\",
           step_1 == "increases" & step_2 == "decreases" ~ "Λ",
           step_1 == "decreases" & step_2 == "increases" ~ "V",
           TRUE ~ "other"
         )) %>%
  ungroup() %>%
  mutate(trajectory = fct_infreq(trajectory))

eng_long_cat_props <- eng_long_cats %>%
  count(lexical_category, trajectory) %>%
  group_by(lexical_category) %>%
  mutate(label = sprintf("N = %s (%.0f%%)", n, n / sum(n) * 100))

eng_long_grouped <- eng_longs %>%
  right_join(eng_long_cats %>% select(lexical_category, original_id, trajectory)) %>%
  select(lexical_category, original_id, age, prop, trajectory)

eng_long_comp <- eng_long_grouped %>%
  # filter(trajectory %in% c("/", "Λ")) %>%
  pivot_wider(names_from = lexical_category, values_from = c(prop, trajectory)) %>%
  filter(!is.na(prop_nouns), !is.na(prop_verbs)) %>%
  group_by(trajectory_nouns) %>%
  count(trajectory_verbs) %>%
  mutate(p = n / sum(n))
```

```{r overreg-eng-longs-plot, fig.width=8, fig.height=4.5}
ggplot(eng_long_grouped, aes(x = age, y = prop)) +
  facet_grid(lexical_category ~ trajectory, labeller = label_caps, switch = "y") +
  geom_line(aes(colour = original_id), alpha = .3) +
  geom_text(aes(label = label), family = .font, hjust = 0, vjust = 1, size = 3,
            x = min(eng_long_grouped$age), y = max(eng_long_grouped$prop),
            data = eng_long_cat_props) +
  .scale_colour_numerous(guide = FALSE) +
  labs(x = "Age (months)", y = glue("Proportion of items overregularized")) +
  scale_x_continuous(breaks = seq(18, 30, 3)) +
  theme(strip.placement = "outside")
```


### Norwegian

Because longitudinal data are so much more plentiful in the Norwegian dataset, we are able to map proportions within individual children. Figure \@ref(overreg-nor-longs-age) shows smoothed curves for those children with at least XYZ administrations. As in the cross-sectional data, we see noun and verb over-regularization traveling together developmentally. Further, we see that the moment that over-regularization is reported seems to vary substantially by child. Some children are continuing to increase their overregularization throughout the sampling period, while others go through a discrete phase (at least for the high-frequency items shown on the form) and then return to zero by the end of the sampling period at age 3. Others barely over-regularize in this period. Thus, at a minimum we can conclude there is truly substantial individual variation in overregularization. 

```{r overreg-nor-longs}
nor_longs <- overreg_longs %>%
  ungroup() %>%
  filter(language == "Norwegian") %>%
  group_by(original_id, lexical_category) %>%
  filter(!all(prop == 0)) %>%
  group_by(lexical_category, original_id) %>%
  mutate(num_ages = n_distinct(age))
```

```{r overreg-nor_models, eval=FALSE}
model_min <- 4
nor_models <- nor_longs %>%
  filter(num_ages >= model_min) %>%
  select(original_id, data_id, lexical_category, age, num_true, num_false, prop, total) %>%
  nest(data = c(-lexical_category, -original_id)) %>%
  mutate(
    null = map(data, function(df) {
      glm(prop ~ 1, weights = total, family = "binomial", data = df)
    }),
    linear = map(data, function(df) {
      glm(prop ~ age, weights = total, family = "binomial", data = df)
    }),
    quadratic = map(data, function(df) {
      glm(prop ~ age + I(age^2), weights = total, family = "binomial", data = df)
    })
  )

nor_models <- nor_models %>%
  ungroup() %>%
  select(-data) %>%
  gather(model_type, model, -original_id, -lexical_category)

nor_aic <- nor_models %>%
  mutate(aic = map_dbl(model, AIC)) %>%
  select(-model) %>%
  filter(model_type != "null")

nor_rsq <- nor_models %>%
  mutate(loglik = map_dbl(model, logLik),
         n = map_dbl(model, ~length(.$fitted.values))) %>%
  select(-model) %>%
  spread(model_type, loglik) %>%
  gather(model_type, loglik, linear, quadratic) %>%
  rename(loglik_null = null) %>%
  mutate(rsq = 1 - (loglik / loglik_null)) %>%
  select(-loglik_null, -loglik) 

nor_model_comp <- left_join(nor_aic, nor_rsq) %>%
  pivot_wider(names_from = model_type, values_from = c(aic, n, rsq)) %>%
  mutate(winner = if_else(aic_quadratic < aic_linear, "quadratic", "linear")) %>%
  pivot_longer(cols = c(contains("linear"), contains("quadratic")),
               names_to = c("measure", "model_type"), names_sep = "_",
               values_to = "value") %>%
  pivot_wider(names_from = measure, values_from = value)
feather::write_feather(nor_model_comp, "data/overregularization/nor_model_comp.feather")

nor_coefs <- nor_models %>%
  ungroup() %>%
  filter(model_type != "null") %>%
  mutate(coefs = map(model, broom::tidy)) %>%
  select(-model) %>%
  unnest(cols = coefs)
feather::write_feather(nor_coefs, "data/overregularization/nor_coefs.feather")

ages <- tibble(age = min(nor_longs$age):max(nor_longs$age))
nor_fits <- nor_models %>%
  ungroup() %>%
  filter(model_type != "null")  %>%
  mutate(fits = map(model, function(m){
    ages %>% mutate(.fitted = predict(m, newdata = ages, type = "response"))
  }))

nor_fit_vals <- nor_fits %>%
  select(-model) %>%
  unnest(cols = fits)
feather::write_feather(nor_fit_vals, "data/overregularization/nor_fit_vals.feather")
```

```{r overreg-nor-traj}
nor_model_comp <- feather::read_feather("data/overregularization/nor_model_comp.feather")
nor_coefs <- feather::read_feather("data/overregularization/nor_coefs.feather")
nor_fit_vals <- feather::read_feather("data/overregularization/nor_fit_vals.feather")

nor_groups <- nor_coefs %>%
  filter(term != "(Intercept)") %>%
  left_join(nor_model_comp) %>%
  filter(model_type == winner, n >= 4) %>%
  mutate(positive = if_else(estimate > 0, "positive", "negative"),
         term = fct_recode(term, "age2" = "I(age^2)")) %>% #"intercept" = "(Intercept)", 
  select(original_id, lexical_category, num_admins = n, winner, term, positive) %>%
  pivot_wider(names_from = term, values_from = positive, names_prefix = "direction_") %>%
  mutate(trajectory = case_when(
    winner == "linear" & direction_age == "positive" ~ "/",
    winner == "linear" & direction_age == "negative" ~ "\\",
    winner == "quadratic" & direction_age2 == "positive" ~ "V",
    winner == "quadratic" & direction_age2 == "negative" ~ "Λ",
    TRUE ~ "ALERT"
  )) %>%
  mutate(trajectory = fct_infreq(trajectory))

nor_group_counts <- nor_groups %>%
  count(lexical_category, trajectory) %>%
  group_by(lexical_category) %>%
  mutate(label = sprintf("N = %s (%.0f%%)", n, n / sum(n) * 100))

nor_fit_vals_grouped <- nor_fit_vals %>%
  left_join(nor_groups) %>%
  filter(model_type == winner) %>%
  mutate(id_n = paste(original_id, num_admins)) %>%
  mutate(original_id = fct_reorder(original_id, num_admins))
```

```{r overreg-nor-groups-plot, dependson="nor-traj", fig.width=8, fig.height=4.5}
ggplot(nor_fit_vals_grouped, aes(x = age, y = .fitted)) +
  facet_grid(lexical_category ~ trajectory, labeller = label_caps, switch = "y") +
  geom_line(aes(group = id_n, colour = original_id, alpha = num_admins)) +
  geom_text(aes(label = label), family = .font, hjust = 0, vjust = 1, size = 3,
            x = min(nor_fit_vals_grouped$age), y = max(nor_fit_vals_grouped$.fitted),
            data = nor_group_counts) +
  .scale_colour_numerous(guide = FALSE) +
  scale_alpha_continuous(guide = FALSE) +
  scale_x_continuous(breaks = seq(16, 36, 4)) +
  labs(x = "Age (months)", y = "Model fit probability of overregularizing") +
  theme(strip.placement = "outside")
```

```{r overreg-nor-lexcat-plot, dependson="nor-traj", out.width="75%"}
nor_lexcat <- nor_groups %>%
  select(original_id, lexical_category, trajectory) %>%
  pivot_wider(names_from = lexical_category, values_from = trajectory) %>%
  filter(!is.na(nouns), !is.na(verbs))

nor_lexcat_props <- nor_lexcat %>%
  group_by(nouns) %>%
  count(verbs) %>%
  mutate(p = n / sum(n))

nor_lexcat_labels <- nor_lexcat_props %>%
  group_by(nouns) %>%
  mutate(sp = cumsum(p) - 0.5 * p) %>%
  filter(nouns == verbs)

ggplot(nor_lexcat_props, aes(x = nouns, y = p, fill = fct_rev(verbs))) +
  geom_col() +
  geom_text(aes(label = verbs, y = sp), data = nor_lexcat_labels, fontface = "bold") +
  .scale_fill_discrete() +
  labs(x = "Noun trajectory",
       fill = "Verb trajectory",
       y = "Proportion of children")
```

```{r overreg-nor-dense-plot, dependson="nor-traj", fig.width=8, fig.height=7}
min_admin_plot <- 9
nor_fit_demo <- nor_fit_vals_grouped %>%
  filter(trajectory == "Λ", num_admins >= min_admin_plot) %>%
  group_by(original_id) %>%
  filter(all(c("nouns", "verbs") %in% lexical_category)) %>%
  mutate(sum_fitted = sum(.fitted)) %>%
  ungroup() %>%
  mutate(original_id = fct_reorder(original_id, sum_fitted, .desc = TRUE))

nor_longs_demo <- nor_longs %>%
  ungroup() %>%
  inner_join(nor_fit_demo) %>%
  mutate(original_id = fct_reorder(original_id, sum_fitted, .desc = TRUE))

ggplot(nor_fit_demo, aes(x = age, y = .fitted, colour = lexical_category)) +
  facet_wrap(~original_id, ncol = 6) +
  geom_point(aes(y = prop), alpha = 0.5, size = 0.8, data = nor_longs_demo) +
  geom_line(size = 1) +
  .scale_colour_discrete(name = "") +
  scale_linetype(guide = FALSE) +
  scale_x_continuous(breaks = seq(16, 36, 4)) +
  labs(x = "Age (months)", y = "Model fit probability of overregularizing") +
  theme(legend.position = "top",
        strip.text = element_blank())
```

## Conclusions

This brief chapter examined overregularization data from the morphology items of the Words and Sentences form. The primary takehome from our analyses is that there is tremendous heterogeneity in these data -- many children are never reported to overgeneralize within the age range of the sample. Others do, however. This behavior is not well-predicted by age or vocabulary, however, making it somewhat mysterious what the drivers of over-regularization behavior are. 

One possibility that bears discussion is whether parents are less keen observers of morphological generalization than they are of vocabulary growth more broadly. It is possible that the lack of systematicity we observed is due to inconsistency in which parents report overgeneralization -- perhaps only some parents are sensitized to the somewhat meta-linguistic observation that their child is using a frequent ending incorrectly (e.g., *foots*). This kind of bias would be consistent with the noun-verb overregularization correlation we observed -- only systematic validation outside of the CDI would truly dispell this worry. 

On the other hand, the kind of variability we observed is not unlike the variability observed in naturalistic studies of overgeneralization [e.g., @marcus1990]. Thus, at a minimum, our work here suggests caution in the received narrative of morphological generalization as just another stage in the predictable progression of language learning. Unlike, say, word combination (cf. Chapter \@ref(grammar)), we do not see as clear a developmental march towards this more elusive behavior. 
