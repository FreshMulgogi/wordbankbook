```{r aoapred-setup} 
pander::panderOptions("round", 2)

data_path <- "data/aoa"
data_files <- list.files(data_path, full.names = TRUE)
for (file in data_files) load(file)

num_langs <- n_distinct(lang_coefs$language)
predictors <- levels(lang_coefs$term)
num_coefs <- length(predictors)

langs_aoa <- unique(lang_coefs$language) %>% str_replace("Quebec", "Quebecois")
# hack for aoapred having cached data with old lang label

lang_colours_aoa <- lang_colours[names(lang_colours) %in% langs_aoa] %>%
  set_names(str_remove(names(.), " \\(.*\\)"))

label_caps <- function(value) {
  if_else(toupper(value) == value, value,
          paste0(toupper(substr(value, 1, 1)),
                 tolower(substr(value, 2, nchar(value)))))
}
```

```{r aoapred-coefs}
display_predictors <- predictors %>%
  map_chr(~.x %>% str_replace("_", " ") %>% str_replace("num", "number") %>%
            str_replace("phons", "phonemes") %>% label_caps()) %>%
  set_names(predictors)

plt_lang_coefs <- lang_coefs %>%
  mutate(term = term %>%
           factor(labels = display_predictors[levels(lang_coefs$term)]),
         signif = if_else(signif, "significant", "non-significant"),
         language = gsub("(.*) \\(.*\\)", "\\1", language))

mean_lang_coefs <- plt_lang_coefs %>%
  group_by(term, measure, interaction) %>%
  summarise(mean_estimate = mean(estimate),
            n_sig = sum(signif == "significant"))

mean_term_coefs <- lang_coefs %>%
  filter(interaction == "main effect") %>%
  group_by(term) %>%
  summarise(mean_estimate = mean(estimate),
            n_sig = sum(signif),
            n_pos = sum(estimate > 0),
            n_neg = sum(estimate < 0)) %>%
  arrange(desc(abs(mean_estimate)))

mean_interaction_coefs <- lang_coefs %>%
  filter(interaction == "interaction with age") %>% #, signif) %>%
  group_by(term, measure) %>%
  summarise(mean_estimate = mean(estimate),
            #n_sig = sum(signif),
            n_pos = mean(estimate > 0),
            n_neg = mean(estimate < 0)) %>%
  #arrange(desc(abs(mean_estimate)))
  arrange(desc(n_neg)) %>%
  filter(n_neg >= 0.9)

mean_term_coef <- function(t) {
 mean_term_coefs %>%
    filter(term == t) %>%
    pull(mean_estimate) %>%
    round(2)
}

plt_lexcat_coefs <- lexcat_coefs %>%
  mutate(term = term %>%
           factor(labels = display_predictors[levels(lexcat_coefs$term)]),
         signif = if_else(signif, "significant", "non-significant"),
         lexical_category = lexical_category %>%
           fct_relevel("Nouns", "Predicates", "Function words"),
         language = gsub("(.*) \\(.*\\)", "\\1", language)) %>%
  filter(interaction == "main effect",
         !(term %in% c("Valence", "Arousal")))

mean_lexcat_coefs <- plt_lexcat_coefs %>%
  group_by(lexical_category, term, measure, interaction) %>%
  summarise(mean_estimate = mean(estimate))

ref_coefs <- plt_lang_coefs %>%
  filter(language == "English", measure == "understands")

lexcat_mean_cor <- function(lc) {
  lexcat_coef_summary %>%
    group_by(lexical_category) %>%
    summarise(mean_cor = mean(mean_cor)) %>%
    filter(lexical_category == lc) %>%
    pull(mean_cor) %>%
    round(2)
}
```

```{r aoapred-polysemy}
# polysemously split uni_lemmas
poly <- uni_model_data %>%
  ungroup() %>%
  distinct(language, uni_lemma, words) %>%
  filter(str_detect(uni_lemma, "\\(.*\\)")) %>%
  mutate(homonym = str_replace(uni_lemma, "(.*) \\(.*\\)", "\\1")) %>%
  group_by(language, homonym) %>%
  filter(n() > 1) %>%
  distinct(language, homonym) %>%
  ungroup() %>%
  count(language)
```

```{r aoapred-overlap}
# how much do uni_lemmas overlap across languages

overlap <- uni_model_data %>%
  ungroup() %>%
  distinct(language, uni_lemma) %>%
  group_by(uni_lemma) %>%
  summarise(n_langs = n()) %>%
  group_by(n_langs) %>%
  summarise(n = n()) %>%
  mutate(prop = n / sum(n))

in_range <- function(min_langs, max_langs) {
  round(sum(
    filter(overlap, n_langs >= min_langs, n_langs <= max_langs)$prop * 100
  ))
}
```

```{r aoapred-correlations}
# pairwise correlations among predictors

# cors <- uni_model_data %>%
#   split(paste(.$language, .$measure)) %>%
#   map_df(function(lang_data) {
#     pred_data <- lang_data %>%
#       select_(.dots = c("uni_lemma", predictors)) %>%
#       distinct() %>%
#       gather_("predictor", "value", predictors) %>%
#       split(.$predictor)
#     
#     map(pred_data, function(pd1) {
#       map_dbl(pred_data, function(pd2) cor(pd1$value, pd2$value))
#     }) %>%
#       as.data.frame() %>%
#       mutate(predictor1 = row.names(.)) %>%
#       gather_("predictor2", "cor", predictors) %>%
#       filter(predictor1 != predictor2) %>%
#       mutate(language = unique(lang_data$language),
#              measure = unique(lang_data$measure))
# 
#   }) %>%
#   as_tibble() %>%
#   mutate(predictors = map2_chr(predictor1, predictor2,
#                                ~paste(sort(c(.x, .y)), collapse = "|"))) %>%
#   distinct(language, predictors, cor)
# 
# mean_cors <- cors %>%
#   group_by(predictors) %>%
#   summarise(mean_cor = mean(cor)) %>%
#   arrange(desc(abs(mean_cor)))
# 
# pair_cor <- function(preds) {
#   mean_cors %>% filter(predictors == preds) %>% .$mean_cor
# }

# max_other_cor <- cors %>%
#   mutate(predictor_pair = paste(predictor1, predictor2)) %>%
#   filter(!(predictor_pair %in% c("solo_frequency MLU", "MLU solo_frequency"))) %>%
#   arrange(desc(abs(cor))) %>%
#   pull(cor) %>%
#   .[1] %>%
#   abs()
```

```{r aoapred-pairwise}
# pairwise correlations among predictors

predictor_cors <- uni_model_data %>%
  ungroup() %>%
  select(language, uni_lemma, !!predictors) %>%
  distinct() %>%
  gather(predictor, value, !!predictors) %>%
  group_by(language) %>%
  nest() %>%
  mutate(cors = map(data, ~.x %>%
                    widyr::pairwise_cor(predictor, uni_lemma, value,
                                 upper = FALSE))) %>%
  select(-data) %>%
  unnest() %>%
  arrange(desc(abs(correlation))) %>%
  rename(predictor1 = item1, predictor2 = item2)

mean_predictor_cors <- predictor_cors %>%
  group_by(predictor1, predictor2) %>%
  summarise(mean_cor = mean(correlation)) %>%
  arrange(desc(abs(mean_cor)))

mean_pair_cor <- function(p1, p2) {
  mean_predictor_cors %>%
    filter(predictor1 == p1 & predictor2 == p2 |
             predictor1 == p2 & predictor2 == p1) %>%
    pull(mean_cor) %>%
    round(2)
}
```

```{r aoapred-collinearity}
# multicollinearity check

predictor_data <- uni_model_data %>%
  ungroup() %>%
  select(language, !!predictors) %>%
  distinct() %>%
  nest(-language)

predictor_vif <- function(lang_data, predictor) {
  others <- paste(predictors[predictors != predictor], collapse = ' + ')
  predictor_model <- glue::glue("{predictor} ~ {others}") %>%
    as.formula() %>%
    lm(data = lang_data)
  1 / (1 - summary(predictor_model)$r.squared)
}

vifs <- predictor_data %>%
  mutate(vifs = map(data, function(lang_data) {
                    data_frame(predictor = predictors,
                                vif = map_dbl(predictors,
                                              ~predictor_vif(lang_data, .x)))
         })) %>%
  select(-data) %>%
  unnest()
```
