# Vocabulary Composition: Semantic {#categories-semantic}

Following the approach in the previous chapter, we investigate the consistency of semantic content categories across languages. By analogy with the "noun bias," are some languages "vehicle focused" or "animal focused"? These analyses are expected to reveal cultural and linguistic differences in the specific words learned by children (perhaps due to differences in the content of their environment). 

## Introduction and methods

In contrast to the "noun bias" literature, where a wide variety of hypotheses have been articulated over the preceding decades, differences in content have been less explored and so these analyses are far more exploratory. Analyses of cognitive biases in the early language of international adoptees by @snedeker2012 are a notable exception, but these analyses are limited to English data due to the complexity of gathering such data. To limit the scope of our current exploration, we focus on WS-type forms and production measures, which we have reason to believe will be most reliable. 

```{r catsem-items, fig.width=8, fig.height=7, fig.cap="Number of languages whose forms contain each semantic category."}
cat_label <- function(cats) {
  cats %>% str_replace("(food|games|furniture)_(.*)", "\\1 & \\2") %>%
    str_replace_all("_", " ") %>% str_to_title()
}

items <- items %>%
  filter(type == "word") %>%
  mutate(num_item_id = as.numeric(substr(item_id, 6, nchar(item_id))))

category_freqs <- items %>%
  filter(form %in% WSs) %>%
  unite(langform, language, form, sep = .inst_sep) %>%
  filter(!is.na(category)) %>%
  group_by(category, lexical_category, langform) %>%
  summarise(items = n()) %>%
  group_by(category, lexical_category) %>%
  summarise(items = mean(items), 
            langs = n()) %>%
  ungroup %>%
  filter(lexical_category != "unknown") %>%
  mutate(category_label = cat_label(category) %>% fct_reorder(langs),
         lexcat_label = lexical_category %>%
           str_replace_all("_", " ") %>% str_to_title() %>%
           fct_relevel("Nouns", "Predicates"))

ggplot(category_freqs,
       aes(x = category_label, y = langs, fill = lexcat_label)) + 
  coord_flip() +
  geom_col() + 
  .scale_fill_discrete(name = "Lexical category", 
                       guide = guide_legend(ncol = 3)) +
  scale_y_continuous(expand = c(0, 0),
                     limits = c(0, max(category_freqs$langs) + 0.5)) +
  xlab("") + 
  ylab("Number of languages") +
  theme(legend.position = "top")

filtered_freqs <- category_freqs %>%
  filter(lexical_category %in% c("nouns","other"), langs > 10)
included_cats <- filtered_freqs %>% pull(category)
included_labels <- filtered_freqs %>% pull(category_label)
```

In these analyses, we take advantage of the fact that CDI forms are typically structured into semantic categories (e.g., Animals or Body Parts). As Figure \@ref(fig:catsem-items) shows, while some semantic categories are shared across many instruments, there are others that are quite rare (many corresponding to specific categories that are of interest in particular languages). We focus on those semantic categories with greater representation in the data. Further, to avoid duplicating our analysis in Chapter \@ref(categories-syntactic), we focus on those semantic categories that fall into "nouns" and "other" lexical classes. (In general, Action Words and Descriptive Words tend to be broad predicate classes without as much clear semantic differentiation). This filtering step leaves `r length(included_labels)` categories: `r included_labels`. Samples included in this analysis are shown in Table \@ref(tab:catsem-sample-sizes). 


```{r catsem-script, eval=FALSE}
# this code contains caching for the various feathers. 
source("_categories-semantic.R")
```


```{r catsem-sample-sizes, results="asis"}
load("data/categories-semantic/cat_comp_data.Rds")
cat_comp_data <- cat_comp_data %>%
  ungroup() %>%
  mutate(category_label = cat_label(category)) %>%
  filter(measure == "produces")

areas <- read_feather("data/categories-semantic/sem_vocab_comp_areas.feather") %>%
  mutate(category_label = cat_label(category)) %>%
  filter(measure == "produces")

area_summary <- areas %>%
  group_by(language, form, measure, category, category_label) %>%
  summarise(mean =  mean(area),
            ci_lower = ci_lower(area),
            ci_upper = ci_upper(area)) %>%
  ungroup() %>%
  mutate(language = factor(language),
         instrument = paste(language, form, sep = .inst_sep))

area_summary_ordered <- area_summary %>%
  mutate(category_label = fct_reorder(category_label, mean))

sample_sizes <- cat_comp_data %>%
  group_by(language, form, measure, category) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  select(language, form, n) %>%
  distinct() 

cat(dt_caption("Number of CDI administrations in every instrument included in these analyses."))
sample_sizes %>% dt()
```


```{r catsem-plot_area_demo}
get_lang_cat_predictions <- function(lang, cat) {
  model <- filter(models, 
                  language == lang, 
                  category == cat)$model[[1]]
  data_frame(vocab = pts,
             prop = predict(model, newdata = data_frame(vocab = pts)),
             category = cat,
             language = lang)
}

get_lang_predictions <- function(lang) {
  map_df(unique(demo_data$category),
         function(cat) get_lang_cat_predictions(lang, cat))
}

demo_langs <- "English (American)"
demo_data <- cat_comp_data %>%
  ungroup() %>%
  filter(form == "WS", 
         language %in% demo_langs, 
         category %in% included_cats) %>%
  mutate(panel = paste(language, "(data)"))

pts <- seq(0, 1, 0.01)

models <- demo_data %>%
  group_by(language, category) %>%
  do(model = clm(prop ~ I(vocab ^ 3) + I(vocab ^ 2) + vocab - 1, data = .))

predictions <- map_df(demo_langs, get_lang_predictions) %>%
  mutate(category_label = cat_label(category) %>%
           fct_reorder2(vocab, prop, .fun = function(x, y) sum(x - y),
                        .desc = FALSE))
```

We first illustrate this approach using data from the English WS form alone. Analogous to the plots in Chapter \@ref(categories-syntactic), Figure \@ref(fig:catsem-eng-preds) shows areas where the data deviate from the pattern of category acquisition predicted by random item sampling. The size of the shaded region above vs. below the diagonal gives evidence of over- vs. under-sampling for a particular semantic category. 

```{r catsem-eng-preds, fig.cap="For American English WS data, model fit curves for proportion of each semantic category produced by each child as a function of the proportion of all vocabulary items produced by that child.", fig.height=5.5}
ggplot(predictions, aes(x = vocab, y = prop)) +
  facet_wrap(~category_label, ncol = 5) +
  coord_fixed() +
  geom_line(aes(colour = category_label), size = 1) +
  geom_polygon(aes(fill = category_label), alpha = 0.2) +
  geom_abline(slope = 1, intercept = 0, color = .grey, linetype = .refline) + 
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.5),
                     name = "Proportion of category") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.5),
                     name = "Vocabulary size") +
  .scale_colour_numerous(guide = FALSE) +
  .scale_fill_numerous(guide = FALSE) 
```

Many of the results of this analysis for English are expected. Sounds items are heavily over-represented, as are Body Parts, Games & Routines, and to a slightly lesser extent, Toys, Animals, and Vehicles. These particular biases are likely related to particular parenting practices, cultural emphases (for example, on animal names), and young children's' idiosyncratic interests. For a more in-depth examination of the consistencies in very early vocabulary, see Chapter \@ref(items-consistency); for more detail on what makes particular words easier or harder to learn, see Chapter \@ref(items-prediction). 

The largest *under*-representation across categories is Time Words. This pattern is consistent with a body of work on children's acquisition of the semantics of time words that suggests that children struggle with understanding these complex terms through age five [@tillman2015;@tillman2017]. 

We next turn to how this pattern varies across languages. 

## Global results

```{r catsem-plot-points-ws, fig.cap="Model fit curves for each semantic category as a function of vocabulary size for each language.", fig.height=5.5}
plot_data <- cat_comp_data %>%
  ungroup() %>%
  filter(form %in% WSs, 
         category %in% included_cats) %>%
  mutate(langform = interaction(language, form, sep = .inst_sep), 
         category_label = category_label %>%
           fct_reorder2(vocab, prop, function(x, y) sum(x - y), .desc = FALSE))
  
ggplot(plot_data, aes(x = vocab, y = prop, colour = langform)) +
  facet_wrap(~category_label, ncol = 5) +
  coord_fixed() +
  scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.5),
                     name = "Proportion of category") +
  scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.5),
                     name = "Vocabulary size") +
  scale_colour_manual(values = inst_colours, guide = FALSE) +
  geom_line(stat = "smooth", method = "clm",
            formula = y ~ I(x ^ 3) + I(x ^ 2) + x - 1, 
            size = 1, se = FALSE, alpha = .2) + 
  geom_abline(linetype = .refline, colour = .grey)
```

Because there are so many different languages represented in this analysis, the simplest analysis examines the spread of languages across categories (Figure \@ref(fig:catsem-plot-points-ws)). Somewhat surprisingly, the ordering of categories looks quite similar to what was observed in English. Sounds, Games & Routines, and Body parts are all over-represented. Vehicles, Food & Drink, Animals, and Clothing all are variable across cultures, as is People. Small Household Items, Outside Things, and Furniture & Rooms show variability but overall less bias. Finally, Places To Go and Time Words are both under-represented systematically across all languages. 

```{r catsem-plot-areas, fig.cap="Relative representation in vocabulary compared to chance for categories that tend to be over-represented across languages (line ranges indicate bootstrapped 95 percent confidence intervals).", fig.width=8, fig.height=8}
# cat_order <- area_summary %>%
#   filter(category %in% included_cats) %>%
#   group_by(category) %>%
#   summarise(mean = mean(mean)) %>%
#   arrange(desc(mean)) %>%
#   pull(category)

area_summary %>%
  filter(form %in% WSs, 
         category %in% c("sounds","games_routines","vehicles","body_parts")) %>%
  unite(langform, language, form, sep = .inst_sep) %>%
ggplot(aes(x = langform, y = mean, colour = langform)) +
  facet_wrap(~category_label) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  coord_flip() +
  geom_hline(yintercept = 0, linetype = .refline, colour = .grey) + 
  scale_colour_manual(values = inst_colours, guide = FALSE) +
  ylab("Relative representation in early vocabulary") + 
  xlab("")
```

We can zoom in on the most highly over-represented categories (Figure \@ref(fig:catsem-plot-areas)). The highest mean comes from Body Parts, which are over-represented in just about every language. Interestingly, the three datasets with the lowest proportion of Body Parts are the two Mandarin datasets (WS and TC) and the Cantonese WS data. Games & Routines are generally over-represented but somewhat more variable, with Kiswahili, Kigiriama, and Mandarin TC data lowest. Sounds are quite highly variable but almost all positive, with Russian being the outlier. Inspection of these items shows *negative* developmental trajectories for a number of words in the Sounds category. We believe these data are likely an artifact of parents feeling that they should "trade off" with noun labels in the Animals category, and hence items in Sounds category should be discounted. Finally, words in the Vehicles category appear more variable with positive preferences across language families.

```{r catsem-people-places-time, fig.width=8, fig.cap="Relative representation in vocabulary compared to chance for categories that tend to be under-represented or highly variable across languages (line ranges indicate bootstrapped 95 percent confidence intervals)."}
ggplot(filter(area_summary, 
              form %in% WSs, 
              category %in% c("people","places","time_words")) %>%
         unite(langform, language, form, sep = .inst_sep),
       aes(x = langform, y = mean, colour = langform)) +
  facet_grid(.~category_label) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  coord_flip() +
  geom_hline(yintercept = 0, linetype = .refline, colour = .grey) + 
  scale_colour_manual(values = inst_colours, guide = FALSE) +
  ylab("Relative representation in early vocabulary") + 
  xlab("")
```

We end by considering People, Places To Go, and Time Words (Figure \@ref(fig:catsem-people-places-time)). People is a highly-variable category, with some languages under-representing and others over-representing. @tardif2008 speculated that names for people were a substantial part of children's earliest words, but that may reflect that study's use of Mandarin and Cantonese data where people terms are very over-represented due to cultural emphasis on family connections. Surprisingly, despite the relatively multi-generational and family-centric nature of children's experience in Kenya [@alcock2013], people words were relatively under-represented in Kiswahili and Kigiriama. 

In contrast to the heterogeneity in people words, words in Places To Go and, especially, Time Words were almost uniformly under-represented in children's vocabulary. As noted above, time is known to be conceptually difficult for children. Interestingly, though, less has been written about children's understanding of geographical vocabulary. Time words offer a number of conceptual challenges in terms of mapping an ordered set of durations (second < minute < hour < day, etc.) to a set of concepts that do not map cleanly onto perceptual experience. In some sense, many of the same conceptual difficulties hold true for larger locational/geographical hierarchies (neighborhood < city < state < country). Or alternatively, the under-representation of places in children's early vocabulary may simply reflect the relative lack of diversity of their experiences with some of the items that traditionally populate this section (e.g., *beach*, *camping*, *church*, *circus* to name the first four). See Chapter \@ref(psychometrics) for some evidence that *camping* especially may be variable in children's experiences.

### Dimensionality reduction

```{r catsem-princomp}
areas <- filter(area_summary_ordered, 
              form %in% WSs, 
              # measure == "produces", 
              category %in% included_cats) %>%
  unite(langform, language, form, sep = .inst_sep) %>%
  filter(category != "sounds")

areas <- areas %>%
  select(langform, category_label, mean) %>%
  spread(category_label, mean) 

areas_matrix <- as.matrix(select(areas, -langform))
row.names(areas_matrix) <- areas$langform

# remove NAs 
areas_matrix_clean <- areas_matrix[!rowSums(!is.finite(areas_matrix)),]

pcs <- princomp(areas_matrix_clean)
```

Our next analysis of these data takes an exploratory dimensionality-reduction approach. Rather than examining each semantic category individually, we consider the space defined by variation in semantic preferences by running principal components analysis (PCA) on these data. PCA is a dimensionality reduction technique that projects high-dimensional data (e.g., bias by semantic category for each language) into a set of orthogonal dimensions where lower dimensions capture as much of the variance as possible. 

Standard PCA requires no missing data, thus we removed languages with missing categories. This analysis thus includes `r nrow(areas_matrix_clean)` language/form combinations and `r ncol(areas_matrix_clean)` categories. (We exclude words from Sounds because of the issue with Russian in this category and other missing data). 

Figure \@ref(fig:catsem-pca-autoplot-data) and Figure \@ref(fig:catsem-pca-autoplot-loadings) show the data projected into the space of the first two principal components and the loadings of semantic categories on these two components, respectively. 

```{r catsem-pca-autoplot-data, fig.cap="First two principal components for each language."}
ggfortify:::autoplot.pca_common(pcs, label.repel = TRUE,
                                loadings.label.repel = TRUE,
                                label.family = .font)
```

```{r catsem-pca-autoplot-loadings, fig.cap="Loadings of each semantic category."}
ggfortify:::autoplot.pca_common(pcs, loadings = TRUE, loadings.label = TRUE, 
                                shape = FALSE, label = FALSE,
                                loadings.label.repel = TRUE,
                                loadings.colour = .grey,
                                loadings.label.colour = "black",
                                loadings.label.family = .font)
```

Several observations emerge: Mandarin and Cantonese WS data are very far towards the direction of people (indicating that these datasets are unusual in this respect). Second, Kiswahili and Kigiriama are especially far in the direction of Outside and Places To Go words, perhaps consistent with the datasets being collected in rural and semi-rural areas. Many Northern European datasets (as well as Korean) are clustered at the far left, with high scores on Vehicles, Clothing, and Animals. Overall, this analysis reveals some interesting structure, but care should be taken not to over-interpret. In particular, within culture differences (e.g., Mandarin TC vs. Mandarin WS) are as large in size as between-culture differences.

## Individual conceptual items

In this section, we isolate individual items from specific domains of interest. Our approach is to use the "universal lemma" mappings (see Chapter \@ref(methods-and-data)) to find matching lexical items across languages. The specific domains we consider are time, color, body parts, and logical words. We also investigated spatial prepositions and number words, but do not include them here. Spatial prepositions present a wide variety of mapping issues since lexical items "cut up" space differently across languages [see e.g., @bowerman1996]. Number words are not found on enough CDI forms to have sufficient data for inclusion. 


```{r catsem-uni-base-plot}
plot_unis <- function(uni_data) {
  uni_data <- uni_data %>%
    mutate(uni_lemma = fct_reorder(uni_lemma, mean, .desc=TRUE)) %>%
    unite(langform, language, form, sep = .inst_sep)
  
  ggplot(uni_data, 
         aes(x = age, y = mean, col = langform)) + 
    coord_fixed(ratio = 16) +
    geom_smooth(se=FALSE, span = 1, alpha = .3) + 
    geom_smooth(aes(group = 1), span = 1, col = "black", se=FALSE, lty = 2) + 
    facet_wrap(~uni_lemma) + 
    theme(legend.position = "bottom", 
          legend.text = element_text(size = 8)) + 
    scale_colour_manual(values = inst_colours, name = "",
                        guide = guide_legend(ncol = 4)) +
    ylim(0,1) + 
    ylab("Proportion producing") + 
    xlab("Age (months)") + 
    xlim(16,32) # arbitrary
}
```

### Time 


```{r catsem-time}
time_words <- read_feather("data/categories-semantic/time_words.feather")
time_unis <- unique(time_words$uni_lemma)
```

As discussed above, the semantics of time words are very challenging for children through middle childhood [@tillman2015;@tillman2017]. Despite this, parents report that children do produce them by age 2.5. The set of words with sufficient translation equivalents for inclusion was `r glue::glue("_{time_unis}_")`.

```{r catsem-time-words, fig.height=9, fig.cap="Developmental trajectory of each time word in each language.", dependson="catsem-uni-base-plot"}
plot_unis(time_words)
```

Figure \@ref(fig:catsem-time-words) shows trajectories for these lexical items across languages, sorted by difficulty. Because *night* is typically signaled by darkness, it is perceptually very concrete and likely easier than other time words. Similarly, *now* seems relatively more straightforward given that it has a common imperative meaning in sentences like "give me that right now." In contrast, the latest-acquired is *yesterday*, which is highly abstract and requires a sort of "mental time travel" in thinking retrospectively beyond the "here and now" [@busby2005].  While *tomorrow* shares those same features, it does not appear to pose similar challenges for children in these data. 

### Color


Color word acquisition has been a focus of interest at least since early work by @carey1978's influential study of "fast mapping." Although early work suggested that color words were learned almost simultaneously [@bartlett1977], more recent studies have described a more protracted trajectory of partial knowledge. Many children learn some color words and overextend these to cover the rest of color space [@wagner2013]. Adding to the complexity of this issue is substantial cohort changes in the age at which colors are learned: while school-aged children struggled with their colors 50-100 years ago, more recently children learn colors in the age range spanned by the CDI forms [@bornstein1985].


```{r catsem-color}
color_words <- read_feather("data/categories-semantic/color_words.feather")
color_unis <- unique(color_words$uni_lemma)
```

There is tremendous cross-linguistic variation in color vocabulary [@kay2009]. We take advantage of the fact that most of the languages in our dataset have relatively larger color vocabularies, which we can assume means that individual colors probably have relatively similar extensions.^[Such an assumption would not be warranted if we were considering languages with just a handful of color terms, in which the extension of a term like _red_ would be much larger than in English.] Despite this, most CDI forms do not include all the basic level color words. The set of color words with sufficient translation equivalents for inclusion was `r glue::glue("_{color_unis}_")`.

```{r catsem-color-words, fig.cap="Developmental trajectory of each color word in each language.", fig.height=7, dependson="catsem-uni-base-plot"}
plot_unis(color_words)
```

In this set of words (Figure \@ref(fig:catsem-color-words)), we see that *red* is typically the first learned, although there is substantial variability in when it is learned. It is followed by *yellow*, *blue*, and *green*, with *black* and *white* following behind, consistent with reports by @wagner2013. 

```{r catsem-color-langs-words, fig.cap="Mean developmental trajectory of color words in each language."}
color_langs <- color_words %>%
  unite(langform, language, form, sep = .inst_sep) %>%
  group_by(langform, age) %>%
  summarise(mean = mean(mean))
 
ggplot(color_langs, 
       aes(x = age, y = mean, col = langform)) +
  geom_smooth(se = FALSE, span = 1) + 
  ggrepel::geom_label_repel(data = color_langs %>%
                              group_by(langform) %>%
                              filter(age == max(age)),
                            aes(label = langform), force = 4,
                            size = 2.5, alpha = 0.8, family = .font) +
  scale_colour_manual(values = inst_colours, guide = FALSE) +
  ylim(0,1) + 
  ylab("Proportion producing") + 
  xlab("Age (months)") + 
  xlim(16,36)
```

We additionally see an ordering across languages which have higher rates of color word production reported (Figure \@ref(fig:catsem-color-langs-words)). As in other analyses (see Chapter \@ref(vocabulary)), Mandarin WS has the highest level of production. American and Australian English also tend to have high levels of color production. Interestingly, Kiswahili has by far the lowest level of color production, perhaps related to the limited availability of manufactured toys of contrastive colors [@bornstein1985]. 

### Body parts

```{r catsem-body-words, fig.cap="Developmental trajectory of each body part word in each language.", fig.height=6.5, dependson="catsem-uni-base-plot"}
body_words <- read_feather("data/categories-semantic/body_words.feather")
plot_unis(body_words)
```

Words for Body Parts (Figure \@ref(fig:catsem-body-words)) are produced very early by most children, and variance is quite low across languages (with the exception of a few terms in Cantonese and Cypriot Greek). One interesting pattern that is visible in these data is the ordering of *hand* and *foot* before *leg* and *arm*. Interestingly, Cantonese is probably variant here because *hand* and *leg* are monomorphemic (and written with single characters) while *foot* and *arm* in Cantonese are morphological compounds. 


### Logic

```{r catsem-logic-words, fig.cap="Developmental trajectory of each logic word in each language.", fig.height=8, dependson="catsem-uni-base-plot"}
logic_words <- read_feather("data/categories-semantic/logic_words.feather")
logic_unis <- unique(logic_words$uni_lemma)
plot_unis(logic_words)
```

Finally, we examine words for logical operators (Figure \@ref(fig:catsem-logic-words)). The only items that are available across significant samples of languages are `r glue::glue("_{logic_unis}_")`. The negative words are learned early, with an ordering consistent with @bellugi1967 and @pea1982. *No* is very early, and *not* later. Interestingly, the quantifiers are not ordered as shown by @katsos2016 in a massive cross-linguistic study. In that study -- as well as in our own work in English [@horowitz2017] -- *all* was found to be understood better than *none*. In contrast, here we tend to find *none* is learned earlier than *all* and definitely learned earlier than *some*. One possibility is that these uses are only found in a restricted set of cases. Another is that contextualized production of negation is simpler than de-contextualized comprehension, as we have found in some of our work on the comprehension of negation in context [@nordmeyer2014;@nordmeyer2018].

### Category variability

Finally, we quantify the variability across languages for each of these restricted sets of lexical items. For 22--26 month-olds (chosen somewhat arbitrarily to be an age range of high coverage across forms that does not encompass too much developmental change), we compute the coefficient of variation for children at each age on each lexical item. (We first average across ages and then across lexical items; reported Ns are for the average number of contributing languages). We additionally add words from the Animals category for the sake of comparison. Table \@ref(tab:catsem-cat-var) gives the coefficient of variation for each category.

```{r catsem-cat-var}
animal_words <- read_feather("data/categories-semantic/animal_words.feather")

cat_var <- bind_rows(time_words %>% mutate(category = "time"),
                     body_words %>% mutate(category = "body"),
                     color_words %>% mutate(category = "color"), 
                     logic_words %>% mutate(category = "logic"), 
                     animal_words %>% mutate(category = "animals")) %>%
  filter(age > 21, age < 27) %>%
  group_by(category, uni_lemma, language) %>%
  summarise(mean = mean(mean)) %>% # average across ages
  group_by(category, uni_lemma) %>%
  summarise(cv = cv(mean), 
            sem = cv_sem(mean), 
            n = n()) %>%
  group_by(category) %>%
  summarise(cv = mean(cv), 
            sem = mean(sem), 
            n = mean(n)) %>%
  mutate(category = category %>% str_to_title())

cat_var %>%
  kable(digits = 2, col.names = c("Category", "CV", "SEM", "N"),
        caption = "Mean coefficient of variation for each semantic category.")
```

The acquisition of words from the Body Parts, as well as Animals, categories are highly consistent across languages. In contrast, color words, logic words, and time words are far less consistent cross-linguistically. These effects are likely somewhat affected by floor and ceiling effects, but inspection of individual items confirms the robustness of the general conclusion.

```{r catsem-cvs}
cvs <- cat_var %>%
  mutate(signature = paste("Bias for",category), 
         measure = "produces") %>%
  ungroup() %>%
  mutate(category = "Composition")

write_feather(cvs,"data/cvs/semantic_comp.feather")
```


## Discussion

In these exploratory analyses, we considered representation of different semantic categories across the different languages in our dataset. We found some surprising consistencies. Words from the Places to Go and Words About Time categories were under-represented, while words from the Sounds, Games & Routines, and Body Parts categories were over-represented. These consistencies were also contrasted with some areas of greater variability: for example, the preference for words from the Vehicles, Clothing, and Animals categories appeared to be a somewhat coherent dimension in our data, with many (northern) European languages higher on this dimension than non-European languages. Still, substantial caution is necessary in interpreting these results as the sample of non-European languages is small. Finally, we found that acquisition of complex conceptual words reflecting colors, time, and logical constructs was highly variable across languages.
