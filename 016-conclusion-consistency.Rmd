# Variability and Consistency {#conclusion-consistency}

In the preceding chapters, we have have presented evidence from a wide range of analyses of the Wordbank dataset. These analyses have revealed both striking variability across our units of sampling -- children, primarily, but also words and even languages -- but they have also revealed substantial consistency. In this synthetic chapter we begin by presenting a set of analyses of the empirical consistency and variability of specific phenomena. We then discuss the interplay and tension between these two ideas, variability and consistency, and how they interact with and inform theoretical conceptions of language acquisition more broadly.

## Synthetic measures of variability

```{r cons-min}
MIN_LANGS <- 6
```

In each of the substantive chapters of this book (roughly speaking from Chapter \@ref(vocabulary) to \@ref(style)), we have presented analyses of specific phenomena of theoretical interest. Wherever possible, we have generalized these analyses across languages so that their relative consistency can be examimined and discussed. The goal of the current analysis is to bring together these analyses into a single meta-analysis (in the general sense, not the specific statistical sense). 

This strategy executes the general idea discussed in Chapter \@ref(intro-theory). Our analyses identify "signatures" of language development that have been central to theoretical discussion. We then quantify these signatures numerically and measure their variation across languages. The resulting quantities are an empirically-derived measure of which aspects of language development appear more similar across different languages and contexts. We discuss the types of inferences licensed and not licensed by these analyses below. 

### Methods
Each measur
e for which we compute the CV will have both a different base unit and a different number of languages contributing. For example, when considering the correlation between grammar and the lexicon (Chapter \@ref(grammar)), we will be looking at the CV of a set of correlations with one specific set of languages contributing. When we look at the size of the noun bias (Chapter \@ref(categories-syntactic)) we will be looking at a group of bias estimates that have different units and a different set of languages. Thus, caution is warranted in interpreting these variability estimates, even as we believe that they are informative. To assist in interpretation, we exclude measures that can be computed in fewer than `r MIN_LANGS+1` languages; provide the N contributing languages for all analyses; and compute an estimate of the standard error of the CV ($$SEM \approx CV / \sqrt{2N}$$).

We begin by identifing a small number of measures computed in each chapter to serve as the "signatures" to be promoted into this analysis. For each measure, we compute its cross-linguistic variability using a standardized measure of variance, the coefficient of variation (CV, the standard deviation divided by the mean). This measure can range from 0 (with a phenomenon completely invariant across languages) to infinity (with higher numbers indicating greater variation). These CV values provide a single common measure to allow comparability of otherwise very different quantities, allowing inferences across analyses and datasets -- albeit with some cautions that we describe below. 

Each measure for which we compute the CV will have both a different base unit and a different number of languages contributing. For example, when considering the correlation between grammar and the lexicon (Chapter \@ref(grammar)), we will be looking at the CV of a set of correlations with one specific set of languages contributing. When we look at the size of the noun bias (Chapter \@ref(categories-syntactic)) we will be looking at a group of bias estimates that have different units and a different set of languages. Thus, caution is warranted in interpreting these variability estimates, even as we believe that they are informative. To assist in interpretation, we exclude measures that can be computed in fewer than `r MIN_LANGS+1` languages; provide the N contributing languages for all analyses; and compute an estimate of the standard error of the CV ($SEM \approx CV / \sqrt{2N}$).

The measures we include in this analysis are necessarily a subjectively-determined subset of the possible measures we have examined in the book. And of course those in turn are a subset of the measures we could have computed. Wherever possible we have attepted to make reasonable decisions, but some of these are by necessity somewhat arbitrary. An example of such a decision comes from the summary of Chapter \@ref(vocabulary). In that chapter we noted that population variability appears quite consistent across languages. We summarised population variability in production via a statistic, MMAD -- but what is the appropriate range of ages to include in a single estiamte? We noted that there appears to be a ceiling effect in the later ages, and so include variability in production from 12 -- 24 months. But this decision is data-dependent and so of course there is a risk of circularity. We point the issue out not to undermine this particular analysis; we believe the ceiling effect is quite clear and other aspects of the age choice do not lead to much change in the CV estimate. Rather we intend to highlight that the summary we give is not a theory-neutral estimate but rather a "best guess" -- an attempt to navigate the myriad choices involved in our analysis in a reasonable way. 

One example of such a choice is that we have made the decision to omit estimates of early production from WG-type forms. Our judgment was motivated by the fact that such estimates routinely are very noisy due to the sparsity of early production. In chapter after chapter, we found unreliable or uninterpretable results that are plausibly due to data sparsity; thus, we choose to omit these patterns. 


```{r cons-cvs_load}
files <- dir("data/cvs/", pattern = "*.feather")



cvs <- data_frame(name = files) %>%
  split(.$name) %>%
  map_df(function (x) { 
    read_feather(paste0("data/cvs/", x$name))
  }) 

# ugly cleanup of signature names
sigs <- unique(cvs$signature)
sigs <- str_replace_all(str_to_lower(sigs),"_", " ")
sigs <- paste0(toupper(substr(sigs, 1, 1)), substr(sigs, 2, nchar(sigs)))
sigs <- str_replace(sigs, "Mlu","MLU")
sigs <- str_replace(sigs, "Madm","MADM")
sigs <- str_replace(sigs, "Mom ed","Maternal Education")


cvs <- cvs %>%
  mutate(y = 0, 
         measure = fct_recode(measure, 
                               production = "produces", 
                               comprehension = "understands"), 
         signature = factor(signature, 
                            levels = unique(signature), 
                            labels = sigs), 
         signature = fct_reorder(signature, cv, .desc = TRUE)) %>%
  filter(n > MIN_LANGS) 


```

For the sake of our analysis, we have divided measures from the preceding chapters into four categories. These are:

1. Measures of the composition of vocabulary, from Chapters \@ref(categories-syntactic) and \@ref(categories-semantic). These measures describe the over- and under-representation of various word categories in vocabulary. The units over which CV is computed are bias scoresl; these are bounded from -.5 to .5 (deviation from unbiased acquisition of a particular category). 

2. Predictors of word difficulty, from Chapter \@ref(items-prediction). The consistency of different regression predictors of age of acquisition are here represented by their cross-linguistic consistency. This analysis is distinct from the analysis presented in that chapter (which focused mostly on the *magnitude* rather than *variability* of the coefficients themselves). Despite that, we include it here for comparison with other signatures. The units over which CV is computed are standardized regression coefficients.

3. Relational measures. These measures are from Chapters \@ref(gesture) and \@ref(grammar). These measures are originally correlations between vocabulary size and other aspects of early language.

4. Vocabulary signatures. These measures document patterns in the overall size of vocabulary across individuals and demographic groups. They are extracted from Chapters \@ref(vocabulary) and \@ref(demographics) and the original units are themselves variability-based (MMAD scores). 

```{r cons-cvs_plot_1}
ggplot(cvs, 
       aes(x = signature, y = cv, col = measure)) + 
  geom_point(aes(size = n), alpha = .5) + 
  geom_linerange(aes(ymin = cv - sem, ymax = cv + sem)) + 
  ylab("Coefficient of variation across languages") + 
  geom_hline(yintercept = 0, lty = 2) + 
  xlab("") + 
  coord_flip() + 
  facet_wrap(~category, 
             drop = TRUE, scales = "free_y") + 
  theme(legend.position = "bottom") + 
  .scale_colour_discrete(name = "Measure") + 
  scale_size_continuous(name = "N languages") + 
  ylim(0,2)
```

### Results

The figure above shows the coefficient of variation across languages for all measures in each of these categories. Error bars show standard error of the CV. Dot size shows the number of languages included in the analysis. Color shows whether the measure was computed on comprehension or production. Points are ordered from lowest CV to highest. A number of patterns are immediately apparent, providing a synthesis across the different parts of our broader enterprise. 

First, comprehension is almost always more variable than production, even when an even number of languages are included. The only obvious exception to this regularity is for coefficient weights on arousal in the Predictors category -- and we can discount this example: arousal was on average one of the weakest predictors of acquisition order overall. Why would comprehension be more variable across languages than production, especially given evidence that comprehension vocabulary tends to be *less* idiosyncratic than production [@mayor2014]? One strong possibility is the psychometric properties of comprehension vs. production reports.  

As described in Chapter \@ref(psychometrics), while comprehension scores still appear to be a reliable and valid index of children's abilities in the aggregate, individual comprehension questions tend to carry less information. Thus, there may simply be more noise in these measurements, leading to less cross-linguistic stability. This regularity illustrates a point we have made earlier and will return to below: the inferences from consistency and variability are asymmetric. In the case of consistency, we can make relatively strong inferences about some kind of shared process or mechanism. In contrast, in the case of variability, there are many sources of variance (including measurement error) that can account for a specific pattern of performance. 

Second, relational measures are highly invariant across languages. These relations include correlations between the size of children's lexicon (in production or comprehension) and their gesture, morphology, and grammatical complexity. These findings can be measured in a relatively small set of languages (due to limited data availability for the gesture and complexity items on the form). Nevertheless, the high level of consistency is striking. Of course, as we disussed in the associated chapters, one possible confound in these findings is general parent reporting bias. That is, parents who are biased to believe their children talk more are also likely to be biased to believe their children are also more advanced with respect to gestures and grammatical complexity. 

Third, demographic predictors -- birth order, maternal education, and sex -- are somewhat variable, likely reflecting at least some cultural vriation. The most variable of these is the relation of maternal education with vocabulary. Maternal education is plausibly a proxy for socioeconomic status (SES); in turn the relation of SES to vocabulary is likely mediated by many local- and national-level policies including access to childcare, parent leave, pre- and post-partum education and services. Thus, we view variation on this dimention as highly plausible *a priori*. 

Fourth, generalizations about vocabulary composition span the range from extremely consistent (early over-representation of body parts) to extremely variable (bias for -- or against -- predicates). Overall, however, it is interesting to see that there are some consistencies in the things that children talk about early: in particular the bias for body parts and animal words seems consistent with some of the results on the predictive power of "babiness" (things babies like to talk about) in Chapter \@ref(items-prediction). In contrast, it's the hard and abstract domains that are somewhat more variable, e.g. color, time, logic words (and function words more generally). These analyses are limited by the relatively small set of lexical items that are shared across languages and aross the CDI forms for those languages, however. 

Finally, while predictors of word difficulty are consistent relative to a chance baseline (see Chapter \@ref(items-prediction)), they are also on the higher end of variability. Especially in comparison to some of the relational signatures (e.g., the correlation between grammatical complexity and vocabulary), their variability is high. Plausibly some of this variability is due to additional variation added to these estimates by the use of external resources (e.g., corpus counts). In particular, as we discussed in that earlier chapter, there is an unknown amount of noise added by estimating frequencies from smaller-scale cross-linguistic corpora. 


### Limitations

All of our individual analyses have as limitations the nature of the data on which they are based. That is, the data are correlational and cross-sectional, with wide variation in critical administration details. But the current analyses have a set of further limitations that should qualify our interpretation of the figure shown above. 

One salient issue is that each estimate includes different 




In the face of this 



## Synthesis

### Develpmental process

What sort of developmental process of vocabulary learning could lead to these universals? Any claim of this sort must be very speculative. If pushed, we would point to the following (weak) proposals regarding processes that are consistent with some of our putative universals. 

1. Demographic differences are -- at least -- consistent with interactional-input theories of vocabulary development [@hart1995;@hoff2003;@weisleder2013] in which the more and higher-quality the input the child receives, the faster vocabulary grows. Under this hypothesis, first-born, female, and higher-maternal education children all are likely to receive more and higher-quality input: female children through the route of their somewhat greater social/interactional abilities (an extra assumption), first-born children through their greater allocation of parent attention, and high maternal-education children through greater parental awareness of the role of input, differering parental practices, and greater amount of leisure time to spend with children among other factors. 

2. Both the noun bias and the age-of-acquisition prediction results are consistent with the broader cross-situational viewpoint on acquisition [@smith2008;@gleitman1990]. On this view, nouns are easy to learn because the more they are heard, the more opportunities children get to build consistent mappings between the words and their referents. In contrast, verbs and other predicates rely more on a base of nouns and a basic comprehension of the syntactic structures in which they appear in order to infer meaning in context. Thus they should be acquired relatively later and with relativel more support from shorter, easier-to-parse utterances (MLU as a predictor, for example). Cross-linguistic exceptions will tend to be for languages like Mandarin where many early-learned verbs are semantically-transparent enough to be learned cross-situationally. 

3. Correlations between grammar and the lexicon, as well as the greater role of MLU in predicting acquisition of function words are both consistent with views that posit gradual syntactic abstraction and generalization. Versions of such viewpoints exist throughout the broad theoretical space of language acquisition [@yang2016;@tomasello2003;@meylan2017], but all proposals rely on a learning mechanism in which generalizations about structure are graded and rely on the amount of evidence available. 





<!-- ### Variability -->

<!-- Beginning with the first monograph reporting the CDI norming study, @fenson1994 noted that variability is perhaps the primary and most striking fact about children's vocabulary learning. In Chapter \@ref(vocabulary), we quantified this variability and found that -- across languages and spanning children's second year -- the variability was as large as the central tendency.  -->

<!-- In practical terms, the huge variance across children accounts for the fact that while some typically-developing two year olds will talk your ear off, others will barely utter a handful of words (even if they understand more). From a biological perspective, this variability is quite unprecedented. As a comparison, variation in heights for toddlers is tiny compared with variation in vocabulary: the mean height for a 24-month-old is around 33 inches, with a standard deviation of a little more than an inch, leading to a coefficient of variation around .03. This measurement is almost two orders of magnitude smaller than the coefficient of variation on vocabulary.  -->


### Consistency 

How can we describe and explain this variability? While much of the variance in the distribution of children remains unexplained, we still observe some striking correlates that can provide 
 In this sense, our work here follows what we might call the "Batesian program," the use of large-N data from the CDI to identify consistent developmental patterns that give clues to the organization of the mechanisms of language acquisition. To provide grounding to our discussion, we review consistencies below:

**Demographic differences**. In Chapter \@ref(vocabulary), we explored demographic differences in vocabulary. With very limited exceptions, we see a consistent advantage for girls over boys in early word learning across languages. Similarly, across (a smaller set of) languages, children with earlier birth orders are reported to have larger vocabularies. Both of these demographic differences should be considered in light of the probability of reporting biases -- for example, parents might *expect* girls to have larger vocabularies and hence report more words on average [though perhaps the consistency of the female advantage is surprising given variation in gender biases and stereotypes across countries, e.g., @nosek2009]. We return to the issue of difficulties in causal inference below. 

**Coefficient of Variation** Variability across kids (size of the fan) FIXME

**Category biases**. In Chapter \@ref(categories-syntactic), we extend previous work [e.g., @bornstein2004] by quantifying the degree of bias for and against different word classes in early vocabulary. For example, with a handful of exceptions (discussed in depth in that chapter) we see a bias for the overrepresentation of nouns in early vocabulary, at the expense of predicates and, even more so, function words. 

**Individual words**. Following @tardif2008, we show that there are large similarities in the most common early words. Further, we show that the predictors of what words are easier and harder across langauges are extremely consistent. 

**Grammar and the lexicon**. Following @bates1997, we show the tight developmental correlations between the growth of grammatical complexity in children's early language and the growth of their vocabulary. 


### Limitations





Claims of universals should always be taken with a grain of salt. In our case, a variety of caveats apply, from the relatively limited sample size N = `r length(unique(instruments$language))` [see @piantadosi2014 for guidance on claims about strict universals] to the strong Indo-European bias amongst the languages in the database. At best our claim is of a statistical universal rather than an absolute universal. In addition, nearly all of our data come from populations in relatively industrialized nations [cf. @henrich2010]. FURTHER CAVEATS

So what *do* these data tell us? 

### Ruling out methodological alternatives

One important class of explanations that limits our ability to make generalizations is explanations of our observations that rely on data regarding the process of gathering CDI data itself, whether they relate to:

* the design process for the CDI, e.g., biases on the selection of words to be included in a form;
* the sampling process for families, e.g., biases on backgrounds of families within and across samples;
* the reporting process, e.g., biases regarding particular types of children (e.g., girls) or particular types of words (e.g., function words);

To rule out these explanations, we need to rely on the existence of converging evidence for the same effects from other sources. Some of these sources are cited in the original chapters, but we briefly review them here.

**Gender** [Probably in the original CDI/gender paper, look for references?]

**Birth order** [??]

**Noun bias** [bornstein study, others cited in that chapter?]

**Grammar/Lexicon** [??]

**Predictor consistency** [at least @huttenlocher1991, maybe others for frequency. harder for babiness, etc.]

In sum, for many of our proposed consistencies, we can begin to muster evidence against them from convergent sources. Nevertheless, much more work is needed to measure the size (not just the direction) of these effects and compare effect size across different measurements. For example, if the same size gender effect were found in the same population with both parent report and pointing-based methods, this finding would provide evidence against a parent-reporting bias account of gender differences. This high standard has yet to be met for most of the findings we report. 


## Limitations

All of our analyses are fundamentally correlational. No causal inferences from Wordbank data are possible. We'll say this again so you know we mean it: *no causal inferences are possible*. All of the consistencies described above admit alternative causal explanations. 

For example, as noted, parents could *think* that girls speak more and hence report more words for girls. Or girls could actually know more words. Similarly, first-born children could receive more language input due to the lack of other competition for parents' attention, and hence have larger vocabulary. Or parents could be *aware* of more of first-born children's vocabulary. Or both. As in the gender case, external data can provide evidence for or against particular causal explanations but in their absence we are left to speculate. 

For more cognitive consistencies that we observe, alternative causal interpretations are again possible. To take one example, the "noun bias" could result from any of the following causal mechansisms (as well as mixtures of these, or mixtures of these and others not described): 
* children could learn nouns more easily due to their social/referential disambiguation relative to the syntactic disambiguation  [@gleitman1990;@gillette1999]; 
* they could be learned more easily due to their conceptual transparency [@gentner2003]; 
* they could be reported more frequently by parents due to some feature, such as their  imageability or concreteness;
* etc. 

Nevertheless, an observed pattern of correlations can still create a target for theory. 

Theorizing in language acquisition has traditionally argued on the axes defined by the nativist/empiricist debate, as well as the debate between domain-general and domain-specific representations and mechanisms. We label the implied axis of the debate here as the continuum between domain-general, empiricist theories and domain-specific, nativist theories. Anchoring one side of this continuum are statistical learning theories, that posit that domain-general mechanisms that learn structure from continuous input can induce structure from linguistic input [CITES: rethinking innateness, etc.]. On the other side are content-nativist theories that posit language-specific representational structures, such as the Principles and Parameters theory [@chomsky1981, @baker2005]. 

For all the reasons described above, we do not believe that the observed consistencies directly bear on traditional questions of the mechanisms underlying language acquisition. Taking the correlation between grammar and the lexicon as a case study: theoretical proposals from many parts of the space shown in Figure \@ref(fig:theory-axis) can account for these data. For example, a purely bottom-up statistical generalization mechanism would clearly produce a correlation between lexical and grammatical structure [as in @bates1997's original propopsal]; statistical generalizations require lexical data and so more data should correlate with more generalization. But a more domain-specific nativist grammatical proposal might also produce this correlation, provided that it required triggering data [e.g., @gibson1994, @yang2015tolerance]. And many variations in between. 



the consistencies we observe across languages point to putative universals: generalizations that hold across very disparate populations of human children learning typologically distinct languages. Surely such universals should be an important basis for theorizing about language acquisition. A theory that accounted for such universals "for free" -- as a result of basic assumptions about the nature of the learning mechansisms -- would be able to claim more and broader evidence, for example. 

### Speculations about Process


