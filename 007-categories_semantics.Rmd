# Categorical Composition: Semantics {#categories-semantic} 

Following the approach in the previous chapter, we investigate the consistency of semantic content categories across languages. By analogy with the "noun bias," are some languages "vehicle-focused"? These analyses are expected to reveal cultural and linguistic differences in the specific words learned by children (perhaps due to differences in the content of their environment). 

## Introduction, Methods, and an Example

In contrast to the "noun bias" literature, where a wide variety of hypotheses have been articulated over the preceeding decades, differences in content have been less explored and so these analyses are far more exploratory. To limit the scope of this exploration, we focus on WS-type forms and production measures, which we have reason to believe will be most reliable. 

```{r  ccs_items}
items <- items %>%
  filter(type == "word") %>%
  mutate(num_item_id = as.numeric(substr(item_id, 6, nchar(item_id))))

category_freqs <- items %>%
  filter(form %in% WSs) %>%
  unite(langform, language, form) %>%
  filter(!is.na(category)) %>%
  group_by(category, lexical_category, langform) %>%
  summarise(items = n()) %>%
  group_by(category, lexical_category) %>%
  summarise(items = mean(items), 
            langs = n()) %>%
  ungroup %>%
  mutate(category = fct_reorder(category, langs, .desc = TRUE))

ggplot(category_freqs,
       aes(x = category, y = langs, fill = lexical_category)) + 
  geom_bar(stat = "identity") + 
  scale_fill_solarized(name = 
                         "Lexical Category", 
                       guide = guide_legend(ncol = 3)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5), 
        legend.position = "bottom") + 
  xlab("") + 
  ylab("Languages") 

included_cats <- category_freqs %>%
  filter(lexical_category %in% c("nouns","other"), 
         langs > 10) %>% 
  pull(category)
```

In these analyses, we take advantage of the fact that CDI forms are typically structured into semantic categories (e.g., "animals" or "body parts"). As the figure above shows, while some semantic categories are shared across many instruments, thers are others that are quite rare (many corresponding to specific syntactic categories that are of interest in particular languages). We focus on those semantic categories with greater representation in the data. Further, to avoid duplicating our analysis in Chapter \@ref(categories), we focus on those semantic categories that fall into "nouns" and "other" lexical classes. (In general, "action words" and "descriptive words" tend to be broad predicate classes without as much clear semantic differentiation). This filtering step leaves `r length(included_cats)` categories: `r Reduce(paste0, sprintf("%s, ", included_cats[1:length(included_cats)-1]))` and `r included_cats[length(included_cats)]`. Samples included in this analysis are shown below 


```{r, eval=FALSE}
source("_categories_semantics.R")
```


```{r ccs_sample_sizes}
cat_comp_data <- read_feather("data/cat_comp_data.feather")
areas <- read_feather("data/sem_vocab_comp_areas.feather")

area_summary <- areas %>%
  group_by(language, form, measure, category) %>%
  summarise(mean =  mean(area),
            ci_lower = ci_lower(area),
            ci_upper = ci_upper(area)) %>%
  ungroup() %>%
  mutate(language = factor(language),
         instrument = paste(language, form))

area_summary_ordered <- area_summary %>%
  mutate(category = fct_reorder(category, mean))

sample_sizes <- cat_comp_data %>%
  group_by(language, form, measure, category) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  dplyr::select(language, form, n) %>%
  distinct() 

sample_sizes %>%
  datatable
```


```{r ccs_plot_area_demo}
get_lang_cat_predictions <- function(lang, cat) {
  model <- filter(models, 
                  language == lang, 
                  category == cat)$model[[1]]
  data.frame(vocab = pts,
             prop = predict(model, newdata = data.frame(vocab = pts)),
             category = cat,
             language = lang)
}

get_lang_predictions <- function(lang) {
  bind_rows(sapply(unique(demo_data$category),
                   function(cat) get_lang_cat_predictions(lang, cat),
                   simplify = FALSE))
}

demo_langs <- "English (American)"
demo_data <- filter(cat_comp_data, form == "WS", 
                    language %in% demo_langs, 
                    category %in% included_cats) %>%
  mutate(panel = paste(language, "(data)"))

pts <- seq(0, 1, 0.01)

models <- demo_data %>%
  group_by(language, category) %>%
  do(model = clm(prop ~ I(vocab ^ 3) + I(vocab ^ 2) + vocab - 1, data = .))

predictions <- bind_rows(sapply(demo_langs, get_lang_predictions, simplify = FALSE))

diagonal <- expand.grid(vocab = rep(rev(pts)),
                        language = demo_langs,
                        lexical_category = unique(demo_data$lexical_category))
diagonal$prop <- diagonal$vocab

area_poly <- bind_rows(predictions, diagonal) %>%
  mutate(panel = paste(language, "(models)"))
```

```{r}
ggplot(filter(predictions, language == "English (American)") %>%
         mutate(category = fct_reorder2(category, vocab, prop, function(x, y) {
           sum(x - y)
           }, .desc=FALSE)), 
       aes(x = vocab, y = prop)) +
  facet_wrap(~ category) +
  geom_line(aes(colour = category), size = 1) +
  geom_polygon(data = filter(area_poly, language == "English (American)") %>%
         mutate(category = fct_reorder2(category, vocab, prop, function(x, y) {
           sum(x - y)
           }, .desc=FALSE)),
               aes(fill = category), alpha = 0.2) +
  geom_abline(slope = 1, intercept = 0, color = "gray", linetype = "dashed") + 
  scale_y_continuous(limits = c(0, 1), breaks = c(),
                     name = "") +
  scale_x_continuous(limits = c(0, 1), breaks = c(),
                     name = "") +
  scale_colour_solarized(guide = FALSE) +
  scale_fill_solarized(guide = FALSE) 
```

We first illustrate this approach using data from the English WS form alone. Analogous to the plots in \@ref(categories), the plot above shows areas where the data deviate from the pattern of category acquisition predicted by random item sampling. The size of the shaded region above vs. below the diagonal gives evidence of over- vs. under-sampling for a particular semantic category. 

Many of the results of this analysis for English are expected. Sounds items are heavily over-represented, as are Body Parts, Games and Routines, and to a slightly lesser extent, Toys, Animals, and Vehicles. These particular biases are likely related  particular parenting practices, cultural emphases (for example, on animal names), and young childrens' idiosyncratic interests. For a more in-depth examination of the consistencies in very early vocabulary, see Chapter \@ref(items); for more detail on what makes particular words easier or harder to learn, see Chapter \@ref(aoapred). 

The largest *under*-representation across categories is Time Words. This pattern is consistent with a body of work on children's acquisition of the semantics of time words that suggests that children struggle with understanding these complex terms through age five [@tillman2015,@tillman2017]. 

We next turn to how this pattern varies across languages. 

## Results

```{r ccs_plot_points_ws}
plot_data <- cat_comp_data %>%
    filter(form %in% WSs, 
           category %in% included_cats) %>%
    mutate(langform = interaction(language, form), 
           category = fct_reorder2(category, vocab, prop, function(x, y) {
           sum(x - y)
           }, .desc=FALSE))
  
ggplot(plot_data, 
         aes(x = vocab, y = prop, colour = langform)) +
    facet_wrap(~category) +
    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.5),
                       name = "Proportion of Category") +
    scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.5),
                       name = "Vocabulary Size") +
    scale_colour_solarized(name = "", guide=FALSE) +
    theme(legend.position = "top",
          legend.key = element_blank(),
          legend.background = element_rect(fill = "transparent"), 
          strip.text.x = element_text(size = 7)) + 
  geom_line(stat="smooth",method = "clm", formula = y ~ I(x ^ 3) + I(x ^ 2) + x - 1, 
              size = 1, se = FALSE, alpha = .2) + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") 
```

Because there are so many different languages represented in this analysis, the simplest analysis examines the spread of languages across categories. Somewhat surprisingly, the ordering of categories looks quite similar to what was observed in English. Sounds, Games and Routines, and Body parts are all over-represented. Vehicles, Food and Drink, Animals, and Clothing all are variable across cultures, as is People. Houshold, Outside, and Furniture and Rooms show variability but overall less bias. Fianlly, Places and Time Word are both under-represented systematically across all languages. 

```{r ccs_plot_areas}
cat_order <- area_summary %>%
  filter(category %in% included_cats) %>%
  group_by(category) %>%
  summarise(mean = mean(mean)) %>%
  arrange(desc(mean)) %>%
  pull(category)

ggplot(filter(area_summary, 
              form %in% WSs, 
              category %in% c("sounds","games_routines","vehicles","body_parts")) %>%
         unite(langform, language, form),
       aes(x = langform, y = mean, colour = langform)) +
  facet_grid(.~category) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  coord_flip() +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  scale_colour_solarized(name = "", guide = FALSE) + 
  ylab("Relative representation in early vocabulary") + 
  xlab("")
```

We can zoom in on the most highly over-represeented categories. The highest mean comes from body parts, which are over-represented in just about every language. Interestingly, the three datasets with the lowest proportion of body parts are the two Mandarin datasets (WS and TC) and the Cantonese WS data. Games and routines are generally over-represented but somewhat more variable, with Kiswahili, Kigiriama, and Mandarin TC data lowest. Sounds are quite highly variable but almost all positive, with Russian sounds being the outlier. Inspection of these items shows *negative* developmental trajectories for a number of animal sounds. We believe these data are likely an artifact of parents feeling that they "trade off" with noun labels for animals, and hence should be discounted. Finally, vehicles appear more variable with positive preferences across language families.

```{r}
ggplot(filter(area_summary, 
              form %in% WSs, 
              category %in% c("people","places","time_words")) %>%
         unite(langform, language, form),
       aes(x = langform, y = mean, colour = langform)) +
  facet_grid(.~category) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  coord_flip() +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  scale_colour_solarized(name = "", guide = FALSE) + 
  ylab("Relative representation in early vocabulary") + 
  xlab("")
```
We end by considering people, places, and time words. People is a highly-variable category, with soem languages under-representing and others over-representing. @tardif2008 speculated that names for people were a substantial part of children's earliest words, but that may reflect that study's use of Mandarin and Cantonese data where people terms are very over-represented due to cultural emphasis on family connections. Surprisingly, despite the relatively multi-generational and family-centric nature of children's experience in Kenya [@alcock2013], people words were relatively under-represented in Kiswahili and Kigiriama. 

In contrast to the heteroeneity in people words, words for places and, especially, time words were almost uniformly under-represented in children's vocabulary. As noted above, time is known to be conceptually difficult for children. Interestingly, though, less has been written about children's understanding of geographical vocabulary. Time words offer a number of conceptual challenges in terms of mapping an ordered set of durations (second < minute < hour < day, etc.) to a set of concepts that do not map cleanly onto perceptual experience. In some sense, many of the same conceptual difficulties hold true for larger locational/geographical hierarchies (neighborhood < city < state < country). Or alternatively, the under-representation of places in children's early vocabualry may simply reflect the relative lack of diversity of their experiences with some of the items that traditionally populate this section (e.g., *beach*, *camping*, *church*, *circus* to name the first four). See Appendix \@ref(appendix-psychometrics) for some evidence that *camping* especially may be variable in children's experience.

## Dimensionality Reduction Approach

### WS Production Nouns

```{r ccs_princomp}
areas <- filter(area_summary_ordered, 
              form == "WS", 
              measure == "produces", 
              category %in% included_cats)

areas %<>%
  dplyr::select(language, category, mean) %>%
  spread(category, mean) 


areas_matrix <- as.matrix(dplyr::select(areas, -language))
row.names(areas_matrix) <- areas$language

# remove NAs 
areas_matrix <- areas_matrix[!rowSums(!is.finite(areas_matrix)),]

pcs <- princomp(areas_matrix)
```

Scree plot, indicating that PC1 dominates (for nouns, at least). 

```{r ccs_scree}
plot(pcs)
```

```{r ccs_loadings}
knitr::kable(as.data.frame(pcs$loadings[,]), digits = 2)
```

```{r ccs_loadings_plot}
pc_df <- data_frame(c1 = pcs$scores[,"Comp.1"], 
                     c2 = pcs$scores[,"Comp.2"], 
                    language = row.names(pcs$scores))
                    
                    
ggplot(pc_df, aes(x = c1, y = c2, col = language, label = language)) + 
  geom_point() +
  ggrepel::geom_label_repel() + 
  xlab("Sounds, Vehicles, Games, Animals, Clothing (PC1)") + 
  ylab("Sounds, not Vehicles (PC2)") + 
  scale_color_solarized(guide = FALSE)
```

## Specific semantic categories

```{r ccs_load_sem_data, eval=FALSE}
sem_data <- read_feather("data/semantic_data.feather")
```

Body parts as an example.

```{r ccs_load_bp}
# bp <- filter(sem_data, category == "body_parts")
bp <- read_feather("data/body_parts_data.feather")
```

Get unilemma set. 

```{r ccs_bp_unilemma}
bp_unis_df <- bp %>%
  filter(!is.na(uni_lemma)) %>%
  group_by(language, uni_lemma) %>%
  count %>%
  group_by(uni_lemma) %>%
  count 

bp_unis <- filter(bp_unis_df, nn > 4) %>% pull(uni_lemma)

bp_unis_df %>%
  arrange(desc(nn)) %>%
  datatable
```

Get those high-coverage uni-lemmas. 

```{r ccs_bp_unilemma_means}
bp_means <- bp %>%
  filter(uni_lemma %in% bp_unis) %>%
  group_by(language, uni_lemma, age) %>%
  summarise(mean = mean(produces), 
            n = n())
```

Plot. 

```{r ccs_bp_plots}
body_unis <- c("arm", "leg", "hand","foot", "finger", "toe") # "face", "hand", "head", 
face_unis <- c("cheek","eaer","eye","hair","mouth","nose","tongue","tooth")

upper_lower <- filter(bp_means, n > 10, language != "Korean",  
              uni_lemma %in% body_unis) %>%
  mutate(body_position = ifelse(uni_lemma %in% c("arm","hand","finger"), "upper", "lower"), 
         size = case_when(uni_lemma %in% c("arm","leg") ~ "arm/leg", 
                          uni_lemma %in% c("hand","foot") ~ "hand/foot",
                          uni_lemma %in% c("finger","toe") ~ "finger/toe"))

ggplot(upper_lower, 
       aes(x = age, y = mean, col = size)) + 
  # geom_point(aes(size = n)) +
  geom_smooth(se= FALSE, aes(lty = body_position), span = 1) + 
  facet_wrap(~language) + 
  scale_color_solarized() + 
  theme(legend.position = "bottom") + 
  ylab("Proportion Production") + 
  xlab("Age (months)")
```


```{r ccs_bp_face_plots}
face <- filter(bp_means, n > 10, language != "Korean",  
              uni_lemma %in% face_unis) 
# %>%
  # mutate(body_position = ifelse(uni_lemma %in% c("arm","hand","finger"), "upper", "lower"), 
  #        size = case_when(uni_lemma %in% c("arm","leg") ~ "arm/leg", 
  #                         uni_lemma %in% c("hand","foot") ~ "hand/foot",
  #                         uni_lemma %in% c("finger","toe") ~ "finger/toe"))

ggplot(face, 
       aes(x = age, y = mean, col = uni_lemma)) + 
  # geom_point(aes(size = n)) + 
  geom_smooth(se= FALSE, span = 1) + # aes(lty = body_position), 
  facet_wrap(~language) + 
  scale_color_solarized() + 
  theme(legend.position = "bottom") + 
  ylab("Proportion Comprehension") + 
  xlab("Age (months)")
```


