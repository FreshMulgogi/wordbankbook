# Categorical Composition: Semantics {#categories-semantic} 

Following the approach in the previous chapter, we investigate the consistency of semantic content categories across languages. By analogy with the "noun bias," are some languages "vehicle-focused"? These analyses are expected to reveal cultural and linguistic differences in the specific words learned by children (perhaps due to differences in the content of their environment). 

## Introduction, Methods, and an Example

In contrast to the "noun bias" literature, where a wide variety of hypotheses have been articulated over the preceding decades, differences in content have been less explored and so these analyses are far more exploratory. To limit the scope of this exploration, we focus on WS-type forms and production measures, which we have reason to believe will be most reliable. 

```{r  ccs_items}
items <- items %>%
  filter(type == "word") %>%
  mutate(num_item_id = as.numeric(substr(item_id, 6, nchar(item_id))))

category_freqs <- items %>%
  filter(form %in% WSs) %>%
  unite(langform, language, form) %>%
  filter(!is.na(category)) %>%
  group_by(category, lexical_category, langform) %>%
  summarise(items = n()) %>%
  group_by(category, lexical_category) %>%
  summarise(items = mean(items), 
            langs = n()) %>%
  ungroup %>%
  mutate(category = fct_reorder(category, langs, .desc = TRUE))

ggplot(category_freqs,
       aes(x = category, y = langs, fill = lexical_category)) + 
  geom_bar(stat = "identity") + 
  scale_fill_solarized(name = 
                         "Lexical Category", 
                       guide = guide_legend(ncol = 3)) +
  theme(axis.text.x = element_text(angle = 90, hjust = 1, vjust = .5), 
        legend.position = "bottom") + 
  xlab("") + 
  ylab("Languages") 

included_cats <- category_freqs %>%
  filter(lexical_category %in% c("nouns","other"), 
         langs > 10) %>% 
  pull(category)
```

In these analyses, we take advantage of the fact that CDI forms are typically structured into semantic categories (e.g., "animals" or "body parts"). As the figure above shows, while some semantic categories are shared across many instruments, there are others that are quite rare (many corresponding to specific syntactic categories that are of interest in particular languages). We focus on those semantic categories with greater representation in the data. Further, to avoid duplicating our analysis in Chapter \@ref(categories), we focus on those semantic categories that fall into "nouns" and "other" lexical classes. (In general, "action words" and "descriptive words" tend to be broad predicate classes without as much clear semantic differentiation). This filtering step leaves `r length(included_cats)` categories: `r Reduce(paste0, sprintf("%s, ", included_cats[1:length(included_cats)-1]))` and `r included_cats[length(included_cats)]`. Samples included in this analysis are shown below 


```{r, eval=FALSE}
# this code contains caching for the various feathers. 
source("_categories_semantics.R")
```


```{r ccs_sample_sizes}
cat_comp_data <- read_feather("data/cat_comp_data.feather")
areas <- read_feather("data/sem_vocab_comp_areas.feather")

area_summary <- areas %>%
  group_by(language, form, measure, category) %>%
  summarise(mean =  mean(area),
            ci_lower = ci_lower(area),
            ci_upper = ci_upper(area)) %>%
  ungroup() %>%
  mutate(language = factor(language),
         instrument = paste(language, form))

area_summary_ordered <- area_summary %>%
  mutate(category = fct_reorder(category, mean))

sample_sizes <- cat_comp_data %>%
  group_by(language, form, measure, category) %>%
  summarise(n = n()) %>%
  ungroup() %>%
  dplyr::select(language, form, n) %>%
  distinct() 

sample_sizes %>%
  datatable
```


```{r ccs_plot_area_demo}
get_lang_cat_predictions <- function(lang, cat) {
  model <- filter(models, 
                  language == lang, 
                  category == cat)$model[[1]]
  data.frame(vocab = pts,
             prop = predict(model, newdata = data.frame(vocab = pts)),
             category = cat,
             language = lang)
}

get_lang_predictions <- function(lang) {
  bind_rows(sapply(unique(demo_data$category),
                   function(cat) get_lang_cat_predictions(lang, cat),
                   simplify = FALSE))
}

demo_langs <- "English (American)"
demo_data <- filter(cat_comp_data, form == "WS", 
                    language %in% demo_langs, 
                    category %in% included_cats) %>%
  mutate(panel = paste(language, "(data)"))

pts <- seq(0, 1, 0.01)

models <- demo_data %>%
  group_by(language, category) %>%
  do(model = clm(prop ~ I(vocab ^ 3) + I(vocab ^ 2) + vocab - 1, data = .))

predictions <- bind_rows(sapply(demo_langs, get_lang_predictions, simplify = FALSE))

diagonal <- expand.grid(vocab = rep(rev(pts)),
                        language = demo_langs,
                        lexical_category = unique(demo_data$lexical_category))
diagonal$prop <- diagonal$vocab

area_poly <- bind_rows(predictions, diagonal) %>%
  mutate(panel = paste(language, "(models)"))
```

```{r}
ggplot(filter(predictions, language == "English (American)") %>%
         mutate(category = fct_reorder2(category, vocab, prop, function(x, y) {
           sum(x - y)
           }, .desc=FALSE)), 
       aes(x = vocab, y = prop)) +
  facet_wrap(~ category) +
  geom_line(aes(colour = category), size = 1) +
  geom_polygon(data = filter(area_poly, language == "English (American)") %>%
         mutate(category = fct_reorder2(category, vocab, prop, function(x, y) {
           sum(x - y)
           }, .desc=FALSE)),
               aes(fill = category), alpha = 0.2) +
  geom_abline(slope = 1, intercept = 0, color = "gray", linetype = "dashed") + 
  scale_y_continuous(limits = c(0, 1), breaks = c(),
                     name = "") +
  scale_x_continuous(limits = c(0, 1), breaks = c(),
                     name = "") +
  scale_colour_solarized(guide = FALSE) +
  scale_fill_solarized(guide = FALSE) 
```

We first illustrate this approach using data from the English WS form alone. Analogous to the plots in \@ref(categories), the plot above shows areas where the data deviate from the pattern of category acquisition predicted by random item sampling. The size of the shaded region above vs. below the diagonal gives evidence of over- vs. under-sampling for a particular semantic category. 

Many of the results of this analysis for English are expected. Sounds items are heavily over-represented, as are Body Parts, Games and Routines, and to a slightly lesser extent, Toys, Animals, and Vehicles. These particular biases are likely related  particular parenting practices, cultural emphases (for example, on animal names), and young children's' idiosyncratic interests. For a more in-depth examination of the consistencies in very early vocabulary, see Chapter \@ref(items); for more detail on what makes particular words easier or harder to learn, see Chapter \@ref(aoapred). 

The largest *under*-representation across categories is Time Words. This pattern is consistent with a body of work on children's acquisition of the semantics of time words that suggests that children struggle with understanding these complex terms through age five [@tillman2015,@tillman2017]. 

We next turn to how this pattern varies across languages. 

## Results

```{r ccs_plot_points_ws}
plot_data <- cat_comp_data %>%
    filter(form %in% WSs, 
           category %in% included_cats) %>%
    mutate(langform = interaction(language, form), 
           category = fct_reorder2(category, vocab, prop, function(x, y) {
           sum(x - y)
           }, .desc=FALSE))
  
ggplot(plot_data, 
         aes(x = vocab, y = prop, colour = langform)) +
    facet_wrap(~category) +
    scale_y_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.5),
                       name = "Proportion of Category") +
    scale_x_continuous(limits = c(0, 1), breaks = seq(0, 1, 0.5),
                       name = "Vocabulary Size") +
    scale_colour_solarized(name = "", guide=FALSE) +
    theme(legend.position = "top",
          legend.key = element_blank(),
          legend.background = element_rect(fill = "transparent"), 
          strip.text.x = element_text(size = 7)) + 
  geom_line(stat="smooth",method = "clm", formula = y ~ I(x ^ 3) + I(x ^ 2) + x - 1, 
              size = 1, se = FALSE, alpha = .2) + 
  geom_abline(slope = 1, intercept = 0, linetype = "dashed") 
```

Because there are so many different languages represented in this analysis, the simplest analysis examines the spread of languages across categories. Somewhat surprisingly, the ordering of categories looks quite similar to what was observed in English. Sounds, Games and Routines, and Body parts are all over-represented. Vehicles, Food and Drink, Animals, and Clothing all are variable across cultures, as is People. Household, Outside, and Furniture and Rooms show variability but overall less bias. Finally, Places and Time Word are both under-represented systematically across all languages. 

```{r ccs_plot_areas}
cat_order <- area_summary %>%
  filter(category %in% included_cats) %>%
  group_by(category) %>%
  summarise(mean = mean(mean)) %>%
  arrange(desc(mean)) %>%
  pull(category)

ggplot(filter(area_summary, 
              form %in% WSs, 
              category %in% c("sounds","games_routines","vehicles","body_parts")) %>%
         unite(langform, language, form),
       aes(x = langform, y = mean, colour = langform)) +
  facet_grid(.~category) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  coord_flip() +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  scale_colour_solarized(name = "", guide = FALSE) + 
  ylab("Relative representation in early vocabulary") + 
  xlab("")
```

We can zoom in on the most highly over-represented categories. The highest mean comes from body parts, which are over-represented in just about every language. Interestingly, the three datasets with the lowest proportion of body parts are the two Mandarin datasets (WS and TC) and the Cantonese WS data. Games and routines are generally over-represented but somewhat more variable, with Kiswahili, Kigiriama, and Mandarin TC data lowest. Sounds are quite highly variable but almost all positive, with Russian sounds being the outlier. Inspection of these items shows *negative* developmental trajectories for a number of animal sounds. We believe these data are likely an artifact of parents feeling that they "trade off" with noun labels for animals, and hence should be discounted. Finally, vehicles appear more variable with positive preferences across language families.

```{r}
ggplot(filter(area_summary, 
              form %in% WSs, 
              category %in% c("people","places","time_words")) %>%
         unite(langform, language, form),
       aes(x = langform, y = mean, colour = langform)) +
  facet_grid(.~category) +
  geom_pointrange(aes(ymin = ci_lower, ymax = ci_upper)) + 
  coord_flip() +
  geom_hline(yintercept = 0, linetype = "dashed") + 
  scale_colour_solarized(name = "", guide = FALSE) + 
  ylab("Relative representation in early vocabulary") + 
  xlab("")
```
We end by considering people, places, and time words. People is a highly-variable category, with some languages under-representing and others over-representing. @tardif2008 speculated that names for people were a substantial part of children's earliest words, but that may reflect that study's use of Mandarin and Cantonese data where people terms are very over-represented due to cultural emphasis on family connections. Surprisingly, despite the relatively multi-generational and family-centric nature of children's experience in Kenya [@alcock2013], people words were relatively under-represented in Kiswahili and Kigiriama. 

In contrast to the heterogeneity in people words, words for places and, especially, time words were almost uniformly under-represented in children's vocabulary. As noted above, time is known to be conceptually difficult for children. Interestingly, though, less has been written about children's understanding of geographical vocabulary. Time words offer a number of conceptual challenges in terms of mapping an ordered set of durations (second < minute < hour < day, etc.) to a set of concepts that do not map cleanly onto perceptual experience. In some sense, many of the same conceptual difficulties hold true for larger locational/geographical hierarchies (neighborhood < city < state < country). Or alternatively, the under-representation of places in children's early vocabulary may simply reflect the relative lack of diversity of their experiences with some of the items that traditionally populate this section (e.g., *beach*, *camping*, *church*, *circus* to name the first four). See Appendix \@ref(appendix-psychometrics) for some evidence that *camping* especially may be variable in children's experience.

## Dimensionality reduction


```{r ccs_princomp}
areas <- filter(area_summary_ordered, 
              form %in% WSs, 
              measure == "produces", 
              category %in% included_cats) %>%
  unite(langform, language, form) %>%
  filter(category != "sounds")

areas <- areas %>%
  dplyr::select(langform, category, mean) %>%
  spread(category, mean) 

areas_matrix <- as.matrix(dplyr::select(areas, -langform))
row.names(areas_matrix) <- areas$langform

# remove NAs 
areas_matrix_clean <- areas_matrix[!rowSums(!is.finite(areas_matrix)),]

pcs <- princomp(areas_matrix_clean)
```

Our next analysis of these data takes an exploratory dimensionality-reduction approach. Rather than examining each semantic category individually, we consider the space defined by variation in semantic preferences by running principal components analysis (PCA) on these data. PCA is a dimensionality reduction technique that projects high-dimensional data (e.g., bias by semantic category for each language) into a set of orthogonal dimensions where lower dimensions capture as much of the variance as possible. 

Standard PCA requires no missing data, thus we removed languages with missing categories. This analysis thus includes `r nrow(areas_matrix_clean)` language/form combinations and `r ncol(areas_matrix_clean)` categories (we exclude sounds because of the issue with Russian sounds and other missing data). 

```{r}

autoplot(pcs,  label.repel = TRUE, loadings.label.repel = TRUE)
autoplot(pcs,  loadings = TRUE, loadings.label=TRUE, 
         shape=FALSE, label=FALSE, loadings.label.repel=TRUE)
```

The figures above show the data projected into the space of the first two principal components and the loadings of semantic categories on these two components, respectively. 

Several observations emerge: Mandarin and Cantonese WS data are very far towards the direction of people (indicating that these datasets are unusual in this respect). Second, Kiswahili and Kigiriama are especially far in the direction of  outside and place words, perhaps consistent with the datasets being collected in rural and semi-rural areas. Many Northern European datasets (as well as Korean) are clustered at the far left, with high scores on vehicles, clothing, animals. Overall, this analysis reveals some interesting structure, but care should be taken not to over-interpret. In particular, within culture differences (e.g., Mandarin TC vs. Mandarin WS) are as large in size as between-culture differences.

## Individual conceptual items

In this section, we isolate individual items from specific domains of interest. Our approach is to use the "universal lemma" mappings (see Chapter \@ref(methods)) to find matching lexical items across languages. The specific domains we consider are time, color, body parts, and logical words. We also investigated spatial prepositions and number words, but do not include them here. Spatial prepositions present a wide variety of mapping issues since lexical items "cut up" space differently across languages  [see e.g., @bowerman1996]. And number words are not found on enough CDI forms to have sufficient data for inclusion. 


```{r semantics_base_plot_for_unigrams}
plot_unis <- function(uni_data) {
  uni_data <- uni_data %>%
    mutate(uni_lemma = fct_reorder(uni_lemma, mean, .desc=TRUE)) %>%
    unite(langform, language, form)
  
  ggplot(uni_data, 
         aes(x = age, y = mean, col = langform)) + 
    geom_smooth(se=FALSE, span = 1, alpha = .3) + 
    geom_smooth(aes(group = 1), span = 1, col = "black", se=FALSE, lty = 2) + 
    facet_wrap(~uni_lemma) + 
    theme(legend.position = "bottom", 
          legend.text=element_text(size=6)) + 
    scale_color_discrete(guide = guide_legend(ncol = 6)) + 
    ylim(0,1) + 
    ylab("Proportion Production") + 
    xlab("Age (Months)") + 
    xlim(16,32) # arbitrary
}
```

### Time 


```{r}
time_words <- read_feather("data/time_words.feather")
time_unis <- unique(time_words$uni_lemma)
```

As discussed above, the semantics of time words are very challenging for children through middle childhood [@tillman2014;@tillman2016]. Despite this, parents report that children do produce them by age 2.5. The set of words with sufficient translation equivalents for inclusion was `r Reduce(paste0,sprintf("%s, ", time_unis[1:length(time_unis)-1]))` and `r time_unis[length(time_unis)]`. 

```{r}
plot_unis(time_words)
```

The plot above shows trajectories for these lexical items across languages, sorted by difficulty. Because *night* is typically signaled by darkness, it is perceptually very concrete and likely easier. Similarly, *now* seems relatively more straightforward given that it has a common imperative meaning in sentences like "give  me that right now." In contrast, the latest-acquired is *yesterday*, which is highly abstract and deals with a specific part of the past. 

### Color


Color word acquisition has been a focus of interest at least since early work by  @carey1978's influential study of "fast mapping." Although early work suggested that color words were learned almost simultaneously [@bartlett1977], more recent studies have described a more protracted trajectory of partial knowledge. Many children learn some color words and overextend these to cover the rest of color space [@wagner2013]. Adding to the complexity of this issue is substantial cohort changes in the age at which colors are learned: while school-aged children struggled with their colors 50-100 years ago, more recently children learn colors in the age range spanned by the CDI forms [@bornstein1985].


```{r}
color_words <- read_feather("data/color_words.feather")
color_unis <- unique(color_words$uni_lemma)
```

There is tremendous cross-linguistic variation in color vocabulary [@kay2009]. We take advantage of the fact that most of the languages in our dataset have relatively larger color vocabularies, which we can assume means that individual colors probably have relatively similar extensions.^[Such an assumption would not be warranted if we were considering languages with just a handful of color terms, in which the extension of a term like "red" would be much larger than in English.] Despite this, most CDI forms do not include all the basic level color words. The set of color words with sufficient translation equivalents for inclusion was `r Reduce(paste0,sprintf("%s, ", color_unis[1:length(color_unis)-1]))` and `r color_unis[length(color_unis)]`.


```{r}
plot_unis(color_words)
```

In this set of words, we see that *red* is typically the first learned, although their is substantial variability in when it is learned. It is followed by *yellow*, *blue*, and *green*, with *black* and *white* following behind (consistent with reports by @wagner2013. We additionally see an ordering across languages in which have higher rates of color word production reported.

```{r}
color_langs <- color_words %>%
  unite(langform, language, form) %>%
  group_by(langform, age) %>%
  summarise(mean = mean(mean))
 
ggplot(color_langs, 
       aes(x = age, y = mean, col = langform)) +
  geom_smooth(se = FALSE, span = 1) + 
  geom_label_repel(data = color_langs %>%
                     group_by(langform) %>%
                     filter(age == max(age)),
                   aes(label = langform), 
                   size = 3) +
  scale_color_discrete(guide = FALSE) + 
  ylim(0,1) + 
  ylab("Proportion Production") + 
  xlab("Age (Months)") + 
  xlim(16,36) 
```

As in other analyses (see Chapter \@ref(vocab)), Mandarin WS has the highest level of production. American and Australian English also tend to have high levels of color production. Interestingly, Kiswahili has by far the lowest level of color production, perhaps related to the availability of manufactured toys of contrastive colors [@bornstein1985]. 

### Body parts

```{r}
body_words <- read_feather("data/body_words.feather")
plot_unis(body_words)
```

Words for body parts are produced very early by most children, and variance is quite low across languages (with the exception of a few terms in Cantonese and Cypriot Greek). One interesting pattern that is visible in these data is the ordering of *hand* and *foot* before *leg* and *arm*. 

### Logic

```{r}
logic_words <- read_feather("data/logic_words.feather")
plot_unis(logic_words)
logic_unis <- unique(logic_words$uni_lemma)
```

Finally, we examine words for logical operators. The only items that are available across significant samples of languages are `r Reduce(paste0,sprintf("%s, ", logic_unis[1:length(logic_unis)-1]))` and `r logic_unis[length(logic_unis)]`. The negative words are learned early, with an ordering consistent with @bellugi1967 and @pea1982. *No* is very early, and *not* later. Interestingly, the quantifiers are not ordered as shown by @katsos2016 in a massive cross-linguistic study. In that study -- as well as in our own work in English [@horowitz2017] -- *all* was found to be understood better than *none*. In contrast, here we tend to find *none* learned earlier than *all* and definitely learned earlier than *some*. One possibility is that these uses are only found in a restricted set of cases. Another is that contextualized production of negation is simpler than de-contextualized comprehension, as we have found in some of our work on the comprehension of negation in context [@nordmeyer2014;@nordmeyer2018].

### Category variability


Finally, we quantify the variability across languages for each of these restricted sets of lexical items. For 20-30 month-olds (chosen somewhat arbitrarily as the age range of highest coverage across forms), we compute the coefficient of variation for children at each age on each lexical item. We additionally add animal words for the sake of comparison. The table below gives the coefficient of variation for each category above, averaging across lexical items. 


```{r}
animal_words <- read_feather("data/animal_words.feather")
cat_var <- bind_rows(time_words %>% mutate(category = "time"),
          body_words %>% mutate(category = "body"),
          color_words %>% mutate(category = "color"), 
          logic_words %>% mutate(category = "logic"), 
          animal_words %>% mutate(category = "animals")) %>%
  filter(age > 19, age < 31) %>%
  group_by(category, uni_lemma, age) %>%
  summarise(cv = sd(mean, na.rm = TRUE) / mean(mean, na.rm=TRUE)) %>%
  summarise(cv = mean(cv)) 
  
cat_var %>%
  summarise(cv = round(mean(cv), 2)) %>%
  datatable(colnames = c("Category","Coefficient of Variation"))
```

Body words as well as animal words are highly consistent across languages. In contrast, color, logic words, and time words are far less consistent. These effects are likely somewhat affected by floor and ceiling effects, but inspection of individual items confirms the robustness of the general conclusion.

```{r}
cat_var %>%
  mutate(cv = round(cv,2)) %>%
    datatable(colnames = c("Category","Word", "Coefficient of Variation"))
```


## Discussion

In these exploratory analyses, we considered representation of different semantic categories across the different languages in our dataset. We found some surprising consistencies. Place words and time words were under-represented, while sounds, games and routines, and body parts were over-represented. These consistencies were also contrasted with some areas of greater variability: for example, the preference for vehicles, clothing, and animals appeared to be a somewhat coherent dimension in our data, with many (northern) European languages higher on this dimension than non-European languages. Still, substantial caution is necessary in interpreting these results as the sample of non-European languages is small. Finally, we found that acquisition of complex conceptual words in categories like color, time, and logical words was highly variable across languages.
