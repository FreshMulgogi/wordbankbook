# Individual Words: Consistencies {#items}

## Baby's First Words are Consistent Across Languages

```{r load_consistency_data}
if(!local_data) {
  wg_langs <- instruments %>%
    filter(form == "WG") %>%
    distinct(language) %>%
    pull(language)
  
  ws_langs <- instruments %>%
    filter(form == "WS") %>%
    distinct(language) %>%
    pull(language)
  
  ws_sub_langs <- intersect(wg_langs, ws_langs)
  
  wg_data <- map( wg_langs, function(lang) {
    get_instrument_data(lang, "WG") %>%
      mutate(language = lang)
    }) %>%
    bind_rows
  
  ws_sub_data <-  map(ws_sub_langs, function(lang) {
    get_instrument_data(lang, "WS") %>%
      mutate(language = lang)
    }) %>%
    bind_rows


# Get words and gestures data
kid_wg_data <- wg_data %>%
  left_join(items) %>%
  left_join(admins) %>%
  filter(form == "WG", type == "word", !is.na(uni_lemma), !is.na(age)) %>%
  select(data_id, value, age, language, uni_lemma, category, lexical_category, lexical_class)

# Get the items from Words and Sentences also on Words and Gestures for each language
stitch_items <- items %>%
  filter(language %in% unique(ws_sub_data$language)) %>%
  group_by(language, lexical_category, uni_lemma) %>%
  summarise(n = n()) %>%
  filter(n > 1) %>%
  select(-n) %>%
  mutate(form = "WS") %>%
  left_join(items)

# Stitch together words and gestures
stitched_data <- ws_sub_data %>%
  left_join(stitch_items) %>%
  left_join(admins) %>%
  filter(!is.na(age)) %>%
  select(data_id, value, age, language, uni_lemma, category, 
         lexical_category, form) %>%
  bind_rows(kid_wg_data %>%
              filter(language %in% unique(ws_sub_data$language)) %>%
              mutate(form = "WG"))

}
```

Some words about AOA estimation

```{r compute_aoa}
# Fit robust regressions to comprehension or production data
fit_rglm <- function(data) {
  
  if(any(str_detect(names(data), "produces")))
    model <- robustbase::glmrob(cbind(produces, total - produces) ~ age,
               family = "binomial",
               data = data)
  else
    model <- robustbase::glmrob(cbind(understands, total - understands) ~ age,
               family = "binomial",
               data = data)
  
  aoa <- -model$coefficients[["(Intercept)"]] / model$coefficients[["age"]]
  
  data.frame(uni_lemma = data$uni_lemma[1],
             language = data$language[1],
             lexical_category = data$lexical_category[1],
             rglm_aoa = aoa)

}

if(!local_data) {
  

# Compute number of kids who produce each word at each age
production_data <- stitched_data %>%
  group_by(form, language, lexical_category, age, uni_lemma) %>%
  summarise(produces = sum(value == "produces", na.rm = T), 
            total = n()) %>%
  filter(!is.na(uni_lemma)) %>%
  filter(!language %in% c("French (Quebec)", "Hebrew"))

# Get production for items on both forms 
both_form_data <- production_data %>%
  group_by(language, uni_lemma) %>%
  summarise(num_forms = length(unique(form))) %>%
  filter(num_forms > 1) %>%
  select(-num_forms) %>%
  left_join(production_data)

# Comprehension on WG
understanding_data <- kid_wg_data %>%
  group_by(language, lexical_category, age, uni_lemma) %>%
  summarise(understands = sum(value %in% c("understands", "produces"), 
                              na.rm = T),  
            total = n()) %>%
  filter(!is.na(uni_lemma)) %>%
  filter(!language %in% c("French (Quebec)", "Hebrew"))

# Estimate AOAs for production
production_aoas <- both_form_data%>%
  split(paste(.$language, .$uni_lemma, sep = "_")) %>%
  map(fit_rglm) %>%
  bind_rows %>%
  mutate(measure = "produces")

# Estimate AOAs for comprehension
understanding_aoas <- understanding_data %>%
  split(paste(.$language, .$uni_lemma, sep = "_")) %>%
  map(fit_rglm) %>%
  bind_rows %>%
  mutate(measure = "understands")

all_aoas <- bind_rows(production_aoas, understanding_aoas)
#write_feather(all_aoas,"data/aoas.feather")

} else {all_aoas <- read_feather("data/aoas.feather")}
  
```

Looking at unilemma completeness

```{r uni_lemma_completeness}
lemma_completeness <- all_aoas %>%
  group_by(measure, uni_lemma) %>%
  summarise(in_langs = sum(!is.na(rglm_aoa))) %>%
  group_by(measure, in_langs) %>%
  summarise(n = n()) %>%
  arrange(measure, desc(in_langs)) %>%
  mutate(prop = n/sum(n)) %>%
  mutate(cum_prop = cumsum(prop),
         cum_n = cumsum(n))
```

Production

```{r uni_lemma_completeness_production}
lemma_completeness %>%
  ungroup() %>%
  filter(measure == "produces") %>%
  select(-measure) %>%
  datatable
```

Comprehension

```{r uni_lemma_completeness_comprehension}
lemma_completeness %>%
  ungroup() %>%
  filter(measure == "understands") %>%
  select(-measure) %>%
  datatable
```

Top 10 words across languages

```{r top10_compute}
top10 <- all_aoas %>%
  group_by(measure,language) %>%
  arrange(rglm_aoa) %>%
  slice(1:10) %>%
  select(-rglm_aoa, -lexical_category) %>%
  mutate(order = 1:n()) %>%
  spread(language, uni_lemma) 
```

Comprehension

```{r top10_production}
top10 %>% 
  ungroup() %>%
  filter(measure == "produces") %>%
  select(-measure, -order) %>%
  datatable
```

Production

```{r top10_comprehension}
top10 %>% 
  ungroup() %>%
  filter(measure == "understands") %>%
  select(-measure, -order) %>%
  datatable
```

Acquisition order in production vs comprehension across languages

```{r understands_and_produces}
median_aoas <- all_aoas %>%
  group_by(measure, uni_lemma) %>%
  summarise(n = sum(!is.na(rglm_aoa)),
            rglm_aoa = median(rglm_aoa, na.rm = T)) %>%
  filter(n >= 6) %>%
  arrange(measure, rglm_aoa)

wide_medians <- median_aoas %>%
  spread(measure, rglm_aoa) %>%
  group_by(uni_lemma) %>%
  summarise_at(vars(n, produces, understands), mean, na.rm=T)

ggplot(wide_medians, aes(x = produces, y = understands, label = uni_lemma)) + 
  geom_text() +
  theme_bw()
```

Consistency across languages
```{r aoa_consistency}
aoa_corr <- function(df, lang1, lang2) {

 corrs <- df %>%
    select(-lexical_category, -measure) %>%
    filter(language == lang1 | language == lang2) %>%
    spread(language, rglm_aoa) %>%
    select(-uni_lemma) %>%
    cor(., use = "complete") 
 
 return(corrs[2,1])
}

compute_corrs <- function(aoas, top_n = NA) {
  
  if(!is.na(top_n)) {
    
    sub_words <- median_aoas %>%
      filter(measure == unique(aoas$measure)) %>%
      slice(1:top_n)
    
    filtered_aoas <- aoas %>%
      filter(uni_lemma %in% sub_words$uni_lemma)
  } 
  else 
    filtered_aoas <- aoas
  
  
  langs <- unique(filtered_aoas$language)
  
  lang_pairs <- combn(langs, 2) %>%
    t() %>%
    as_data_frame() %>%
    rename(lang1 = V1, lang2 = V2)

  
  lang_pairs %>%
    mutate(cor = unlist(map(1:nrow(lang_pairs), function(x) {
      aoa_corr(filtered_aoas,
               as.character(lang_pairs[x,"lang1"]), 
               as.character(lang_pairs[x,"lang2"]))})))

}


production_corrs <- compute_corrs(filter(all_aoas, measure == "produces",
                                         rglm_aoa < 60, rglm_aoa > 6)) 



understanding_corrs <- compute_corrs(filter(all_aoas, measure == "understands",
                                         rglm_aoa < 60, rglm_aoa > 6))
```

Production consistency 
```{r production_consistentency_mat}

production_corrs_full <- production_corrs %>%
  bind_rows(rename(production_corrs, lang1 = lang2, lang2 = lang1)) %>%
  bind_rows(data_frame(lang1 = unique(all_aoas$language), 
                       lang2 = unique(all_aoas$language), cor = 1))

ggplot(production_corrs, aes(x = lang1, y = lang2, fill = cor)) +
  geom_tile() + 
  geom_text(aes(label = round(cor, 2))) +
  theme_bw()
```

Comprehension consistency 
```{r comprehension_consistency_mat}

understanding_corrs_full <- understanding_corrs %>%
  bind_rows(rename(understanding_corrs, lang1 = lang2, lang2 = lang1)) %>%
  bind_rows(data_frame(lang1 = unique(all_aoas$language), 
                       lang2 = unique(all_aoas$language), cor = 1))

ggplot(understanding_corrs, aes(x = lang1, y = lang2, fill = cor)) +
  geom_tile() + 
  geom_text(aes(label = round(cor, 2))) +
  theme_bw()
```

Production dendrogram
```{r consistency_dendro}
library(ggdendro)

production_wide <- production_corrs_full %>%
  spread(lang2, cor) %>%
  as.data.frame 
rownames(production_wide) <- production_wide$lang1

production_hc <- hclust(dist(select(production_wide, -lang1)))
ggdendrogram(production_hc) +
  theme_bw()
```

Understanding dendrogram
```{r}
understanding_wide <- understanding_corrs_full %>%
  spread(lang2, cor) %>%
  as.data.frame 
rownames(understanding_wide) <- understanding_wide$lang1

understanding_hc <- hclust(dist(select(understanding_wide, -lang1)))
ggdendrogram(understanding_hc) +
  theme_bw()
```

Consistency across acquisition order
```{r step_corrs, eval = FALSE}
median_sub_aoas <- median_aoas %>%
  filter(measure == "produces", 
         n >= 6) %>%
  mutate(language = "Median") %>%
  select(-n) %>%
  arrange(rglm_aoa) %>%
  mutate(order = 1:nrow(.))
  
cl_acq_order <- all_aoas %>%
  filter(measure == "produces") %>%
  filter(uni_lemma %in% median_sub_aoas$uni_lemma) %>%
  group_by(language) %>%
  arrange(rglm_aoa) %>%
  mutate(lang_order = 1:n()) %>%
  left_join(select(median_sub_aoas, order, uni_lemma)) %>%
  mutate(diff = lang_order-order)

# ggplot(cl_acq_order, aes(x = order, y = lang_order, 
#                          color = language, label = language)) + 
#   geom_smooth(se=FALSE) + 
#   theme_bw() +
#   geom_dl(method = list(dl.trans(x=x + .2), "last.points", cex=1)) + 
#   geom_line(data = mutate(median_sub_aoas, lang_order = order),
#             color = "black", size = 2)
# 



ggplot(cl_order_stats, aes(x = median, y = diff)) +
  geom_smooth() +
  geom_point() + 
  theme_bw()


ggplot(filter(median_aoa, measure == "produces", n >=6 ), aes(x = )) 

production_step_cors <- map(5:nrow(filter(median_aoas, measure == "produces")), 
                 function(x) mutate(compute_corrs(filter(all_aoas, measure == "produces"),
                                                  x), words = x)) %>%
  bind_rows

production_avg_corr <- production_step_cors %>%
  group_by(words, lang1) %>%
  summarise(cor = mean(cor, na.rm = T)) %>%
  summarise(mean = mean(cor), sd = sd(cor))


ggplot(production_avg_corr, aes(x = words, y = mean)) + 
  geom_ribbon(aes(ymin = mean-sd, ymax = mean+sd), alpha = .5, fill = "red") + 
  geom_line() +
  theme_bw()

understanding_step_cors <- map(5:nrow(filter(median_aoas, measure == "understands")), 
                 function(x) mutate(compute_corrs(filter(all_aoas, measure == "understands"),
                                                  x), words = x)) %>%
  bind_rows

understanding_avg_corr <- understanding_step_cors %>%
  group_by(words, lang1) %>%
  summarise(cor = mean(cor, na.rm = T)) %>%
  summarise(mean = mean(cor), sd = sd(cor))


ggplot(understanding_avg_corr, aes(x = words, y = mean)) + 
  geom_ribbon(aes(ymin = mean-sd, ymax = mean+sd), alpha = .5, fill = "red") + 
  geom_line() +
  theme_bw()
```

Demographic effects. In this part, we focus on demographic differences in the learning of individual words. Braginsky et al. (2016b) reported on gender differences in the particular words in early vocabulary; we generalize this analysis to birth order and socio-economic status



## Predicting Which Words are Harder or Easier

AOA PRED

Predicting early learning. Braginsky et al. (2016a) provides an analysis in which independent data sources (including transcripts of child-directed speech) are brought to bear as predictors of acquisition differences between words. This “age of acquisition prediction” model allows us to quantify the consistency and variability in predictor values across languages for particular words, using the UL approach to cross-linguistic analysis. 

By-item stuff like overall item trajectories, `gender-input`, and `uni_lemma` based cross-linguistic consistency things.
